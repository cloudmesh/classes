<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Technologies &#8212; Big Data Classes</title>
    
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/bootswatch-3.3.6/cerulean/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     'Draft',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-3.3.6/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-sphinx.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Lessons" href="../lesson/index.html" />
    <link rel="prev" title="HID Assignment" href="hids-techs.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body role="document">

  <div id="navbar" class="navbar navbar-inverse navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html">
          i524</a>
        <span class="navbar-text navbar-version pull-left"><b></b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="index.html">Overview</a></li>
                <li><a href="lectures.html">Lectures</a></li>
                <li><a href="../lesson/index.html">Lessons</a></li>
                <li><a href="../changelog.html">Changes</a></li>
                <li><a href="https://github.com/cloudmesh/classes">Fork</a></li>
                <li><a href="https://piazza.com/class/ix39m27czn5uw">Piazza</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="preface/index.html">Preface</a><ul>
<li class="toctree-l2"><a class="reference internal" href="preface/about.html">About</a></li>
<li class="toctree-l2"><a class="reference internal" href="preface/disclaimer.html">Disclaimer</a></li>
<li class="toctree-l2"><a class="reference internal" href="preface/convention.html">Conventions</a></li>
<li class="toctree-l2"><a class="reference internal" href="preface/instructors.html">Instructors</a></li>
<li class="toctree-l2"><a class="reference internal" href="preface/instructors.html#teaching-assistants">Teaching Assistants</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="index.html">i524 Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="index.html#meeting-times">Meeting Times</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#online-meetings">Online Meetings</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#who-can-take-the-class">Who can take the class?</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#homework">Homework</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#open-source-publication-of-homework">Open Source Publication of Homework</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#piazza">Piazza</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#tips-on-how-to-achieve-your-best">Tips on how to achieve your best</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#submissions">Submissions</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#selected-project-ideas">Selected Project Ideas</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#software-project">Software Project</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#report-format">Report Format</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#github-repositories">Github repositories</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#code-repositories-deliverables">Code Repositories Deliverables</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#learning-outcomes">Learning Outcomes</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#academic-integrity-policy">Academic Integrity Policy</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#links">Links</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#course-numbers">Course Numbers</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="calendar.html">I524 Calendar</a><ul>
<li class="toctree-l2"><a class="reference internal" href="calendar.html#comments">Comments</a></li>
<li class="toctree-l2"><a class="reference internal" href="calendar.html#official-university-calendar">Official University calendar</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures.html">I524 Lectures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures.html#lectures">Lectures</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures.html#lectures-theory-track">Lectures - Theory Track</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures.html#lectures-collaboration-track">Lectures - Collaboration Track</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures.html#lectures-systems">Lectures - Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures.html#unreleased-lectures">Unreleased Lectures</a></li>
</ul>
</li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="hids-techs.html">HID Assignment</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Technologies</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#workflow-orchestration">Workflow-Orchestration</a></li>
<li class="toctree-l2"><a class="reference internal" href="#application-and-analytics">Application and Analytics</a></li>
<li class="toctree-l2"><a class="reference internal" href="#application-hosting-frameworks">Application Hosting Frameworks</a></li>
<li class="toctree-l2"><a class="reference internal" href="#high-level-programming">High level Programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="#streams">Streams</a></li>
<li class="toctree-l2"><a class="reference internal" href="#basic-programming-model-and-runtime-spmd-mapreduce">Basic Programming model and runtime, SPMD, MapReduce</a></li>
<li class="toctree-l2"><a class="reference internal" href="#inter-process-communication-collectives">Inter process communication Collectives</a></li>
<li class="toctree-l2"><a class="reference internal" href="#in-memory-databases-caches">In-memory databases/caches</a></li>
<li class="toctree-l2"><a class="reference internal" href="#object-relational-mapping">Object-relational mapping</a></li>
<li class="toctree-l2"><a class="reference internal" href="#extraction-tools">Extraction Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="#sql-newsql">SQL(NewSQL)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#nosql">NoSQL</a></li>
<li class="toctree-l2"><a class="reference internal" href="#file-management">File management</a></li>
<li class="toctree-l2"><a class="reference internal" href="#data-transport">Data Transport</a></li>
<li class="toctree-l2"><a class="reference internal" href="#cluster-resource-management">Cluster Resource Management</a></li>
<li class="toctree-l2"><a class="reference internal" href="#file-systems">File systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="#interoperability">Interoperability</a></li>
<li class="toctree-l2"><a class="reference internal" href="#devops">DevOps</a></li>
<li class="toctree-l2"><a class="reference internal" href="#iaas-management-from-hpc-to-hypervisors">IaaS Management from HPC to hypervisors</a></li>
<li class="toctree-l2"><a class="reference internal" href="#cross-cutting-functions">Cross-Cutting Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#new-technologies-to-be-integrated">New Technologies to be integrated</a></li>
<li class="toctree-l2"><a class="reference internal" href="#excersise">Excersise</a></li>
<li class="toctree-l2"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../lesson/index.html">Lessons</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../lesson/cloud/index.html">Cloud (under construction)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/contrib/index.html">Contributing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/doc/index.html">Writing Documents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/linux/index.html">Linux</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/org/index.html">Oragnization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/prg/index.html">Programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/data/index.html">Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/projects/index.html">Software Projects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/projects/draft.html">Software Projects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/iaas/index.html">IaaS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/ansible.html">Ansible</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/ansible-start-point.html">Ansible</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/chef.html">Chef</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/comparison.html">Compaprison of Configuration management software</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/composite_cluster.html">Composite Clusters (under preparation)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/deployment.html">Dynamic deployment of arbitrary X software on VC (under preparation)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/hadoop.html">Hadoop Virtual CLuster (under preparation)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/juju.html">Ubuntu Juju</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/mongodb_cluster.html">MongoDB Virtual Cluster (under preparation)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/openmpi_cluster.html">OpenMPI Virtual Cluster (Under Preparation)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/openstack_heat.html">OpenStack Heat</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/other.html">Other (Under Preparation)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/overview.html">DevOps (under preparation)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/overview_vc.html">Overview Virtual Cluster (under preparation)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/puppet.html">Puppet</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/saltstack-ex1-output.html">Full Message of <code class="docutils literal"><span class="pre">salt-call</span></code> Execution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/saltstack.html">SaltStack</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/index.html">Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-do-i-ask-a-question">How do I ask a question?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-are-the-prerequisites-for-this-class">What are the prerequisites for this class?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#why-is-this-class-not-hosted-on-edx">Why is this class not hosted on EdX?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#why-are-you-not-using-canvas-for-communicating-with-students">Why are you not using CANVAS for communicating with students?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#why-are-you-using-github-for-submitting-projects-and-papers">Why are you using github for submitting projects and papers?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i-am-full-time-student-at-iupui-can-i-take-the-online-version">I am full time student at IUPUI. Can I take the online version?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i-am-a-residential-student-at-iu-can-i-take-the-online-version-only">I am a residential student at IU. Can I take the online version only?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#the-class-is-full-what-do-i-do">The class is full what do I do?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#do-i-need-to-buy-a-textbook">Do I need to buy a textbook?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#why-is-there-no-textbook">Why is there no textbook?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#do-i-need-a-computer-to-participate-in-this-class">Do I need a computer to participate in this class?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#representative-bibliography">Representative Bibliography</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#where-is-the-official-iu-calendar-for-the-fall">Where is the official IU calendar for the Fall?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-to-write-a-research-article-on-computer-science">How to write a research article on computer science?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#which-bibliography-manager-is-required-for-the-class">Which bibliography manager is required for the class?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#can-i-use-endnote-or-other-bibliography-managers">Can I use endnote or other bibliography managers?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#plagiarism-test-and-resources-related-to-that">Plagiarism test and resources related to that</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-many-hours-will-this-course-take-to-work-on-every-week">How many hours will this course take to work on every week?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#is-all-classes-material-final">Is all classes material final?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-are-the-changes-to-the-web-page">What are the changes to the web page?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-lectures-should-i-learn-when">What lectures should I learn when?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i524-why-are-you-doing-the-papers">I524: Why are you doing the papers?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i524-why-are-there-no-homework-to-test-me-on-skills-such-as-ansible-or-python">I524: Why are there no homework to test me on skills such as ansible or python?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i524-why-not-use-chef-or-another-devops-framework">I524: Why not use chef or another DevOps framework?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i-am-lost">I am lost?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i-do-not-like-technology-topic-project-etc">I do not like Technology/Topic/Project/etc?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i-am-not-able-to-attend-the-online-hours">I am not able to attend the online hours</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#do-i-need-to-attend-the-online-sessions">Do I need to attend the online sessions?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-are-the-leaning-outcomes">What are the leaning outcomes?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#there-are-so-many-messages-on-piazza-i-can-not-keep-up">There are so many messages on Piazza I can not keep up.</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i-find-the-hosting-web-confusing">I find the hosting Web confusing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i524-i-do-not-know-python-what-do-i-do">I524: I do not know python. What do I do?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-to-solve-merge-conflict-in-pull-request">How to solve merge conflict in Pull Request?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#building-cloudmesh-classes-in-local-machine">Building cloudmesh/classes in local machine</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-to-sole-merge-conflict-in-a-pull-request">How to sole Merge Conflict in a Pull Request?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#cheat-sheet-for-linux-commands">Cheat sheet for Linux commands</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#tips-techlist-1-homework">Tips: TechList.1 homework</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#techlist-1-and-paper-1-pagecount">Techlist 1 and Paper 1 : Pagecount</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#tips-to-install-virtualbox">Tips to Install Virtualbox</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#do-i-generate-the-ssh-key-on-ubuntu-vm">Do I generate the SSH key on Ubuntu VM ?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#ways-to-run-ubuntu-on-windows-10">Ways to run Ubuntu on Windows 10</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#don-t-use-anaconda">Don&#8217;t use Anaconda</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#using-ssh-key-for-git-push">Using SSH Key for Git Push</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-to-properly-research-a-bibtex-entry">How to properly research a bibtex entry</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-are-the-differnt-entry-types-and-fields">What are the differnt entry types and fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-is-the-nature-of-team-collaboration-on-papers">What is the nature of team collaboration on papers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-are-the-due-dates-for-assignments">What are the due dates for assignments</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-are-good-places-to-find-refernce-entries">What are good places to find refernce entries?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../todo.html">Todos</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../todo.html#general">General</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">Changelog</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#version-unreleased">%%version%% (unreleased)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#id1">3.0.9 (2017-01-30)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#id2">3.0.8 (2017-01-22)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#id6">3.0.7 (2017-01-20)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#id11">3.0.6 (2017-01-11)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#id14">3.0.5 (2017-01-11)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#id19">3.0.4 (2017-01-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#id20">3.0.3 (2017-01-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#id23">3.0.2 (2017-01-07)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#id24">3.0.1 (2017-01-06)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#id25">3.0 (2017-01-06)</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Technologies</a><ul>
<li><a class="reference internal" href="#workflow-orchestration">Workflow-Orchestration</a></li>
<li><a class="reference internal" href="#application-and-analytics">Application and Analytics</a></li>
<li><a class="reference internal" href="#application-hosting-frameworks">Application Hosting Frameworks</a></li>
<li><a class="reference internal" href="#high-level-programming">High level Programming</a></li>
<li><a class="reference internal" href="#streams">Streams</a></li>
<li><a class="reference internal" href="#basic-programming-model-and-runtime-spmd-mapreduce">Basic Programming model and runtime, SPMD, MapReduce</a></li>
<li><a class="reference internal" href="#inter-process-communication-collectives">Inter process communication Collectives</a></li>
<li><a class="reference internal" href="#in-memory-databases-caches">In-memory databases/caches</a></li>
<li><a class="reference internal" href="#object-relational-mapping">Object-relational mapping</a></li>
<li><a class="reference internal" href="#extraction-tools">Extraction Tools</a></li>
<li><a class="reference internal" href="#sql-newsql">SQL(NewSQL)</a></li>
<li><a class="reference internal" href="#nosql">NoSQL</a></li>
<li><a class="reference internal" href="#file-management">File management</a></li>
<li><a class="reference internal" href="#data-transport">Data Transport</a></li>
<li><a class="reference internal" href="#cluster-resource-management">Cluster Resource Management</a></li>
<li><a class="reference internal" href="#file-systems">File systems</a></li>
<li><a class="reference internal" href="#interoperability">Interoperability</a></li>
<li><a class="reference internal" href="#devops">DevOps</a></li>
<li><a class="reference internal" href="#iaas-management-from-hpc-to-hypervisors">IaaS Management from HPC to hypervisors</a></li>
<li><a class="reference internal" href="#cross-cutting-functions">Cross-Cutting Functions</a><ul>
<li><a class="reference internal" href="#monitoring">Monitoring</a></li>
<li><a class="reference internal" href="#security-privacy">Security &amp; Privacy</a></li>
<li><a class="reference internal" href="#distributed-coordination">Distributed Coordination</a></li>
<li><a class="reference internal" href="#message-and-data-protocols">Message and Data Protocols</a></li>
</ul>
</li>
<li><a class="reference internal" href="#new-technologies-to-be-integrated">New Technologies to be integrated</a></li>
<li><a class="reference internal" href="#excersise">Excersise</a></li>
<li><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
            
            
            
              <li class="hidden-sm"></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
      <div class="col-md-3">
        <div id="sidebar" class="bs-sidenav" role="complementary"><li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="preface/index.html">Preface</a><ul>
<li class="toctree-l2"><a class="reference internal" href="preface/about.html">About</a></li>
<li class="toctree-l2"><a class="reference internal" href="preface/disclaimer.html">Disclaimer</a></li>
<li class="toctree-l2"><a class="reference internal" href="preface/convention.html">Conventions</a></li>
<li class="toctree-l2"><a class="reference internal" href="preface/instructors.html">Instructors</a></li>
<li class="toctree-l2"><a class="reference internal" href="preface/instructors.html#teaching-assistants">Teaching Assistants</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="index.html">i524 Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="index.html#meeting-times">Meeting Times</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#online-meetings">Online Meetings</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#who-can-take-the-class">Who can take the class?</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#homework">Homework</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#open-source-publication-of-homework">Open Source Publication of Homework</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#piazza">Piazza</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#tips-on-how-to-achieve-your-best">Tips on how to achieve your best</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#submissions">Submissions</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#selected-project-ideas">Selected Project Ideas</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#software-project">Software Project</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#report-format">Report Format</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#github-repositories">Github repositories</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#code-repositories-deliverables">Code Repositories Deliverables</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#learning-outcomes">Learning Outcomes</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#academic-integrity-policy">Academic Integrity Policy</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#links">Links</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#course-numbers">Course Numbers</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#references">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="calendar.html">I524 Calendar</a><ul>
<li class="toctree-l2"><a class="reference internal" href="calendar.html#comments">Comments</a></li>
<li class="toctree-l2"><a class="reference internal" href="calendar.html#official-university-calendar">Official University calendar</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="lectures.html">I524 Lectures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="lectures.html#lectures">Lectures</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures.html#lectures-theory-track">Lectures - Theory Track</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures.html#lectures-collaboration-track">Lectures - Collaboration Track</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures.html#lectures-systems">Lectures - Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="lectures.html#unreleased-lectures">Unreleased Lectures</a></li>
</ul>
</li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="hids-techs.html">HID Assignment</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Technologies</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#workflow-orchestration">Workflow-Orchestration</a></li>
<li class="toctree-l2"><a class="reference internal" href="#application-and-analytics">Application and Analytics</a></li>
<li class="toctree-l2"><a class="reference internal" href="#application-hosting-frameworks">Application Hosting Frameworks</a></li>
<li class="toctree-l2"><a class="reference internal" href="#high-level-programming">High level Programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="#streams">Streams</a></li>
<li class="toctree-l2"><a class="reference internal" href="#basic-programming-model-and-runtime-spmd-mapreduce">Basic Programming model and runtime, SPMD, MapReduce</a></li>
<li class="toctree-l2"><a class="reference internal" href="#inter-process-communication-collectives">Inter process communication Collectives</a></li>
<li class="toctree-l2"><a class="reference internal" href="#in-memory-databases-caches">In-memory databases/caches</a></li>
<li class="toctree-l2"><a class="reference internal" href="#object-relational-mapping">Object-relational mapping</a></li>
<li class="toctree-l2"><a class="reference internal" href="#extraction-tools">Extraction Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="#sql-newsql">SQL(NewSQL)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#nosql">NoSQL</a></li>
<li class="toctree-l2"><a class="reference internal" href="#file-management">File management</a></li>
<li class="toctree-l2"><a class="reference internal" href="#data-transport">Data Transport</a></li>
<li class="toctree-l2"><a class="reference internal" href="#cluster-resource-management">Cluster Resource Management</a></li>
<li class="toctree-l2"><a class="reference internal" href="#file-systems">File systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="#interoperability">Interoperability</a></li>
<li class="toctree-l2"><a class="reference internal" href="#devops">DevOps</a></li>
<li class="toctree-l2"><a class="reference internal" href="#iaas-management-from-hpc-to-hypervisors">IaaS Management from HPC to hypervisors</a></li>
<li class="toctree-l2"><a class="reference internal" href="#cross-cutting-functions">Cross-Cutting Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#new-technologies-to-be-integrated">New Technologies to be integrated</a></li>
<li class="toctree-l2"><a class="reference internal" href="#excersise">Excersise</a></li>
<li class="toctree-l2"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../lesson/index.html">Lessons</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../lesson/cloud/index.html">Cloud (under construction)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/contrib/index.html">Contributing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/doc/index.html">Writing Documents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/linux/index.html">Linux</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/org/index.html">Oragnization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/prg/index.html">Programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/data/index.html">Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/projects/index.html">Software Projects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/projects/draft.html">Software Projects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/iaas/index.html">IaaS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/ansible.html">Ansible</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/ansible-start-point.html">Ansible</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/chef.html">Chef</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/comparison.html">Compaprison of Configuration management software</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/composite_cluster.html">Composite Clusters (under preparation)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/deployment.html">Dynamic deployment of arbitrary X software on VC (under preparation)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/hadoop.html">Hadoop Virtual CLuster (under preparation)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/juju.html">Ubuntu Juju</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/mongodb_cluster.html">MongoDB Virtual Cluster (under preparation)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/openmpi_cluster.html">OpenMPI Virtual Cluster (Under Preparation)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/openstack_heat.html">OpenStack Heat</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/other.html">Other (Under Preparation)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/overview.html">DevOps (under preparation)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/overview_vc.html">Overview Virtual Cluster (under preparation)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/puppet.html">Puppet</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/saltstack-ex1-output.html">Full Message of <code class="docutils literal"><span class="pre">salt-call</span></code> Execution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lesson/devops/saltstack.html">SaltStack</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/index.html">Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-do-i-ask-a-question">How do I ask a question?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-are-the-prerequisites-for-this-class">What are the prerequisites for this class?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#why-is-this-class-not-hosted-on-edx">Why is this class not hosted on EdX?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#why-are-you-not-using-canvas-for-communicating-with-students">Why are you not using CANVAS for communicating with students?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#why-are-you-using-github-for-submitting-projects-and-papers">Why are you using github for submitting projects and papers?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i-am-full-time-student-at-iupui-can-i-take-the-online-version">I am full time student at IUPUI. Can I take the online version?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i-am-a-residential-student-at-iu-can-i-take-the-online-version-only">I am a residential student at IU. Can I take the online version only?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#the-class-is-full-what-do-i-do">The class is full what do I do?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#do-i-need-to-buy-a-textbook">Do I need to buy a textbook?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#why-is-there-no-textbook">Why is there no textbook?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#do-i-need-a-computer-to-participate-in-this-class">Do I need a computer to participate in this class?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#representative-bibliography">Representative Bibliography</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#where-is-the-official-iu-calendar-for-the-fall">Where is the official IU calendar for the Fall?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-to-write-a-research-article-on-computer-science">How to write a research article on computer science?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#which-bibliography-manager-is-required-for-the-class">Which bibliography manager is required for the class?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#can-i-use-endnote-or-other-bibliography-managers">Can I use endnote or other bibliography managers?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#plagiarism-test-and-resources-related-to-that">Plagiarism test and resources related to that</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-many-hours-will-this-course-take-to-work-on-every-week">How many hours will this course take to work on every week?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#is-all-classes-material-final">Is all classes material final?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-are-the-changes-to-the-web-page">What are the changes to the web page?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-lectures-should-i-learn-when">What lectures should I learn when?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i524-why-are-you-doing-the-papers">I524: Why are you doing the papers?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i524-why-are-there-no-homework-to-test-me-on-skills-such-as-ansible-or-python">I524: Why are there no homework to test me on skills such as ansible or python?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i524-why-not-use-chef-or-another-devops-framework">I524: Why not use chef or another DevOps framework?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i-am-lost">I am lost?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i-do-not-like-technology-topic-project-etc">I do not like Technology/Topic/Project/etc?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i-am-not-able-to-attend-the-online-hours">I am not able to attend the online hours</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#do-i-need-to-attend-the-online-sessions">Do I need to attend the online sessions?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-are-the-leaning-outcomes">What are the leaning outcomes?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#there-are-so-many-messages-on-piazza-i-can-not-keep-up">There are so many messages on Piazza I can not keep up.</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i-find-the-hosting-web-confusing">I find the hosting Web confusing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#i524-i-do-not-know-python-what-do-i-do">I524: I do not know python. What do I do?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-to-solve-merge-conflict-in-pull-request">How to solve merge conflict in Pull Request?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#building-cloudmesh-classes-in-local-machine">Building cloudmesh/classes in local machine</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-to-sole-merge-conflict-in-a-pull-request">How to sole Merge Conflict in a Pull Request?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#cheat-sheet-for-linux-commands">Cheat sheet for Linux commands</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#tips-techlist-1-homework">Tips: TechList.1 homework</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#techlist-1-and-paper-1-pagecount">Techlist 1 and Paper 1 : Pagecount</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#tips-to-install-virtualbox">Tips to Install Virtualbox</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#do-i-generate-the-ssh-key-on-ubuntu-vm">Do I generate the SSH key on Ubuntu VM ?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#ways-to-run-ubuntu-on-windows-10">Ways to run Ubuntu on Windows 10</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#don-t-use-anaconda">Don&#8217;t use Anaconda</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#using-ssh-key-for-git-push">Using SSH Key for Git Push</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#how-to-properly-research-a-bibtex-entry">How to properly research a bibtex entry</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-are-the-differnt-entry-types-and-fields">What are the differnt entry types and fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-is-the-nature-of-team-collaboration-on-papers">What is the nature of team collaboration on papers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-are-the-due-dates-for-assignments">What are the due dates for assignments</a></li>
<li class="toctree-l2"><a class="reference internal" href="../faq.html#what-are-good-places-to-find-refernce-entries">What are good places to find refernce entries?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../todo.html">Todos</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../todo.html#general">General</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">Changelog</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#version-unreleased">%%version%% (unreleased)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#id1">3.0.9 (2017-01-30)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#id2">3.0.8 (2017-01-22)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#id6">3.0.7 (2017-01-20)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#id11">3.0.6 (2017-01-11)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#id14">3.0.5 (2017-01-11)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#id19">3.0.4 (2017-01-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#id20">3.0.3 (2017-01-09)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#id23">3.0.2 (2017-01-07)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#id24">3.0.1 (2017-01-06)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#id25">3.0 (2017-01-06)</a></li>
</ul>
</li>
</ul>
</ul>
</li><ul>
<li><a class="reference internal" href="#">Technologies</a><ul>
<li><a class="reference internal" href="#workflow-orchestration">Workflow-Orchestration</a></li>
<li><a class="reference internal" href="#application-and-analytics">Application and Analytics</a></li>
<li><a class="reference internal" href="#application-hosting-frameworks">Application Hosting Frameworks</a></li>
<li><a class="reference internal" href="#high-level-programming">High level Programming</a></li>
<li><a class="reference internal" href="#streams">Streams</a></li>
<li><a class="reference internal" href="#basic-programming-model-and-runtime-spmd-mapreduce">Basic Programming model and runtime, SPMD, MapReduce</a></li>
<li><a class="reference internal" href="#inter-process-communication-collectives">Inter process communication Collectives</a></li>
<li><a class="reference internal" href="#in-memory-databases-caches">In-memory databases/caches</a></li>
<li><a class="reference internal" href="#object-relational-mapping">Object-relational mapping</a></li>
<li><a class="reference internal" href="#extraction-tools">Extraction Tools</a></li>
<li><a class="reference internal" href="#sql-newsql">SQL(NewSQL)</a></li>
<li><a class="reference internal" href="#nosql">NoSQL</a></li>
<li><a class="reference internal" href="#file-management">File management</a></li>
<li><a class="reference internal" href="#data-transport">Data Transport</a></li>
<li><a class="reference internal" href="#cluster-resource-management">Cluster Resource Management</a></li>
<li><a class="reference internal" href="#file-systems">File systems</a></li>
<li><a class="reference internal" href="#interoperability">Interoperability</a></li>
<li><a class="reference internal" href="#devops">DevOps</a></li>
<li><a class="reference internal" href="#iaas-management-from-hpc-to-hypervisors">IaaS Management from HPC to hypervisors</a></li>
<li><a class="reference internal" href="#cross-cutting-functions">Cross-Cutting Functions</a><ul>
<li><a class="reference internal" href="#monitoring">Monitoring</a></li>
<li><a class="reference internal" href="#security-privacy">Security &amp; Privacy</a></li>
<li><a class="reference internal" href="#distributed-coordination">Distributed Coordination</a></li>
<li><a class="reference internal" href="#message-and-data-protocols">Message and Data Protocols</a></li>
</ul>
</li>
<li><a class="reference internal" href="#new-technologies-to-be-integrated">New Technologies to be integrated</a></li>
<li><a class="reference internal" href="#excersise">Excersise</a></li>
<li><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>
<p></p>
<hr>
<small>
<b>Links</b>
<ul>
  <li><a href="https://cloudmesh.github.io/classes/faq.html">FAQ</a> </li>  
  <li><a href="https://cloudmesh.github.io/classes/i524/index.html#online-meetings">Meetings</a> </li>
  <li><a
  href="https://iu.instructure.com/courses/1603897/assignments/syllabus">Zoom</a>
  <li> <a href="https://cloudmesh.github.io/classes/i524/technologies.html#excersise">HW Techlist.1</a>
  </li>
  <li> <a href="https://cloudmesh.github.io/classes/i524/paper1-hw.html#paper-1-homework">HW Paper.1</a>
  </li>
  <li> <a href="https://cloudmesh.github.io/classes/i524/calendar.html#i524-calendar">Calendar</a>
  </li>
  <li> <a href="https://cloudmesh.github.io/classes/"> <img src="https://cloudmesh.github.io/classes/_static/html.jpg" width="40" height="40" alt="pdf"> Web Page</a>
  </li>
  <li>
    <a href="https://cloudmesh.github.io/classes/i524-notes.pdf">
       <img src="https://cloudmesh.github.io/classes/_static/pdf.png" width="40" height="40" alt="pdf"> (Incomplete)</a>
  </li>
</ul>
</small>

<p></p>
<hr>
<form action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
        </div>
      </div>
    <div class="col-md-9 content">
      
  <div class="section" id="technologies">
<span id="index-0"></span><h1>Technologies<a class="headerlink" href="#technologies" title="Permalink to this headline"></a></h1>
<p>In this section we find a number of technologies that are related to
big data. Certainly a number of these projects are hosted as an Apache
project. One important resource for a general list of all apache
projects is at</p>
<ul class="simple">
<li>Apache projects: <a class="reference external" href="https://projects.apache.org/projects.html?category">https://projects.apache.org/projects.html?category</a></li>
</ul>
<div class="section" id="workflow-orchestration">
<h2>Workflow-Orchestration<a class="headerlink" href="#workflow-orchestration" title="Permalink to this headline"></a></h2>
<ol class="arabic">
<li><p class="first">ODE</p>
</li>
<li><p class="first">ActiveBPEL</p>
</li>
<li><p class="first">Airavata</p>
</li>
<li><p class="first">Pegasus</p>
</li>
<li><p class="first">Kepler</p>
</li>
<li><p class="first">Swift</p>
</li>
<li><p class="first">Taverna</p>
<p>Taverna is workflow management system. According to
<a class="reference internal" href="#www-taverna" id="id1">[1]</a>, Taverna is transitioning to Apache Incubator
as of Jan 2017.  Taverna suite includes 2 products:</p>
<p>(1). Taverna Workbench is desktop client where user can define the workflow.
(2). Taverna Server is responsible for executing the remote workflows.</p>
<p>Taverna workflows can also be executed on command-line.  Taverna
supports wide range of services including WSDL-style and RESTful
Web Services, BioMart, SoapLab, R, and Excel. Taverna also support
mechanism to monitor the running workflows using its web browser
interface.  In the <a class="reference internal" href="#taverna-paper" id="id2">[2]</a> paper, the formal syntax and
operational semantics of Taverna is explained.</p>
</li>
<li><p class="first">Triana</p>
</li>
<li><p class="first">Trident</p>
<p>In <a class="reference internal" href="#www-trident-tutorial" id="id3">[3]</a>, it is explained that Apache Trident
is a &#8220;high-level abstraction for doing realtime computing on top of
[Apache] Storm.&#8221; Similarly to Apache Storm, Apache Trident was
developed by Twitter. Furthermore, <a class="reference internal" href="#www-trident-tutorial" id="id4">[3]</a>
introduces Trident as a tool that &#8220;allows you to seamlessly intermix
high throughput (millions of messages per second), stateful stream
processing with low latency distributed querying.&#8221; In
<a class="reference internal" href="#www-trident-overview" id="id5">[4]</a>, the five kinds of operations in
Trident are described as &#8220;Operations that apply locally to each
partition and cause no network transfer&#8221;, &#8220;repartitioning operations
that repartition a stream but otherwise don&#8217;t change the contents
(involves network transfer)&#8221;, &#8220;aggregation operations that do
network transfer as part of the operation&#8221;, &#8220;operations on grouped
streams&#8221; and &#8220;merges and joins.&#8221; In <a class="reference internal" href="#www-trident-tutorial" id="id6">[3]</a>,
these five kinds of operations (i.e. joins, aggregations, grouping,
functions, and filters) and the general concepts of Apache Trident
are described as similar to &#8220;high level batch processing tools like
Pig or Cascading.&#8221;</p>
</li>
<li><p class="first">BioKepler</p>
<p>BioKepler is a Kepler module of scientific workflow components to
execute a set of bioinformatics tools using distributed execution
patterns <a class="reference internal" href="#www-biokepler" id="id7">[5]</a>. It contains a specialized set of
actors called bioActors for running bioinformatic tools,
directors providing distributed data-parallel(DPP) execution on
Big Data platforms such as Hadoop and Spark they are also
configurable and reusable <a class="reference internal" href="#www-biokepler-demos" id="id8">[6]</a>. BioKepler
contains over 40 example workflows that demonstrate the actors and
directors <a class="reference internal" href="#bioactors" id="id9">[7]</a>.</p>
</li>
<li><p class="first">Galaxy</p>
</li>
<li><p class="first">IPython</p>
</li>
<li><p class="first">Jupyter</p>
</li>
<li><p class="first">(Dryad)</p>
</li>
<li><p class="first">Naiad</p>
</li>
<li><p class="first">Oozie</p>
</li>
<li><p class="first">Tez</p>
</li>
<li><p class="first">Google FlumeJava</p>
</li>
<li><p class="first">Crunch</p>
</li>
<li><p class="first">Cascading</p>
<p><a class="reference internal" href="#www-cascading" id="id10">[8]</a> Cascading software authored by Chris Wensel
is development platform for building the application in Hadoop.
It basically act as an abstraction for Apache Hadoop used for
creating complex data processing workflow using the scalability of
hadoop however hiding the complexity of mapReduce jobs.  User can
write their program in java without having knowledge of
mapReduce. Applications written on cascading are portable.</p>
<p>Cascading Benefits
1. With Cascading application can be scaled as per the data sets.
2. Easily Portable
3. Single jar file for application deployment.</p>
</li>
<li><p class="first">Scalding</p>
</li>
<li><p class="first">e-Science Central</p>
<p>In <a class="reference internal" href="#e-science-central-paper-2010" id="id11">[9]</a>, it is explained
that e-Science Central is designed to address some of the
pitfalls within current Infrastructure as a Service (e.g.
Amazon EC2) and Platform as a Service (e.g. force.com)
services. For instance, in
<a class="reference internal" href="#e-science-central-paper-2010" id="id12">[9]</a>, the &#8220;majority of
potential scientific users, access to raw hardware is of
little use as they lack the skills and resources needed to
design, develop and maintain the robust, scalable
applications they require&#8221; and furthermore &#8220;current
platforms focus on services required for business
applications, rather than those needed for scientific
data storage and analysis.&#8221; In
<a class="reference internal" href="#www-e-science-central" id="id13">[10]</a>, it is explained that
e-Science Central is a &#8220;cloud based platform for
data analysis&#8221; which is &#8220;portable and can be run on
Amazon AWS, Windows Azure or your own hardware.&#8221; In
<a class="reference internal" href="#e-science-central-paper-2010" id="id14">[9]</a>, e-Science Central
is further described  as a platform, which &#8220;provides
both Software and Platform as a Service for scientific
data management, analysis and collaboration.&#8221; This
collaborative platform is designed to be scalable while
also maintaining ease of use for scientists. In
<a class="reference internal" href="#e-science-central-paper-2010" id="id15">[9]</a>, &#8220;a project
consisting of chemical modeling by cancer researchers&#8221;
demonstrates how e-Science Central &#8220;allows scientists to
upload data, edit and run workflows, and share results in
the cloud.&#8221;</p>
</li>
<li><p class="first">Azure Data Factory</p>
</li>
<li><p class="first">Google Cloud Dataflow</p>
<p>Google Cloud Dataflow is a unified programming model and a managed
service for developing and executing a wide variety of data processing
patterns (pipelines). Dataflow includes SDKs for defining data
processing workflows and a Cloud platform managed services to run
those workflows on a Google cloud platform resources such as Compute
Engine, BigQuery amongst others <a class="reference internal" href="#www-dataflow" id="id16">[11]</a>. Dataflow
pipelines can operate in both batch and streaming mode. The platform
resources are provided on demand, allowing users to scale to meet
their requirements, its also optimized to help balance lagging work
dynamically.</p>
<p>Being a cloud offering, Dataflow is designed to allow users to focus
on devising proper analysis without worrying about the installation
and maintaining <a class="reference internal" href="#www-googlelivestream" id="id17">[12]</a> the underlying data
piping and process infrastructure.</p>
</li>
<li><p class="first">NiFi (NSA)</p>
</li>
<li><p class="first">Jitterbit</p>
</li>
<li><p class="first">Talend</p>
</li>
<li><p class="first">Pentaho</p>
</li>
<li><p class="first">Apatar</p>
</li>
<li><p class="first">Docker Compose</p>
</li>
<li><p class="first">KeystoneML</p>
</li>
</ol>
</div>
<div class="section" id="application-and-analytics">
<h2>Application and Analytics<a class="headerlink" href="#application-and-analytics" title="Permalink to this headline"></a></h2>
<ol class="arabic" start="32">
<li><p class="first">Mahout <a class="reference internal" href="#www-mahout" id="id18">[13]</a></p>
<p>&#8220;Apache Mahout software provides three major features:
(1) A simple and extensible programming environment and framework
for building scalable algorithms
(2) A wide variety of premade algorithms for Scala + Apache Spark,
H2O, Apache Flink
(3) Samsara, a vector math experimentation environment with R-like
syntax which works at scale&#8221;</p>
</li>
<li><p class="first">MLlib</p>
</li>
<li><p class="first">Mbase</p>
</li>
<li><p class="first">DataFu</p>
<p>The Apache DataFu project was created out of the need for stable,
well-tested libraries for large scale data processing in Hadoop.
As detailed in <a class="reference internal" href="#www-datafu" id="id19">[14]</a> Apache DatFu consists of two
libraries Apache DataFu Pig and Apache DataFu Hourglass.  Apache
DataFu Pig is a collection of useful user-defined functions for
data analysis in Apache Pig. The functions are in areas of
Statistics, Bag Operations, Set Operations, Sessions, Sampling,
Estimation, Hashing and Link Analysis.  Apache DataFu Hourglass is
a library for incrementally processing data using Hadoop
MapReduce. It is designed to make computations over sliding windows
more efficient. For these types of computations, the input data is
partitioned in some way, usually according to time, and the range
of input data to process is adjusted as new data arrives.
Hourglass works with input data that is partitioned by day, as
this is a common scheme for partitioning temporal data.</p>
</li>
<li><p class="first">R</p>
<p><a class="reference internal" href="#www-r" id="id20">[15]</a> R, a GNU project, is a successor to S - a
statistical programming language. It offers a range of
capabilities  programming language, high level graphics,
interfaces to other languages and debugging. &#8220;R is an integrated
suite of software facilities for data manipulation, calculation
and graphical display&#8221;. The statistical and graphical techniques
provided by R make it popular in the statistical community. The
statistical techniques provided include linear and nonlinear
modelling, classical statistical tests, time-series analysis,
classification and clustering to name a few. <a class="reference internal" href="#book-r" id="id21">[16]</a> The
number of packages available in R has made it popular for use in
machine learning, visualization, and data operations tasks like
data extraction, cleaning, loading, transformation, analysis,
modeling and visualization. It&#8217;s strength lies in analyzing data
using its rich library but falls short when working with very
large datasets.</p>
</li>
<li><p class="first">pbdR</p>
<p>Programming with Big Data in R (pbdR) <a class="reference internal" href="#www-pbdr" id="id22">[17]</a> is an
environment having series of R packages for statistical computing
with Big Data using high-performance statistical computation. It
uses R, a popular language between statisticians and data
miners. &#8220;pbdR&#8221; focuses on distributed memory system, where data is
distributed accross several machines and processed in batch
mode. It uses MPI for inter process communications. R focuses on
single machines for data analysis using a interactive
GUI. Currenly there are two implementation of pbdR, one Rmpi and
another being pdbMpi.  Rmpi uses SPMD parallelism while pbdRMpi
uses manager/worker parallelism.</p>
</li>
<li><p class="first">Bioconductor</p>
</li>
<li><p class="first">ImageJ</p>
</li>
<li><p class="first">OpenCV</p>
</li>
<li><p class="first">Scalapack</p>
</li>
<li><p class="first">PetSc</p>
</li>
<li><p class="first">PLASMA MAGMA</p>
</li>
<li><p class="first">Azure Machine Learning</p>
<p>Azure Machine Learning is a cloud based service that can be used
to do predictive analytics, machine learning or data mining. It
has features like in-built algorithm library, machine learning
studio and a webservice <a class="reference internal" href="#www-azuremlsite" id="id23">[18]</a>. In built
algorithm library has implementation of various popular machine
learning algorithms like decision tree, SVM, linear regression,
neural networks etc. Machine learning studio facilitates creation
of predictive models using graphical user interface by dragging,
dropping and connecting of different modules that can be used by
people with minimal knowledge in the machine learning
field. Machine learning studio is a free service for basic version
and comes with a monthly charge for advanced versions. Apart from
building models, studio also has options to do preprocessing like
clean, transform and normalize the data. Webservice provides
option to deploy the machine learning algorithm as ready to
consume APIs that can be reused in future with minimal effort and
can also be published.</p>
</li>
<li><p class="first">Google Prediction API &amp; Translation API</p>
<p>Google Prediction API &amp; Translation API are part of Cloud ML API
family with specific roles. Below is a description of each and
their use.</p>
<p>Google Prediction API provides pattern-matching and machine
learning capabilities. Built on HTTP and JSON, the prediction API
uses training data to learn and consecutively use what has been
learned to predict a numeric value or choose a category that
describes new pieces of data. This makes it easier for any
standard HTTP client to send requests to it and parse the
responses. The API can be used to predict what users might like,
categorize emails as spam or non-spam, assess whether posted
comments sentiments are positive or negative or how much a user
may spend in a day. Prediction API has a 6 month limited free
trial or a paid use for $10 per project which offers up to 10,000
predictions a day <a class="reference internal" href="#www-prediction" id="id24">[19]</a>.</p>
<p>Google Translation API is a simple programmatic interface for
translating an arbitrary string into any supported
language. Google Translation API is highly responsive allowing
websites and applications to integrate for fast dynamic
translation of source text from source language to a target
language. Translation API also automatically identifies and
translate languages with a high accuracy from over a hundred
different languages.  Google Translation API is charged at $20 per
million characters making it an affordable localization
solution. Translation API is also distributed in two editions,
premium edition which is tailored for users with precise long-form
translation services like livestream, high volumes of emails or
detailed articles and documents. Theres also standard edition
which is tailored for short, real-time
conversations <a class="reference internal" href="#www-translation" id="id25">[20]</a>.</p>
</li>
<li><p class="first">mlpy</p>
</li>
<li><p class="first">scikit-learn</p>
</li>
<li><p class="first">PyBrain</p>
</li>
<li><p class="first">CompLearn</p>
</li>
<li><p class="first">DAAL(Intel)</p>
</li>
<li><p class="first">Caffe</p>
<p>Caffe is a deep learning framework made with three terms namely
expression, speed and modularity <a class="reference internal" href="#www-caffe" id="id26">[21]</a>. Using Expressive
architecture, switching between CPU and GPU by setting a single
flag to train on a GPU machine then deploy to commodity cluster or
mobile devices.Here the concept of configuration file will comes
without hard coding the values . Switching between CPU and GPU can
be done by setting a flag to train on a GPU machine then deploy to
commodity clusters or mobile devices.</p>
<p>It can process over 60 million images per day with a single NVIIA
k40 GPU It is being used bu academic research projects, startup
prototypes, and even large-scale industrial applications in vision,
speech, and multimedia.</p>
</li>
<li><p class="first">Torch</p>
<p>Torch is a open source machine learning library, a scientific
computing framework <a class="reference internal" href="#www-torch" id="id27">[22]</a> .It implements LuaJIT
programming language and implements C/CUDA. It implements
N-dimensional array. It does routines of indexing, slicing,
transposing etc. It has in interface to C language via scripting
language LuaJIT. It supports different artificial intelligence
models like neural network and energy based models. It is
compatible with GPU.  The core package of is torch. It provides
a flexible N dimensional array which supports basic routings. It
has been used to build hardware implementation for data flows like
those found in neural networks.</p>
</li>
<li><p class="first">Theano</p>
</li>
<li><p class="first">DL4j</p>
<p>DL4j stands for Deeplearning4j. <a class="reference internal" href="#www-dl4j" id="id28">[23]</a> It is a deep
learning programming library written for Java and the Java virtual
machine (JVM) and a computing framework with wide support for deep
learning algorithms. Deeplearning4j includes implementations of
the restricted Boltzmann machine, deep belief net, deep
autoencoder, stacked denoising autoencoder and recursive neural
tensor network, word2vec, doc2vec, and GloVe. These algorithms all
include distributed parallel versions that integrate with Apache
Hadoop and Spark. It is a open-source software released under
Apache License 2.0.</p>
<p>Training with Deeplearning4j occurs in a cluster. Neural nets are
trained in parallel via iterative reduce, which works on
Hadoop-YARN and on Spark. Deeplearning4j also integrates with CUDA
kernels to conduct pure GPU operations, and works with distributed
GPUs.</p>
</li>
<li><p class="first">H2O</p>
</li>
<li><p class="first">IBM Watson</p>
<p>IBM Watson <a class="reference internal" href="#www-ibmwatson-wiki" id="id29">[24]</a> is a super computer built on
cognitive technology that processes information like the way human
brain does by understanding the data in a natural language as well
as analyzing structured and unstructured data. It was initially
developed as a question and answer tool more specifically to
answer questions on the quiz show &#8220;Jeopardy&#8221; but now it has been
seen as helping doctors and nurses in the treatment of cancer. It
was developed by IBM&#8217;s DeepQA research team led by David
Ferrucci. <a class="reference internal" href="#www-ibmwatson" id="id30">[25]</a> illustrates that with Watson you
can create bots that can engage in conversation with you. You can
even provide personalized recommendations to Watson by
understanding a user&#8217;s personality, tone and emotion. Watson uses
the Apache Hadoop framework in order to process the large volume
of data needed to generate an answer by creating in-memory
datasets used at run-time. Watson&#8217;s DeepQA UIMA (Unstructured
Information Management Architecture) annotators were deployed as
mappers in the Hadoop Map-Reduce framework. Watson is written in
multiple programming languages like Java, C++, Prolog and it runs
on the SUSE Linux Enterprise Server. <a class="reference internal" href="#www-ibmwatson" id="id31">[25]</a>
mentions that today Watson is available as a set of open source
APIs and Software As a Service product as well.</p>
</li>
<li><p class="first">Oracle PGX</p>
</li>
<li><p class="first">GraphLab</p>
<p>GraphLab <a class="reference internal" href="#www-graphlab" id="id32">[26]</a> is a graph-based, distributed computation,
high performance framework for machine learning written in C++. It
is an open source project started by Prof. Carlos Guestrin of
Carnegie Mellon University in 2009, designed considering the
scale, variety and complexity of real world data. It integrates
various high level algorithms such as Stochastic Gradient Descent,
Gradient Descent &amp; Locking and provides high performance
experience. It includes scalable machine learning toolkits which
has implementation for deep learning, factor machines, topic
modeling, clustering, nearest neighbors and almost everything
required to enhance machine learning models. This framework is
targeted for sparse iterative graph algorithms. It helps data
scientists and developers easily create and install applications
at large scale.</p>
</li>
<li><p class="first">GraphX</p>
<p>GraphX is Apache Spark&#8217;s API for graph and graph-parallel computation.
<a class="reference internal" href="#www-graphx" id="id33">[27]</a></p>
<p>GraphX provides:</p>
<p>Flexibility: It seamlessly works with both graphs and collections. GraphX
unifies ETL, exploratory analysis, and iterative graph computation within a
single system. You can view the same data as both graphs and collections,
transform and join graphs with RDDs efficiently, and write custom iterative
graph algorithms using the Pregel API.</p>
<p>Speed: Its performance is comparable to the fastest specialized graph
processing systems while retaining Apache Spark&#8217;s flexibility, fault
tolerance, and ease of use.</p>
<p>Algorithms: GraphX comes with a variety of algorithms such as PageRank,
Connected Components, Label propagations, SVD++, Strongly connected
components and Triangle Count.</p>
<p>It combines the advantages of both data-parallel and graph-parallel systems
by efficiently expressing graph computataion within the Spark data-parallel
framework. <a class="reference internal" href="#www-graphx1" id="id34">[28]</a></p>
<p>It gets developed as a part of Apache Spark project. It thus gets tested and
updated with each Spark release.</p>
</li>
<li><p class="first">IBM System G</p>
</li>
<li><p class="first">GraphBuilder(Intel)</p>
</li>
<li><p class="first">TinkerPop</p>
<p>ThinkerPop is a graph computing framework from Apache software
foundation. :cite :<cite>www-ApacheTinkerPop</cite> Before coming under the
Apache project, ThinkerPop was a stack of technologies like
Blueprint, Pipes, Frames, Rexters, Furnace and Gremlin where each
part was supporting graph-based application development. Now all
parts are come under single TinkerPop project
repo. <a class="reference internal" href="#www-news" id="id35">[29]</a> It uses Gremlin, a graph traversal machine
and language. It allows user to write complex queries (traversal),
that can use for real-time transactional (OLTP) queries, graph
analytic system (OLAP) or combination of both as in
hybrid. Gremlin is written in
java. <a class="reference internal" href="#www-apachetinkerpophome" id="id36">[30]</a> TinkerPop has an ability to
create a graph in any size or complexity. Gremlin engine allows
user to write graph traversal in Gremlin language, Python,
JavaScript, Scala, Go, SQL and SPARQL. It is capable to adhere
with small graph which requires a single machine or massive graphs
that can only be possible with large cluster of machines, without
changing the code.</p>
</li>
<li><p class="first">Parasol</p>
</li>
<li><p class="first">Dream:Lab</p>
<p>DREAM:Lab stands for Distributed Research on Emerging
Applications and Machines Lab. <a class="reference internal" href="#dream" id="id37">[31]</a> DREAM:Lab is centered
around distributed systems research to enable expeditious
utilization of distributed data and computing systems. <a class="reference internal" href="#dream" id="id38">[31]</a>
DREAM:Lab utilizes the capabilities of hundereds of personal
computers to allow access to supercomputing resources to average
individuals. <a class="reference internal" href="#rao" id="id39">[32]</a> The DREAM:Lab pursues this goal by utilizing
distributed computing. <a class="reference internal" href="#rao" id="id40">[32]</a> Distributed computing consists of
independent computing resources that communicate with each other
over a network. <a class="reference internal" href="#denero" id="id41">[33]</a> A large, complex computing problem is
broken down into smaller, more manageable tasks and then these
tasks are distributed to the various components of the distributed
computing system. <a class="reference internal" href="#denero" id="id42">[33]</a></p>
</li>
<li><p class="first">Google Fusion Tables</p>
<p>Fusion Tables is a cloud based services, provided by Google for
data management and integration. Fusion Tables allow users to
upload the data in tabular format using data files like
spreadsheet, CSV, KML, .tsv up to
250MB. <a class="reference internal" href="#www-fusiontablesupport" id="id43">[34]</a> It used for data management,
visualizing data (e.g. pie-charts, bar-charts, lineplot,
scatterplot, timelines) <a class="reference internal" href="#wiki-fusiontable" id="id44">[35]</a> , sharing of
tables, filter and aggregation the data. It allows user to take
the data privately, within controlled collaborative group or in
public. It allows to integrate the data from different tables from
different users or tables.Fusion Table uses two-layer storage,
Bigtable and Magastore. The information rows are stored in bigdata
table called Rows, user can merge the multiple table in to one,
from multiple users. Megastore is a library on top of
bigtable. <a class="reference internal" href="#googlefusiontable2012" id="id45">[36]</a> Data visualization is one
the feature, where user can see the visual representation of their
data as soon as they upload it. User can store the data along with
geospatial information as well.</p>
</li>
<li><p class="first">CINET</p>
</li>
<li><p class="first">NWB</p>
<blockquote>
<div><p><a class="reference internal" href="#www-nwb-edu" id="id46">[37]</a> NWB stands for Network workbench is analysis, modelling and visualization toolkit for the network scientists.
It provides an environment which help scientist researchers and practitioner to get online access to the shared resource
environment and network datasets for analysis, modelling and visualization of large scale networking application.
User can access this network datasets and algorithms previously obtained by doing lot of research and can also add their own
datasets helps in speeding up the process and saving the time for redoing the same analysis.</p>
<p>NWB provides advanced tools for users to understand and interact with different types of networks.
NWB members are largely the computer scientist, biologist, engineers, social and behavioural scientist. The platform
helps the specialist researchers to transfer the knowledge within the broader scientific and research communities.</p>
</div></blockquote>
</li>
<li><p class="first">Elasticsearch</p>
<p>Elasticsearch <a class="reference internal" href="#www-elasticsearch" id="id47">[38]</a> is a real time
distributed, RESTful search and analytics engine which is capable
of performing full text search operations for you. It is not just
limited to full text search operations but it also allows you to
analyze your data, perform CRUD operations on data, do basic text
analysis including tokenization and
filtering. <a class="reference internal" href="#www-elasticsearch-intro" id="id48">[39]</a> For example while
developing an E-commerce website, Elasticsearch can be used to
store the entire product catalog and inventory and can be used to
provide search and autocomplete suggestions for the
products. Elasticsearch is developed in Java and is an open source
search engine which uses standard RESTful APIs and JSON on
top of Apache&#8217;s Lucene - which is a full text search engine
library. Clinton Gormley &amp; Zachary Tong <a class="reference internal" href="#elasticsearch-book" id="id49">[40]</a>
describes elastic search as &#8220;A distributed real time document
store where every field is indexed and searchable&#8221;. They also
mention that &#8220;Elastic search is capable of scaling to hundreds of
servers and petabytes of structured and unstructured
data&#8221;. <a class="reference internal" href="#www-elasticsearch-hadoop" id="id50">[41]</a> mentions that Elastic
search can be used on big data by using the Elasticsearch-Hadoop
(ES-Hadoop) connector. ES-Hadoop connector lets you index the
Hadoop data into the Elastic Stack to take full advantage of the
Elasticsearch engine and returns output through Kibana
visualizations. <a class="reference internal" href="#www-wikipedia-elasticsearch" id="id51">[42]</a> A log parsing
engine &#8220;Logstash&#8221; and analytics and visualization platform
&#8220;Kibana&#8221; are also developed alongside Elasticsearch forming a
single package.</p>
</li>
<li><p class="first">Kibana</p>
</li>
<li><p class="first">Logstash</p>
<p>Logstash is an open source data collection engine with real-time
pipelining capabilities. Logstash can dynamically unify data from
disparate sources and normalize the data into destinations of your
choice. <a class="reference internal" href="#www-logstash" id="id52">[43]</a> Cleanse and democratize all your data
for diverse advanced downstream analytics and visualization use
cases.</p>
<p>While Logstash originally drove innovation in log collection, its
capabilities extend well beyond that use case. Any type of event
can be enriched and transformed with a broad array of input,
filter, and output plugins, with many native codecs further
simplifying the ingestion process. Logstash accelerates your
insights by harnessing a greater volume and variety of data.</p>
</li>
<li><p class="first">Graylog</p>
</li>
<li><p class="first">Splunk</p>
</li>
<li><p class="first">Tableau</p>
</li>
<li><p class="first">D3.js</p>
</li>
<li><p class="first">three.js</p>
</li>
<li><p class="first">Potree</p>
</li>
<li><p class="first">DC.js</p>
<p>According to <a class="reference internal" href="#www-dcjs" id="id53">[44]</a>: DC.js&nbsp;is a javascript charting
library with native&nbsp;crossfilter&nbsp;support, allowing exploration on
large multi-dimensional datasets. It uses d3&nbsp;to render charts in
CSS-friendly SVG format. Charts rendered using dc.js are data
driven and reactive and therefore provide instant feedback to user
interaction. DC.js library can be used to perform data anlysis
on both mobile devices and different browsers. Under the dc
namespace the following chart classes are included: barChart,
boxplot, bubbleChart, bubbleOverlay, compositeChart, dataCount,
dataGrid, dataTable, geoChoroplethChart, heatMap,
legend,lineChart, numberDisplay, pieChart, rowChart, scatterPlot,
selectMenu and seriesChart.</p>
</li>
<li><p class="first">TensorFlow</p>
</li>
<li><p class="first">CNTK</p>
</li>
</ol>
</div>
<div class="section" id="application-hosting-frameworks">
<h2>Application Hosting Frameworks<a class="headerlink" href="#application-hosting-frameworks" title="Permalink to this headline"></a></h2>
<ol class="arabic" start="80">
<li><p class="first">Google App Engine  <a class="reference internal" href="#www-gae" id="id54">[45]</a></p>
<p>On purpose we put in here a &#8220;good&#8221; example of a bad entry that woudl
receive 10 out of 100 points, e.g. an F:</p>
<p>&#8220;Google App Engine&#8221; provides platform as a service.
There are major advantages from this framework:</p>
<ol class="arabic simple">
<li>Scalable Applications</li>
<li>Easier to maintain</li>
<li>Publishing services easily</li>
</ol>
<p>Reasons: (a) &#8220;major advantages is advertisement&#8221; if you add word
major (b) grammar needs to be improved (c) the three points do not
realy say anything about Google App Engine (d) the reader will
after reading this have not much information about what it is (e)
a refernce is not included. (f) enumeration should be in this page
avoided. We like to see a number of paragraphs with text.</p>
<p><strong>Note: This is an example for a bad entry</strong></p>
</li>
<li><p class="first">AppScale</p>
<p>AppScale is an application hosting platform. This platform helps
to deploy and scale the unmodified Google App Engine application,
which run the application on any cloud infrastructure in public,
private and on premise cluster. <a class="reference internal" href="#www-appscale" id="id55">[46]</a> AppScale
provide rapid, API development platform that can run on any cloud
infrastructure. The platform separates the app logic and its
service part to have control over application deployment, data
storage, resource use, backup and migration.  AppScale is based on
Googles App Engine APIs and has support for Python, Go, PHP and
Java applications. It supports single and multimode deployment,
which will help with large, dataset or CPU. AppScale allows to
deploy app in thee main mode i.e. dev/test, production and
customize deployment.  [www-apscale-deployment]</p>
</li>
<li><p class="first">Red Hat OpenShift</p>
</li>
<li><p class="first">Heroku</p>
</li>
<li><p class="first">Aerobatic</p>
<p>According to <a class="reference internal" href="#www-aero" id="id57">[47]</a>: Aerobatic is a platform that allows
hosting static websites. It used to be an ad-on for Bitbucket but
now Aerobatic is transitioning to standalone CLI(command Line
Tool) and web dashboard . Aerobatic allows automatic builds to
different branches. New changes to websites can be deployed using
aero deploy command which can be executed from local desktop or
any of CD tools and services like Jenkins, Codeship,Travis and so
on.  It also allows users to configure custom error pages and
offers authentication which can also be customized. Aerobatic is
backed by AWS cloud. Aerobatic has free plan and pro plan options
for customers.</p>
</li>
<li><p class="first">AWS Elastic Beanstalk</p>
</li>
<li><p class="first">Azure</p>
<p>Microsoft Corporation (MSFT) markets its cloud products under the
<em>Azure</em> brand name. At its most basic, Azure acts as an
<em>infrastructure- as-a-service</em> (IaaS) provider.  IaaS virtualizes
hardware components, a key differentiation from other
<em>-as-a-service</em> products. IaaS &#8220;abstract[s] the user from the
details of infrasctructure like physical computing resources,
location, data partitioning, scaling, security, backup, etc.&#8221;
<a class="reference internal" href="#www-wikipedia-cloud" id="id58">[48]</a></p>
<p>However, Azure offers a host of closely-related tool and products
to enhance and improve the core product, such as raw block
storage, load balancers, and IP addresses
<a class="reference internal" href="#www-azure-msft" id="id59">[49]</a>. For instance, Azure users can access
predictive analytics, Bots and Blockchain-as-a-Service
<a class="reference internal" href="#www-azure-msft" id="id60">[49]</a> as well as more-basic computing,
networking, storage, database and management components
<a class="reference internal" href="#www-sec-edgar-msft" id="id61">[50]</a>.  The Azure website shows twelve major
categories under <em>Products</em> and twenty <em>Solution</em> categories,
e.g., e-commerce or Business SaaS apps.</p>
<p>Azure competes against Amazon&#8217;s <em>Amazon Web Service</em>,
<a class="reference internal" href="#www-aws-amzn" id="id62">[51]</a> even though IBM (<em>SoftLayer</em>
<a class="reference internal" href="#www-softlayer-ibm" id="id63">[52]</a> and <em>Bluemix</em> <a class="reference internal" href="#www-bluemix-ibm" id="id64">[53]</a>)
and Google (<em>Google Cloud Platform</em>) <a class="reference internal" href="#www-cloud-google" id="id65">[54]</a>
offer IaaS to the market.  As of January 2017, Azure&#8217;s datacenters
span 32 Microsoft-defined <em>regions</em>, or 38 <em>declared regions</em>,
throughout the world. <a class="reference internal" href="#www-azure-msft" id="id66">[49]</a></p>
</li>
<li><p class="first">Cloud Foundry</p>
</li>
<li><p class="first">Pivotal</p>
</li>
<li><p class="first">IBM BlueMix</p>
</li>
<li><p class="first">(Ninefold)</p>
<p>The Australian based cloud computing platform has shut down their
services since January 30, 2016. Refer <a class="reference internal" href="#www-ninefoldsite" id="id67">[55]</a></p>
</li>
<li><p class="first">Jelastic</p>
</li>
<li><p class="first">Stackato</p>
</li>
<li><p class="first">appfog</p>
<p>According to <a class="reference internal" href="#wee" id="id68">[56]</a>, AppFog is a platform as a service (PaaS)
provider. Platform as a service provides a platform for the
development of web applications without the necessity of
purchasing the software and infrastructure that supports
it. <a class="reference internal" href="#kepes" id="id69">[57]</a> PaaS provides an environment for the creation of
software. <a class="reference internal" href="#kepes" id="id70">[57]</a> The underlying support infrastructure that AppFog
provides includes things such as runtime, middleware, o/s,
virtualization, servers, storage, and networking. <a class="reference internal" href="#appfog" id="id71">[58]</a> AppFog
is based on VMWares CloudFoundry project. <a class="reference internal" href="#wee" id="id72">[56]</a> It gets things
such as MySQL, Mongo, Reddis, memCache, etc. running and then
manages them. <a class="reference internal" href="#tweney" id="id73">[59]</a></p>
</li>
<li><p class="first">CloudBees</p>
</li>
<li><p class="first">Engine Yard</p>
</li>
<li><p class="first">(CloudControl)</p>
<p>No Longer active as of Feb. 2016 <a class="reference internal" href="#www-wiki" id="id74">[60]</a></p>
</li>
<li><p class="first">dotCloud</p>
<p>dotCloud services were shutdown on February 29,2016
<a class="reference internal" href="#www-dotcloud" id="id75">[61]</a></p>
</li>
<li><p class="first">Dokku</p>
</li>
<li><p class="first">OSGi</p>
</li>
<li><p class="first">HUBzero</p>
</li>
<li><p class="first">OODT</p>
</li>
<li><p class="first">Agave</p>
</li>
<li><p class="first">Atmosphere</p>
</li>
</ol>
</div>
<div class="section" id="high-level-programming">
<h2>High level Programming<a class="headerlink" href="#high-level-programming" title="Permalink to this headline"></a></h2>
<ol class="arabic" start="104">
<li><p class="first">Kite</p>
</li>
<li><p class="first">Hive</p>
</li>
<li><p class="first">HCatalog</p>
</li>
<li><p class="first">Tajo</p>
<p>Apache Tajo <a class="reference internal" href="#www-apache-tajo" id="id76">[62]</a> is a big data relational and
distributed data warehouse system for Apache&#8217;s Hadoop
framework. It uses the Hadoop Distributed File System (HDFS) as a
storage layer and has its own query execution engine instead of
the MapReduce framework. Tajo is designed to provide low-latency
and scalable ad-hoc queries, online aggregation, and ETL
(extraction-transformation-loading process) on large-data sets
which are stored on HDFS (Hadoop Distributed File System) and on
other data sources. <a class="reference internal" href="#www-tutorialspoint-tajo" id="id77">[63]</a> Apart from HDFS,
it also supports other storage formats as Amazon S3, Apache
HBase, Elasticsearch etc. It provides distributed SQL query
processing engine and even has query optimization techniques and
provides interactive anaysis on large-data sets. Tajo is
compatible with ANSI/ISO SQL standard, JDBC standard. Tajo can
also store data from various file formats such as CSV,
JSON,RCFile, SequenceFile, ORC and Parquet. It provides a SQL
shell which allows users to submit the SQL queries. It also
offers user defined functions to work with it which can be
created in python. A Tajo cluster has one master node and a
number of worker nodes. <a class="reference internal" href="#www-tutorialspoint-tajo" id="id78">[63]</a> The master
node is responsible for performing the query planning and
maintaining a coordination among the worker nodes. It does this
by dividing a query in small task which are assigned to the
workers who have a local query engine for executing the queries
assigned to them.</p>
</li>
<li><p class="first">Shark</p>
</li>
<li><p class="first">Phoenix</p>
<p>In the first quarter of 2013, Salesforce.com released its
proprietary SQL-like interface and query engine for HBase,
<em>Phoenix</em>, to the open source community.  The company appears to
have been motivated to develop Phoenix as a way to 1) increase
accessiblity to HBase by using the industry-standard query
language (SQL); 2) save users time by abstracting away the
complexities of coding native HBase queries; and, 3) implementing
query best practices by implementing them automatically via
Phoenix. <a class="reference internal" href="#www-phoenix-cloudera" id="id79">[64]</a> Although Salesforce.com
initially <em>open-sourced</em> it via Github, by May of 2014 it had
become a top-level Apache project. <a class="reference internal" href="#www-phoenix-wikipedia" id="id80">[65]</a></p>
<p>Phoenix, written in Java, &#8220;compiles [SQL queries] into a series
of HBase scans, and orchestrates the running of those scans to
produce regular JDBC result sets.&#8221; <a class="reference internal" href="#www-apachephoenix-org" id="id81">[66]</a>
In addition, the program directs compute intense portions of the
calls to the server.  For instance, if a user queried for the top
ten records across numerous regions from an HBase database
consisting of a billion records, the program would first select
the top ten records for each region using server-side compute
resources.  After that, the client would be tasked with selecting
the overall top ten. <a class="reference internal" href="#www-phoenix-salesforcedev" id="id82">[67]</a></p>
<p>Despite adding an abstraction layer, Phoenix can actually speed
up queries because it optimizes the query during the translation
process. <a class="reference internal" href="#www-phoenix-cloudera" id="id83">[64]</a> For example, &#8220;Phoenix
beats Hive for a simple query spanning 10M-100M rows.&#8221;
<a class="reference internal" href="#www-phoenix-infoq" id="id84">[68]</a></p>
<p>Finally, another program can enhance HBase&#8217;s accessibility for
those inclined towards graphical interfaces.  SQuirell only
requires the user to set up the JDBC driver and specify the
appropriate connection string. <a class="reference internal" href="#www-phoenix-bighadoop" id="id85">[69]</a></p>
</li>
<li><p class="first">Impala</p>
</li>
<li><p class="first">MRQL</p>
<p>MapReduce Query Language (MRQL, pronounced miracle) &#8220;is a query
processing and optimization system for large-scale, distributed
data analysis&#8221;. <a class="reference internal" href="#www-apachemrql" id="id86">[70]</a> MRQL provides a SQL
like language for use on Apache Hadoop, Hama, Spark, and Flink.
MRQL allows users to perform complex data analysis using only SQL
like queries, which are translated by MRQL to efficient Java
code. <a class="reference internal" href="#www-apachemrql" id="id87">[70]</a></p>
<p>MRQL was created in 2011 by Leaonids
Fegaras <a class="reference internal" href="#www-mrqlhadoop" id="id88">[71]</a> and is currently in the Apache
Incubator.  All projects accepted by the Apache Software
Foundation (ASF) undergo an incubation period until a review
indicates that the project meets the standards of other ASF
projects. <a class="reference internal" href="#www-apacheincubator" id="id89">[72]</a></p>
</li>
<li><p class="first">SAP HANA</p>
<p>As noted in <a class="reference internal" href="#www-sap-hana" id="id90">[73]</a>, SAP HANA is in-memory massively
distributed platform that consists of three components:
analytics, relational ACID compliant database and
application. Predictive analytics and machine learning
capabilities are dynamically allocated for searching and
processing of spatial, graphical, and text data.
SAP HANA accommodates flexible development and deployment of
data on premises, cloud and hybrid configurations.  In a
nutshell, SAP HANA acts as a warehouse that integrates live
transactional data from various data sources on a single
platform <a class="reference internal" href="#olofson-2014" id="id91">[74]</a>. It provides extensive
administrative, security features and data access that ensures
high data availability, data protection and data quality.</p>
</li>
<li><p class="first">HadoopDB</p>
</li>
<li><p class="first">PolyBase</p>
</li>
<li><p class="first">Pivotal HD/Hawq</p>
</li>
<li><p class="first">Presto</p>
<p>Presto <a class="reference internal" href="#www-presto" id="id92">[75]</a> is an open-source distributed SQL query
engine that supports interactive analytics on large datasets. It
allows interfacing with a variety of data sources such as Hive,
Cassandra, RDBMSs and proprietary data source. Presto is used at a
number of big-data companies such as Facebook, Airbnb and
Dropbox. Presto&#8217;s performance compares favorably to similar systems
such as Hive and Stinger <a class="reference internal" href="#presto-paper-2014" id="id93">[76]</a>.</p>
</li>
<li><p class="first">Google Dremel</p>
</li>
<li><p class="first">Google BigQuery</p>
</li>
<li><p class="first">Amazon Redshift</p>
</li>
<li><p class="first">Drill</p>
</li>
<li><p class="first">Kyoto Cabinet</p>
<p>Kyoto Cabinet as specified in <a class="reference internal" href="#www-kyotocabinet" id="id94">[77]</a> is a
library of routines for managing a database which is a simple
data file containing records. Each record in the database is a
pair of a key and a value. Every key and value is serial bytes
with variable length. Both binary data and character string can
be used as a key and a value. Each key must be unique within a
database.  There is neither concept of data tables nor data
types. Records are organized in hash table or B+ tree. Kyoto
Cabinet runs very fast. The elapsed time to store one million
records is 0.9 seconds for hash database, and 1.1 seconds for B+
tree database. Moreover, the size of database is very small. The,
overhead for a record is 16 bytes for hash database, and 4 bytes
for B+ tree database. Furthermore, scalability of Kyoto Cabinet
is great. The database size can be up to 8EB (9.22e18 bytes).</p>
</li>
<li><p class="first">Pig</p>
</li>
<li><p class="first">Sawzall</p>
<p>Google engineers created the domain-specific programming language
(DSL) <em>Sawzall</em> as a productivity enhancement tool for Google
employees.  They targeted the analysis of large data sets with
flat, but regular, structures spread across numerous servers.
The authors designed it to handle &#8220;simple, easily distributed
computations: filtering, aggregation, extraction of statistics,&#8221;
etc. from the aforementioned data sets.
<a class="reference internal" href="#google-sawzall" id="id95">[78]</a></p>
<p>In general terms, a Sawzall job works as follows: multiple
computers each create a Sawzall instance, perform some operation
on a single record out of (potentially) petabytes of data, return
the result to an aggregator function on a different computer and
then shut down the Sawzall instance.</p>
<p>The engineer&#8217;s focus on simplicity and parallelization led to
unconventional design choices.  For instance, in contrast to most
programming languages Sawzall operates on one data record at a
time; it does not even preserve state between records.
<a class="reference internal" href="#www-bytemining-sawzall" id="id96">[79]</a> Addtionally, the language provides
just a single primitive result function, the <em>emit</em> statement.
The emitter returns a value from the Sawzall program to a
designated virtual receptacle, generally some type of aggregator.
In another example of pursuing language simplicity and
parallelization, the aggregators remain separate from the formal
Sawzall language (they are written in C++) because &#8220;some of the
aggregation algorithms are sophisticated and best implemented in
a native language [and] [m]ore important[ly] drawing an explicit
line between filtering and aggregation enables a high degree of
parallelism, even though it hides the parallelism from the
language itself&#8221;.  <a class="reference internal" href="#google-sawzall" id="id97">[78]</a></p>
<p>Important components of the Sawzall language include: <em>szl</em>, the
binary containing the code compiler and byte-code interpreter
that executes the program; the <em>libszl</em> library, which compiles
and executes Sawzall programs &#8220;[w]hen szl is used as part of
another program, e.g. in a [map-reduce] program&#8221;; the Sawzall
language plugin, designated <em>protoc_gen_szl</em>, which generates
Sawzall code when run in conjunction with Google&#8217;s own <em>protoc</em>
protocol compiler; and libraries for intrinsic functions as well
as Sawzall&#8217;s associated aggregation functionality.
<a class="reference internal" href="#www-google-code-wiki-sawzall" id="id98">[80]</a></p>
</li>
<li><p class="first">Google Cloud DataFlow</p>
</li>
<li><p class="first">Summingbird</p>
</li>
<li><p class="first">Lumberyard</p>
</li>
</ol>
</div>
<div class="section" id="streams">
<h2>Streams<a class="headerlink" href="#streams" title="Permalink to this headline"></a></h2>
<ol class="arabic" start="127">
<li><p class="first">Storm</p>
</li>
<li><p class="first">S4</p>
</li>
<li><p class="first">Samza</p>
</li>
<li><p class="first">Granules</p>
</li>
<li><p class="first">Neptune</p>
</li>
<li><p class="first">Google MillWheel</p>
</li>
<li><p class="first">Amazon Kinesis</p>
<p>Kinesis is Amazons <a class="reference internal" href="#www-kinesis" id="id99">[81]</a> real time data processing
engine. It is designed to provide scalable, durable and reliable
data processing platform with low latency. The data to Kinesis
can be ingested from multiple sources in different format. This
data is further made available by Kinesis to multiple
applications or consumers interested in the data. Kinesis
provides robust and fault tolerant system to handle this high
volume of data. Data sharding mechanism is Kinesis makes it
horizontally scalable. Each of these shards in Kinesis process a
group of records which are partitioned by the shard key. Each
record processed by Kinesis is identified by sequence number,
partition key and data blob. Sequence number to records is
assigned by the stream. Partition keys are used by partitioner(a
hash function) to map the records to the shards i.e. which
records should go to which shard. Producers like web servers,
client applications, logs push the data to Kinesis whereas
Kinesis applications act as consumers of the data from Kinesis
engine. It also provides data retention for certain time for
example 24 hours default. This data retention window is a sliding
window. Kinesis collects lot of metrics which can used to
understand the amount of data being processed by Kinesis.  User
can use this metrics to do some analytics and visualize the
metrics data.  Kinesis is one of the tools part of AWS
infrastructure and provides its users a complete
software-as-a-service. Kinesis <a class="reference internal" href="#big-data-analytics-book" id="id100">[82]</a> in
the area of real-time processing provides following key benefits:
ease of use, parellel processing, scalable, cost effective, fault
tolerant and highly available.</p>
</li>
<li><p class="first">LinkedIn</p>
</li>
<li><p class="first">Twitter Heron</p>
</li>
<li><p class="first">Databus</p>
</li>
<li><p class="first">Facebook Puma/Ptail/Scribe/ODS</p>
</li>
<li><p class="first">Azure Stream Analytics</p>
</li>
<li><p class="first">Floe</p>
</li>
<li><p class="first">Spark Streaming</p>
</li>
<li><p class="first">Flink Streaming</p>
</li>
<li><p class="first">DataTurbine</p>
</li>
</ol>
</div>
<div class="section" id="basic-programming-model-and-runtime-spmd-mapreduce">
<h2>Basic Programming model and runtime, SPMD, MapReduce<a class="headerlink" href="#basic-programming-model-and-runtime-spmd-mapreduce" title="Permalink to this headline"></a></h2>
<ol class="arabic" start="143">
<li><p class="first">Hadoop</p>
</li>
<li><p class="first">Spark <a class="reference internal" href="#www-spark" id="id101">[83]</a></p>
<p>Apache Spark which is an open source cluster computing framework
has emerged as the next generation big data processing engine
surpassing Hadoop MapReduce. &#8220;Spark engine is developed for
in-memory processing as well a disk based processing. This system
also provides large number of impressive high level tools such as
machine learning tool M Lib, structured data processing, Spark
SQL, graph processing took Graph X, stream processing engine
called Spark Streaming, and Shark for fast interactive question
device.&#8221; The ability of spark to join datasets across various
heterogeneous data sources is one of its prized
attributes. Apache Spark is not the most suitable data analysis
engine when it comes to processing (1) data streams where latency
is the most crucial aspect and (2) when the available memory for
processing is restricted. &#8220;When available memory is very limited,
Apache Hadoop Map Reduce may help better, considering huge
performance gap.&#8221; In cases where latency is the most crucial
aspect we can get better results using Apache Storm.</p>
</li>
<li><p class="first">Twister</p>
</li>
<li><p class="first">MR-MPI</p>
<p><a class="reference internal" href="#www-mapreducempi" id="id102">[84]</a> MR-MPI stands for Map Reduce-Message
Passing Interface is open source library build on top of standard
MPI. It basically implements mapReduce operation providing a
interface for user to simplify writing mapReduce program.  It is
written in C++ and needs to be linked to MPI library in order to
make the basic map reduce functionality to be executed in
parallel on distributed memory architecture.  It provides
interface for c, c++ and python. Using C interface the library
can also be called from Fortrain.</p>
</li>
<li><p class="first">Stratosphere (Apache Flink)</p>
</li>
<li><p class="first">Reef</p>
<p>REEF (Retainable Evaluator Execution Framework) <a class="reference internal" href="#www-reef" id="id103">[85]</a>
is a scale-out computing fabric that eases the development of Big
Data applications on top of resource managers such as Apache YARN
and Mesos. It is a Big Data system that makes it easy to
implement scalable, fault-tolerant runtime environments for a
range of data processing models on top of resource managers. REEF
provides capabilities to run multiple heterogeneous frameworks
and workflows of those efficiently. REEF contains two libraries,
Wake and Tang where Wake is an event-based-programming framework
inspired by Rx and SEDA and Tang is a dependency injection
framework inspired by Google Guice, but designed specifically for
configuring distributed systems.</p>
</li>
<li><p class="first">Disco</p>
</li>
<li><p class="first">Hama</p>
</li>
<li><p class="first">Giraph</p>
</li>
<li><p class="first">Pregel</p>
</li>
<li><p class="first">Pegasus</p>
</li>
<li><p class="first">Ligra</p>
</li>
<li><p class="first">GraphChi</p>
</li>
<li><p class="first">Galois</p>
<p>Galois system was built by intelligent software systems team at
University of Texas, Austin. As explained in
<a class="reference internal" href="#www-galoissite" id="id104">[86]</a>, Galois is a system that automatically
executes &#8216;Galoized&#8217; serial C++ or Java code&nbsp;in parallel&nbsp;on
shared-memory machines. It works by exploiting amorphous
data-parallelism, which is present even in irregular codes that
are organized around pointer-based data structures such as graphs
and trees. By using Galois provided data structures programmers
can write serial programs that gives the performance of parallel
execution. Galois employs annotations at loop levels to
understand correct context during concurrent execution and
executes the code that could be run in parallel. The key idea
behind Galois is Tao-analysis, in which parallelism is exploited
at compile time rather than at run time by creating operators
equivalent of the code by employing data driven local computation
algorithm <a class="reference internal" href="#taoparallelismpaper" id="id105">[87]</a>. Galois currently supports
C++ and Java.</p>
</li>
<li><p class="first">Medusa-GPU</p>
</li>
<li><p class="first">MapGraph</p>
</li>
<li><p class="first">Totem</p>
</li>
</ol>
</div>
<div class="section" id="inter-process-communication-collectives">
<h2>Inter process communication Collectives<a class="headerlink" href="#inter-process-communication-collectives" title="Permalink to this headline"></a></h2>
<ol class="arabic" start="160">
<li><p class="first">point-to-point</p>
</li>
<li><p class="first">publish-subscribe: MPI</p>
</li>
<li><p class="first">HPX-5</p>
<p>Based on <a class="reference internal" href="#www-hpx-5" id="id106">[88]</a>, High Performance ParallelX (HPX-5)
is an open source, distributed model that provides opportunity
for operations to run unmodified on one-to-many nodes. The
dynamic nature of the model accommodates effective computing
resource management and task scheduling. It is portable and
performance-oriented. HPX-5 was developed by IU Center for
Research in Extreme Scale Technologies (CREST). Concurrency is
provided by lightweight control object (LCO) synchronization and
asynchronous remote procedure calls. ParallelX component allows
for termination detection and supplies per-process
collectives. It addresses the challenges of starvation, latency,
overhead, waiting, energy and reliability. Finally, it supports
OpenCL to use distributed GPU and coprocessors. HPX-5 could be
compiled on various OS platforms , however it was only tested on
several Linux and Darwin (10.11) platforms. Required
configurations and environments could be accessed via
<a class="reference internal" href="#www-hpx-5-user-guide" id="id107">[89]</a>.</p>
</li>
<li><p class="first">Argo BEAST HPX-5 BEAST PULSAR</p>
<p>Search on the internet was not successsful.</p>
</li>
<li><p class="first">Harp</p>
<p>Harp <a class="reference internal" href="#www-harp" id="id108">[90]</a> is a simple, easy to maintain, low risk and
easy to scale static web server that also serves Jade, Markdown,
EJS, Less, Stylus, Sass, and CoffeeScript as HTML, CSS, and
JavaScript without any configuration and requires low cognitive
overhead. It supports the beloved layout/partial paradigm and it
has flexible metadata and global objects for traversing the file
system and injecting custom data into templates. It acts like a
lightweight web server that was powerful enough for me to abandon
web frameworks for dead simple front-end publishing. Harp can
also compile your project down to static assets for hosting
behind any valid HTTP server.</p>
</li>
<li><p class="first">Netty</p>
<p>Netty <a class="reference internal" href="#www-netty" id="id109">[91]</a> &#8220;is an asynchronous event-driven network
application framework for rapid development of maintainable high
performance protocol servers &amp; clients&#8221;. Netty <a class="reference internal" href="#netty-book" id="id110">[92]</a>
&#8220;is more than a collection of interfaces and classes; it also
defines an architectural model and a rich set of design
patterns&#8221;. It is protocol agnostic, supports both connection
oriented protocols using TCP and connection less protocols built
using UDP. Netty offers performance superior to standard Java NIO
API thanks to optimized resource management, pooling and reuse
and low memory copying.</p>
</li>
<li><p class="first">ZeroMQ</p>
<p>In <a class="reference internal" href="#www-zeromq" id="id111">[93]</a>, ZeroMQ is introduced as a software product
that can &#8220;connect your code in any language, on any platform&#8221; by
leveraging &#8220;smart patterns like pub-sub, push-pull, and
router-dealer&#8221; to carry &#8220;messages across inproc, IPC, TCP, TIPC,
[and] multicast.&#8221; In <a class="reference internal" href="#www-zeromq2" id="id112">[94]</a>, it is explained that
ZeroMQ&#8217;s &#8220;asynchronous I/O model&#8221; causes this &#8220;tiny library&#8221; to
be &#8220;fast enough to be the fabric for clustered products.&#8221; In
<a class="reference internal" href="#www-zeromq" id="id113">[93]</a>, it is made clear that ZeroMQ is &#8220;backed by a
large and open source community&#8221; with &#8220;full commercial support.&#8221;
In contrast to Message Passing Interface (i.e. MPI), which is
popular among parallel scientific applications, ZeroMQ is
designed as a fault tolerant method to communicate across highly
distributed systems.</p>
</li>
<li><p class="first">ActiveMQ</p>
</li>
<li><p class="first">RabbitMQ</p>
<p>RabbitMQ is a message broker <a class="reference internal" href="#www-rabbitmq" id="id114">[95]</a> which allows
services to exchange messages in a fault tolerant manner. It
provides variety of features which enables software applications
to connect and scale. Features are: reliability, flexible
routing, clustering, federation, highly available queues,
multi-protocol, many clients, management UI, tracing, plugin
system, commercial support, large community and user
base. RabbitMQ can work in multiple scenarios:</p>
<ol class="arabic">
<li><p class="first">Simple messaging: producers write messages to the queue and
consumers read messages from the the queue. This is synonymous
to a simple message queue.</p>
</li>
<li><p class="first">Producer-consumer: Producers produce messages and consumers
receive messages from the queue. The messages are delivered to
multiple consumers in round robin manner.</p>
</li>
<li><p class="first">Publish-subscribe: Producers publish messages to exchanges
and consumers subscribe to these exchanges. Consumers receive
those messages when the messages are available in those
exchanges.</p>
</li>
<li><p class="first">Routing: In this mode consumers can subscribe to a subset
of messages instead of receiving all messages from the queue.</p>
</li>
<li><p class="first">Topics: Producers can produce messages to a topic multiple
consumers registered to receive messages from those topics get
those messages. These topics can be handled by a single
exchange or multiple exchanges.</p>
</li>
<li><p class="first">RPC:In this mode the client sends messages as well as
registers a callback message queue. The consumers consume the
message and post the response message to the callback queue.</p>
<p>RabbitMQ is based on AMPQ <a class="reference internal" href="#ampq-article" id="id115">[96]</a> (Advanced
Message Queuing Protocol) messaging model. AMPQ is described
as follows messages are published to exchanges, which are
often compared to post offices or mailboxes. Exchanges then
distribute message copies to queues using rules called
bindings. Then AMQP brokers either deliver messages to
consumers subscribed to queues, or consumers fetch/pull
messages from queues on demand</p>
</li>
</ol>
</li>
<li><p class="first">NaradaBrokering</p>
</li>
<li><p class="first">QPid</p>
</li>
<li><p class="first">Kafka</p>
<p>Apache Kafka is a streaming platform, which works based on
publish-subscribe messaging system and supports distributed
environment. Kafka lets publish and subscribe to the messages.</p>
<p>In a publish-subscribe messaging system, publishers are sender of
messages. They publish the messages without the knowledge of who
is going to subscribe to them for processing. Subscribers are
users of these messages. They subscribe to only those messages
which they are interested in, without knowing who the publishers
are. Kafka maintains message feeds based on topic. A topic is a
category or feed name to which records are
published. Applications can use Kafkas Connector APIs to publish
the messages to one or more Kafka topics. Similarly, applications
can use Consumer API to subscribe to one or more topics.
Kafka has the capability to process the stream of data at real time.</p>
<p>Kafkas stream processor takes continual stream of data from
input topics, processes the data in real time and produces
streams of data to output topics. Kafkas Streams API are used
for data transformation. Kafka allows to store the stream of data
in distributed clusters.</p>
<p>Kafka acts as a storage system for incoming data stream. Data is
categorised into topics. As Kafka is a distributed system, data
streams are partitioned and replicated across nodes. Thus, a
combination of messaging, storage and processing data stream
makes Kafka a streaming platform.</p>
<p>Kafka is a commonly used for building data pipelines where data is
transferred between systems or applications. <a class="reference internal" href="#www-kafka" id="id116">[97]</a>
Kafka can also be used by applications that transform real time
incoming data.</p>
</li>
<li><p class="first">Kestrel</p>
</li>
<li><p class="first">JMS</p>
</li>
<li><p class="first">AMQP</p>
<p><a class="reference internal" href="#www-amqp" id="id117">[98]</a> AMQP stands for Advanced Message Queueing
Protocol. AMQP is open interenet protocol that allows secure and
reliable communication between applications in different
orginization and different applications which are on diffferent
platforms. AMQP allows businesses to implement middleware
applications interoperability by allowing secure message transfer
bewteen the applications on timly manner. AMQP is mainly used by
financial and banking business. Other sectors that aslo use AMQP
are Defence, Telecommunication, cloud Computing and so on.
Apache Qpid, StormMQ, RabbitMQ, MQlight, Microsoft&#8217;s Windows
Azure Service Bus, IIT Software&#8217;s SwiftMQ and JORAM are some of
the products that implement AMQP protocol.</p>
</li>
<li><p class="first">Stomp</p>
</li>
<li><p class="first">MQTT</p>
<p>According to <a class="reference internal" href="#www-mqtt" id="id118">[99]</a>, Message Queueing Telemetry
Transport (MQTT) protocol is an Interprocess communication
protocol that could serve as better alternative to HTTP in
certain cases. It is based on a publish-subscribe messaging
pattern. Any sensor or remote machine can publish it&#8217;s data and
any registered client can subscribe the data. A broker takes care
of the message being published by the remote machine and updates
the subscriber in case of new message from the remote
machine. The data is sent in binary format which makes it use
less bandwidth. It is designed mainly to cater to the needs to
devices that has access to minimal network bandwidth and device
resources without affecting reliability and quality assurance of
delivery. MQTT protocol has been in use since 1999. One of the
notable work is project Floodnet <a class="reference internal" href="#www-floodnet" id="id119">[100]</a>, which
monitors river and floodplains through a set of sensors.</p>
</li>
<li><p class="first">Marionette Collective</p>
</li>
<li><p class="first">Public Cloud: Amazon SNS</p>
</li>
<li><p class="first">Lambda</p>
</li>
<li><p class="first">Google Pub Sub</p>
</li>
<li><p class="first">Azure Queues</p>
</li>
<li><p class="first">Event Hubs</p>
</li>
</ol>
</div>
<div class="section" id="in-memory-databases-caches">
<h2>In-memory databases/caches<a class="headerlink" href="#in-memory-databases-caches" title="Permalink to this headline"></a></h2>
<ol class="arabic" start="183">
<li><p class="first">Gora (general object from NoSQL)</p>
<p>Gora is a in-memory data model <a class="reference internal" href="#www-gora" id="id120">[101]</a> which also
provides persistence to the big data. Gora provides persistence
to different types of data stores. Primary goals of Gora are:</p>
<ol class="arabic simple">
<li>data persistence</li>
<li>indexing</li>
<li>data access</li>
<li>analysis</li>
<li>map reduce support</li>
</ol>
<p>Unlike ORM models which mostly work with relational databases for
example hibernate gora works for most type of data stores like
documents, columnar, key value as well as relational. Gora uses
beans to maintain the data in-memory and persist it on
disk. Beans are defined using apache avro schema. Gora provides
modules for each type of data store it supports.  The mapping
between bean definition and datastore is done in a mapping file
which is specific to a data store.  Type Gora workflow will be:</p>
<ol class="arabic simple">
<li>define  the bean used as model for persistence</li>
<li>use gora compiler to compile the bean</li>
<li>create a mapping file to map bean definition to datastore</li>
<li>update gora.properties to specify the datastore to use</li>
<li>get an instance of corresponding data store using datastore factory.</li>
</ol>
<p>Gora has a query interface to query the underlying data
store. Its configuration is stored in gora.properties which
should be present in classpath. In the file you can specify
default data store used by Gora engine. Gora also has a CI/CD
library call GoraCI which is used to write integration tests.</p>
</li>
<li><p class="first">Memcached</p>
<p>Memcached is a free and open-source, high performance, distributed memory
object caching system. <a class="reference internal" href="#www-memcached" id="id121">[102]</a> Although, generic in nature,it
is intended for se in speeding up dynamic web applications by reducing
the database load.</p>
<p>It can be thought of as a short term memory for your applications.
Memcached is an in-memory key-value store for small chunks of arbitrary
data from the results of database calls, API calls and page rendering. Its
API is available in most of the popular languages. In simple terms, it
allows you to take memory from parts of your system where you have more
memory than you need and allocate it to parts of your system where you
have less memory than you need.</p>
</li>
<li><p class="first">Redis</p>
</li>
<li><p class="first">LMDB (key value)</p>
<p>LMDB (Lighting memory-mapped Database) is a high performance embedded
transactional database in form of a key-value store
<a class="reference internal" href="#www-keyvalue" id="id122">[103]</a>. LMDB is designed around
virtual memory facilities found in modern operating
systems, multi-version concurrency control (MVCC)
and single-level store (SLS) concepts. LMDB stores
arbitrary key/data pairs as byte arrays, provides a
range-based search capability, supports multiple
data items for a single key and has a special mode
for appending records at the end of the database
(MDB_APPEND) which significantly increases its write
performance compared to other similar databases.</p>
<p>LMDB is not a relational database <a class="reference internal" href="#www-relationaldb" id="id123">[104]</a> and
strictly uses key-value store. Key-value databases
allows one write at a time, the difference that LMDB
highlights is that write transactions do not block
readers nor do readers block writes. Also, it does
allow multiple applications on the same system to
open and use the store simultaneously which helps in
scaling up performance <a class="reference internal" href="#www-lmdb" id="id124">[105]</a>.</p>
</li>
<li><p class="first">Hazelcast</p>
<p>Hazelcast is a java based, in memory data grid. <a class="reference internal" href="#www-wikihazel" id="id125">[106]</a>
It is open source software, released under the Apache 2.0 License.
<a class="reference internal" href="#www-githubhazel" id="id126">[107]</a></p>
<p>Hazelcast uses a grid to distribute data evenly across a cluster.
Clusters allow processing and storage to scale horizontally.
Hazelcast enables predictable scaling for applications by providing
in memory access to data. <a class="reference internal" href="#www-wikihazel" id="id127">[106]</a></p>
<p>Hazelcast can run locally, in the cloud, in virtual machines, or
in Docker containers. <a class="reference internal" href="#www-wikihazel" id="id128">[106]</a></p>
</li>
<li><p class="first">Ehcache</p>
<p>EHCACHE is an open-source Java-based cache. It supports distributed
caching and could scale to hundred of caches. It comes with REST APIs
and could be integrated with popular frameworks like Hibernate
<a class="reference internal" href="#www-ehcache-features" id="id129">[108]</a>. It offers storage tires such that less
frequently data could be moved to slower tires
<a class="reference internal" href="#www-ehcache-documentation" id="id130">[109]</a>. It&#8217;s XA compliant and supports two-
phase commit and recovery for transactions. It&#8217;s developed and
maintained by Terracotta and is available under Apache 2.0 license.
It conforms to Java caching standard JSR 107.</p>
</li>
<li><p class="first">Infinispan</p>
</li>
<li><p class="first">VoltDB</p>
</li>
<li><p class="first">H-Store</p>
<p>H-Store is an in memory and parallel database management system
for on-line transaction processing (OLTP). Specifically ,
<a class="reference internal" href="#www-hstore" id="id131">[110]</a> illustrates that H-Store is a highly
distributed, row-store-based relational database that runs on a
cluster on shared-nothing, main memory executor nodes.As Noted in
<a class="reference internal" href="#kallman2008" id="id132">[111]</a> &#8220;the architectural and application shifts
have resulted in modern OLTP databases increasingly falling short
of optimal performance.In particular, the availability of
multiple-cores, the abundance of main memory, the lack of user
stalls, and the dominant use of stored procedures are factors
that portend a clean-slate redesign of RDBMSs&#8221;.The H-store which
is a complete redesign has the potential to outperform legacy
OLTP databases by a significant factor.  As detailed in
<a class="reference internal" href="#www-hstorewiki" id="id133">[112]</a> H-Store is the first implementation of a
new class of parallel DBMS, called NewSQL, that provides the
high-throughput and high-availability of NoSQL systems, but
without giving up the transactional guarantees of a traditional
DBMS.  The H-Store system is able to scale out horizontally
across multiple machines to improve throughput, as opposed to
moving to a more powerful , more expensive machine for a
single-node system.</p>
</li>
</ol>
</div>
<div class="section" id="object-relational-mapping">
<h2>Object-relational mapping<a class="headerlink" href="#object-relational-mapping" title="Permalink to this headline"></a></h2>
<ol class="arabic" start="192">
<li><p class="first">Hibernate</p>
</li>
<li><p class="first">OpenJPA</p>
</li>
<li><p class="first">EclipseLink</p>
<p>EclipseLink is an open source persistence Services project from Eclipse
foundation. It is a framework which provide developers to
interact with data services including database and web services,
Object XML mapping etc. <a class="reference internal" href="#www-eclipselink" id="id134">[113]</a>. This is the project
which was developed out of Oracle&#8217;s Toplink product. The main
difference is EclipseLink does not have some key enterprise
feature. Eclipselink support a number of persistence standard
model like JPA, JAXB, JCA and Service Data Object. Like Toplink,
the ORM (Object relational model) is the technique to convert
incompatible type system in Object Oriented programming
language. It is a framework for storing java object into
relational database.</p>
</li>
<li><p class="first">DataNucleus</p>
</li>
<li><p class="first">ODBC/JDBC</p>
</li>
</ol>
</div>
<div class="section" id="extraction-tools">
<h2>Extraction Tools<a class="headerlink" href="#extraction-tools" title="Permalink to this headline"></a></h2>
<ol class="arabic simple" start="197">
<li>UIMA</li>
</ol>
<ol class="arabic" start="381">
<li><p class="first">Tika</p>
<p>&#8220;The Apache Tika toolkit detects and extracts metadata and text
from over a thousand different file types (such as PPT, XLS, and
PDF). All of these file types can be parsed through a single
interface, making Tika useful for search engine indexing, content
analysis, translation, and much more. <a class="reference internal" href="#www-tika" id="id135">[114]</a>&#8220;</p>
</li>
</ol>
</div>
<div class="section" id="sql-newsql">
<h2>SQL(NewSQL)<a class="headerlink" href="#sql-newsql" title="Permalink to this headline"></a></h2>
<ol class="arabic" start="198">
<li><p class="first">Oracle</p>
</li>
<li><p class="first">DB2</p>
</li>
<li><p class="first">SQL Server</p>
<p>SQL Server <a class="reference internal" href="#www-sqlserver-wiki" id="id136">[115]</a> is a relational database
management system from Microsoft. As of Jan 2017, SQL Server is
available in below editions</p>
<ol class="arabic simple">
<li>Standard - consists of core database engine</li>
<li>Web - low cost edition for web hosting</li>
<li>Business Intelligence - includes standard edition and business
intelligence tools like PowerPivot, PowerBI, Master Data Services</li>
<li>Enterprise - consists of core database engine and enterprise services
like cluster manager</li>
<li>SQL Server Azure - <a class="reference internal" href="#www-azuresql" id="id137">[116]</a> core database engine
integrated with Microsoft Azure cloud platform and available in
platform-as-a-service mode.</li>
</ol>
<p>In the book <a class="reference internal" href="#book-sqlserver" id="id138">[117]</a>, the technical architecture of SQL Server in
OLTP(online transaction processing), hybrid cloud and business
intelligence modes is explained in detail.</p>
</li>
<li><p class="first">SQLite</p>
</li>
<li><p class="first">MySQL</p>
<p>MySQL is a relational database management system. <a class="reference internal" href="#devmysql" id="id139">[118]</a> SQL
is an acronym for Structured Query Language and is a standardized
language used to interact with the databases. <a class="reference internal" href="#devmysql" id="id140">[118]</a>
Databases provide structure to a collection of data
while. <a class="reference internal" href="#devmysql" id="id141">[118]</a> A database management system allows for the
addition, accessing, and processing of the data stored in a
database. <a class="reference internal" href="#devmysql" id="id142">[118]</a> Relational databases utilize tables that are
broken down into columns, representing the various fields of the
table, and rows, which correspond to individual entries in the
table. <a class="reference internal" href="#howmysql" id="id143">[119]</a></p>
</li>
<li><p class="first">PostgreSQL</p>
</li>
<li><p class="first">CUBRID</p>
<p>CUBRID name is deduced from the combination of word CUBE(security
within box) and BRIDGE(data bridge).  It is an open source
Relational DataBase Management System designed in C programming
language with high performance, scalability and availability
features. During its development by NCL, korean IT service
provider the goal was to optimize database performance for
web-applications. <a class="reference internal" href="#www-cubrid" id="id144">[120]</a> Importantly most of the SQL
syntax from MYSQL and ORACLE can work on cubrid.CUBRID also
provides manager tool for database administration and migration
tool for migrating the data from DBMS to CUBRID bridging the dbs.
CUBRID enterprise version and all the tools are free and suitable
database candidate for web-application development.</p>
</li>
<li><p class="first">Galera Cluster</p>
<p>Galera cluster <a class="reference internal" href="#www-galera-cluster" id="id145">[121]</a> is a type of database
clustering which has all multiple masters and works on
synchronous replication. At a deeper level, it was created by
extending MySql replication API to provide all support for true
multi master synchronous replication.  This extended api is
called as Write-Set Replication API and is the core of the
clustering logic.  Each transaction of wsrep API not only
contains the record but also other meta-info to requires to
commit each node separately or asynchronously. So though it seems
synchronous logically but works independently on each node.  The
approach is also called virtually synchronous replication. This
helps in directly read-write on a specific node and can lose a
node without handling any complex failover scenarios (zero
downtime).</p>
</li>
<li><p class="first">SciDB</p>
</li>
<li><p class="first">Rasdaman</p>
</li>
<li><p class="first">Apache Derby</p>
</li>
<li><p class="first">Pivotal Greenplum</p>
</li>
<li><p class="first">Google Cloud SQL</p>
</li>
<li><p class="first">Azure SQL</p>
</li>
<li><p class="first">Amazon RDS</p>
</li>
<li><p class="first">Google F1</p>
</li>
<li><p class="first">IBM dashDB</p>
</li>
<li><p class="first">N1QL</p>
</li>
<li><p class="first">BlinkDB</p>
</li>
<li><p class="first">Spark SQL</p>
</li>
</ol>
</div>
<div class="section" id="nosql">
<h2>NoSQL<a class="headerlink" href="#nosql" title="Permalink to this headline"></a></h2>
<ol class="arabic" start="218">
<li><p class="first">Lucene</p>
<p>Apache Lucene <a class="reference internal" href="#www-lucene" id="id146">[122]</a> is a high-performance,
full-featured text search engine library.  It is originally
written in pure Java but also has been ported to few other
languages chiefly python.  It is suitable for applications that
requires full-text search.  One of the key implementation of
Lucene is Internet search engines and local, single-site
searching.  Another important implementation usage is its
recomendation system. The core idea of Lucene is to extract text
from any document that contains text (not image) field, making it
format idependent.</p>
</li>
<li><p class="first">Solr</p>
</li>
<li><p class="first">Solandra</p>
<p>Solandra is a highly scalable real-time search engine built on
Apache Solr and Apache Cassandra. Solandra simplifies maintaining
a large scale search engine, something that more and more
applications need. At its core, Solandra is a tight integration
of Solr and Cassandra, meaning within a single JVM both Solr and
Cassandra are running, and documents are stored and disributed
using Cassandra&#8217;s data model. <a class="reference internal" href="#www-solandra" id="id147">[123]</a></p>
<p>Solandra supports most out-of-the-box Solr functionality (search,
faceting, highlights), multi-master (read/write to any node). It
features replication, sharding, caching, and compaction managed
by Cassandra. <a class="reference internal" href="#www-solandra2" id="id148">[124]</a></p>
</li>
<li><p class="first">Voldemort</p>
<p>According to <a class="reference internal" href="#www-voldemort" id="id149">[125]</a>, project Voldemort, developed
by LinkedIn, is a non-relational database of key-value type that
supports eventual consistency. The distributed nature of the
system allows pluggable data placement and provides horizontal
scalability and high consistency. Replication and partitioning of
data is automatic and performed on multiple servers. Independent
nodes that comprise the server support transparent handling of
server failure and ensure absence of a central point of
failure. Essentially, Voldemort is a hashtable. It uses APIs for
data replication. In memory caching allows for faster
operations. It allows cluster expansion with no data rebalancing.
When Voldemort performance was benchmarked with the other
key-value databases such as Cassandra, Redis and HBase as well as
MySQL relational database <a class="reference internal" href="#rabl-sadoghi-jacobsen-2012" id="id150">[126]</a>, the
Voldemart&#8217;s throughput was twice lower than MySQL and Cassandra
and six times higher than HBase. Voldemort was slightly
underperforming in comparison with Redis. At the same time, it
demonstrated consistent linear performance in maximum throughput
that supports high scalability. The read latency for Voldemort
was fairly consistent and only slightly underperformed
Redis. Similar tendency was observed with the read latency that
puts Voldermort in the cluster of databases that require good
read-write speed for workload operations. However, the same
authors noted that Voldemort required creation of the node
specific configuration and optimization in order to successfully
run a high throughput tests. The default options were not
sufficient and were quickly saturated that stall the database.</p>
</li>
<li><p class="first">Riak</p>
<p>Riak is a set of scalable distributed NoSQL databases developed by
Basho Technologies. Riak KV is a key-value <a class="reference internal" href="#www-riak-kv" id="id151">[127]</a> database
with time-to-live feature so that older data is deleted automatically.
It can be queried through secondary indexes, search via Apache Solr,
and MapReduce. Riak TS is designed for time-series data. It co-
locates related data on the same physical cluster for faster access
<a class="reference internal" href="#www-riak-ts" id="id152">[128]</a>. Riak S2 is designed to store large objects like media
files and software binaries <a class="reference internal" href="#www-riak-s2" id="id153">[129]</a>. The databases are available
in both open source and commercial versions with multicluster
replication provided only in later. REST APIs are available for these
databases.</p>
</li>
<li><p class="first">ZHT</p>
<p>According to <a class="reference internal" href="#datasys" id="id154">[130]</a>, ZHT is a zero-hop distributed hash
table. Distributed hash tables effectively break a hash table up
and assign different nodes responsibility for managing different
pieces of the larger hash table. <a class="reference internal" href="#wiley" id="id155">[131]</a> To retrieve a value in a
distributed hash table, one needs to find the node that is
responsible for the managing the key value pair of
interest. <a class="reference internal" href="#wiley" id="id156">[131]</a> In general, every node that is a part of the
distributed hash table has a reference to the closest two nodes
in the node list. <a class="reference internal" href="#wiley" id="id157">[131]</a> In a ZHT, however, every node contains
information concerning the location of every other node. <a class="reference internal" href="#li" id="id158">[132]</a>
Through this approach, ZHT aims to provide high availability,
good fault tolerance, high throughput, and low latencies, at
extreme scales of millions of nodes. <a class="reference internal" href="#li" id="id159">[132]</a> Some of the defining
characteristics of ZHT are that it is light-weight, allows nodes
to join and leave dynamically, and utilizes replication to obtain
fault tolerance among others. <a class="reference internal" href="#li" id="id160">[132]</a></p>
</li>
<li><p class="first">Berkeley DB</p>
</li>
<li><p class="first">Kyoto/Tokyo Cabinet</p>
<p>Tokyo Cabinet <a class="reference internal" href="#www-tokyo-cabinet" id="id161">[133]</a> and Kyoto Cabinet
<a class="reference internal" href="#www-kyoto-cabinet" id="id162">[134]</a> are libraries of routines for managing a
database. The database normally is a simple data file containing
records having a key value pair structure. Every key and value is
serial bytes with variable length. Both binary data and character
string can be used as a key and a value. There is no concept of
data tables nor data types like RDBMS or DBMS. Records are
organized in hash table, B+ tree, or fixed-length array.Tokyo and
Kyoto cabinets both are developed as a successor of GDBM and QDBM
which are library routines for managing database as well. Tokyo
Cabinet is written in the C language, and is provided as API of
C, Perl, Ruby, Java, and Lua. Tokyo Cabinet is available on
platforms which have API conforming to C99 and POSIX. Whereas
Kyoto Cabinet is written in the C++ language, and is provided as
API of C++, C, Java, Python, Ruby, Perl, and Lua. Kyoto Cabinet
is available on platforms which have API conforming to C++03 with
the TR1 library extensions. Both are free software licenced under
GNU (General Public Licence). <a class="reference internal" href="#www-tokyo-cabinet" id="id163">[133]</a> actually mentions
that Kyoto Cabinet is more powerful and has convenient library
structure than Tokyo and recommends people to use Kyoto. Since
they use key-value pair concept, you can store a record with a
key and a value, delete a record using the key and even retrive a
record using the key. Both have smaller size of database file,
faster processing speed and provide effective backup procedures.</p>
</li>
<li><p class="first">Tycoon</p>
</li>
<li><p class="first">Tyrant</p>
<p>Tyrant provides network interfaces to the database management
system called Tokyo Cabinet. Tyrant is also called as Tokyo
Tyrant. Tyrant is implemented in C and it provides APIs for Perl,
Ruby and C. Tyrant provides high performance and concurrent
access to Tokyo Cabinet. The blog <a class="reference internal" href="#www-tyrant-blog" id="id164">[135]</a>
explains the results of performance experiments between Tyrant and
Memcached + MySQL.</p>
<p>Tyrant was written and maintained by FAL Labs
<a class="reference internal" href="#www-tyrant-fal-labs" id="id165">[136]</a>.  However, according to FAL Labs,
their latest product <a class="reference internal" href="#www-kyoto-tycoon" id="id166">[137]</a> Kyoto Tycoon is
more powerful and convenient server than Tokyo Tyrant.</p>
</li>
<li><p class="first">MongoDB</p>
</li>
<li><p class="first">Espresso</p>
</li>
<li><p class="first">CouchDB</p>
</li>
<li><p class="first">Couchbase</p>
<p>Couchbase, Inc. offers Couchbase Server (CBS) to the marketplace
as a NoSQL, document-oriented database alternative to traditional
relationship- oriented database managgement systems as well as
other NoSQL competitors.  The basic storage unit, a <em>document</em>,
is a &#8220;data structure defined as a collection of named fields&#8221;.
The document utilizes JSON, thereby allowing each document to
have its own individual schema. <a class="reference internal" href="#www-infoworld-cbs" id="id167">[138]</a></p>
<p>CBS combines the in-memory capabilities of Membase with CouchDB&#8217;s
inherent data store reliability and data persistency.  Membase
functions in RAM only, providing the highest-possible speed
capabilities to end users.  However, Membase&#8217;s in-ram existence
limits the amount of data it can use.  More importantly, it
provides no mechanism for data recovery if the server crashes.
Combining Membase with CouchDB provides a persistent data source,
mitigating the disadvantages of either product.  In addition,
CouchDB + membase allows the data size &#8220;to grow beyond the size
of RAM&#8221;.  <a class="reference internal" href="#www-safaribooks-cbs" id="id168">[139]</a></p>
<p>CBS is written in Erlang/OTP, but generally shortened to just
Erlang.  In actuality, t is written in &#8220;Erlang using components
of OTP alongside some C/C++&#8221;<a class="reference internal" href="#www-erlangcentral-cbs" id="id169">[140]</a>, It
runs on an Erlang virtual machine known as
BEAM. <a class="reference internal" href="#www-wikipedia-erlang-cbs" id="id170">[141]</a></p>
<p>Out-of-the-box benefits of Erlang/OTP include dynamic type
setting, pattern matching and, most importantly, actor-model
concurrency.  As a result, Erlang code virtually eliminates the
possibility of inadvertent deadlock scenarios.  In addition,
Erlang/OTP processes are lightweight, spawning new processes does
not consume many resources and message passing between processes
is fast since they run in the same memory space.  Finally, OTP&#8217;s
process supervision tree makes Erlang/OTP extremely
fault-tolerant.  Error handling is indistinguishable from a
process startup, easing testing and bug detection.
<a class="reference internal" href="#www-couchbase-blog-cbs" id="id171">[142]</a></p>
<p>CouchDB&#8217;s design adds another layer of reliability to CBS.
CouchDB operates in <em>append-only</em> mode, so it adds user changes
to the tail of database.  This setup resists data corruption
while taking a snapshot, even if the server continues to run
during the procedure.  <a class="reference internal" href="#www-hightower-cbs" id="id172">[143]</a></p>
<p>Finally, CB uses the Apache 2.0 License, one of several
open-source license alternatives. <a class="reference internal" href="#www-quora-cbs" id="id173">[144]</a></p>
</li>
<li><p class="first">IBM Cloudant</p>
</li>
<li><p class="first">Pivotal Gemfire</p>
<p>According to <a class="reference internal" href="#www-gemfire" id="id174">[145]</a>, a real-time, consistent access
to data-intensive applications is provided by a open source, data
management platform named Pivotal Gemfire. &#8220;GemFire pools memory,
CPU, network resources, and optionally local disk across multiple
processes to manage application objects and behavior&#8221;. The main
features of Gemfire are high scalability, continuous
availability, shared nothing disk persistence, heterogeneous data
sharing and parallelized application behavior on data stores to
name a few.  In Gemfire, clients can subscribe to receive
notifications to execute their task based on a specific change in
data. This is achieved through the continuous querying feature
which enables event-driven architecture. The shared nothing
architecture of Gemfire suggests that each node is
self-sufficient and independent, which means that if the disk or
caches in one node fail the remaining nodes remaining
untouched. Additionally, the support for multi-site
configurations enable the user to scale horizontally between
different distributed systems spread over a wide geographical
network.</p>
</li>
<li><p class="first">HBase</p>
</li>
<li><p class="first">Google Bigtable</p>
<p>Google Bigtable is a NoSQL database service, built upon several
Google technologies, including Google File System, Chubby Lock
Service, and SSTable.  Designed for Big Data, Bigtable provides
high performance and low latency and scales to hundreds of
petabytes.  <a class="reference internal" href="#www-cloudbigtable" id="id175">[146]</a> Bigtable powers many core
Google products, such as Search, Analytics, Maps, Earth, Gmail,
and YouTube.  <a class="reference internal" href="#www-wikibigtable" id="id176">[147]</a> Since May 6, 2015, a
version of Bigtable has been available to the public.  Bigtable
also drives Google Cloud Datastore <a class="reference internal" href="#www-wikibigtable" id="id177">[147]</a> and
Spanner, a distributed NewSQL also developed by
Google. <a class="reference internal" href="#www-wikispanner" id="id178">[148]</a></p>
</li>
<li><p class="first">LevelDB</p>
</li>
<li><p class="first">Megastore and Spanner</p>
<p>Spanner <a class="reference internal" href="#corbett-spanner" id="id179">[149]</a> is Google&#8217;s distributed database
which is used for managing all google services like play, gmail,
photos, picasa, app engine etc Spanner is distributed database
which spans across multiple clusters, datacenters and geo
locations.  Spanner is structured in such a way so as to provide
non blocking reads, lock free transactions and atomic schema
modification. This is unlike other noSql databases which follow
the CAP theory i.e. you can choose any two of the three:
Consistency, Availability and Partition-tolerance. However,
spanner gives an edge by satisfying all three of these. It gives
you atomicity and consistency along with availability, partition
tolerance and synchronized replication.  Megastore bridges the
gaps found in google&#8217;s bigtable. As google realized that it is
difficult to use bigtable where the application requires
constantly changing schema. Megastore offers a solution in terms
of semi-relational data model.  Megastore
<a class="reference internal" href="#www-magastore-spanner" id="id180">[150]</a> also provides a transactional
database which can scale unlike relational data stores and
synchronous replication.  Replication in megastore is supported
using Paxos. Megastore also provides versioning. However,
megastore has a poor write performance and lack of a SQL like
query language. Spanners basically adds what was missing in
Bigtable and megastore. As a global distributed database spanner
provides replication and globally consistent reads and
writes. Spanner deployment is called universe which is a
collections of zones. These zones are managed by singleton
universe master and placement driver. Replication in spanner is
supported by Paxos state machine. Spanner was put into evaluation
in early 2011 as F1 backend(F1 is Google&#8217;s advertisement system)
which was replacement to mysql. Overall spanner fulfils the needs
of relational database along with scaling of noSQL database.  All
these features make google run all their apps seamlessly on
spanner infrastructure.</p>
</li>
<li><p class="first">Accumulo</p>
</li>
<li><p class="first">Cassandra</p>
<p>Apache Cassandra <a class="reference internal" href="#www-cassandra" id="id181">[151]</a> is an open-source
distributed database managemment for handling large volume of
data accross comodity servers. It works on asynchronous
masterless replication technique leading to low latency and high
availability. It is a hybrid between a key-value and column
oriented database. A table in cassandra can be viewed as a multi
dimensional map indexed by a key. It has its own &#8220;Cassandra Query
language (CQL)&#8221; query language for data extraction and
mining. One of the demerits of such structure is it does not
support joins or subqueries. It is a java based system which can
be administered by any JMX compliant tools.</p>
</li>
<li><p class="first">RYA</p>
<p>Rya is a scalable system for storing and retrieving RDF data in
a cluster of nodes. <a class="reference internal" href="#punnoose" id="id182">[152]</a> RDF stands for Resource
Description Framework. <a class="reference internal" href="#punnoose" id="id183">[152]</a> RDF is a model that facilitates
the exchange of data on a network. <a class="reference internal" href="#w3" id="id184">[153]</a> RDF utilizes a form
commonly referred to as a triple, an object that consists of a
subject, predicate, and object. <a class="reference internal" href="#punnoose" id="id185">[152]</a> These triples are used
to describe resources on the Internet. <a class="reference internal" href="#punnoose" id="id186">[152]</a> Through new
storage and querying techniques, Rya aims to make accessing RDF
data fast and easy. <a class="reference internal" href="#apacherya" id="id187">[154]</a></p>
</li>
<li><p class="first">Sqrrl</p>
</li>
<li><p class="first">Neo4J</p>
</li>
<li><p class="first">graphdb</p>
<p>A Graph Database is a database that uses graph structures for semantic
queries with nodes, edges and properties to represent and store data.
<a class="reference internal" href="#www-graphdb" id="id188">[155]</a>
The Graph is a concept which directly relates the data items in the store.
The data which is present in the store is linked together directly with the
help of relationships. It can be retrieved with a single operation.
Graph database allow simple and rapid retrieval of complex hierarchical
structures that are difficult to model in relational systems.</p>
<p>There are different underlying storage mechanisms used by graph databases.
Some graphdb depend on a relational engine and store the graph data in a
table, while others use a key-value store or document-oriented database for
storage. Thus, they are inherently caled as NoSQL structures.
Data retrieval in a graph database requires a different query language
other than SQL. Some of the query languages used to retrieve data from a
graph database are Gremlin, SPARQL, and Cypher.
Graph databases are based on graph theory. They employ the concepts of
nodes, edges and properties.</p>
</li>
<li><p class="first">Yarcdata</p>
</li>
<li><p class="first">AllegroGraph</p>
</li>
<li><p class="first">Blazegraph</p>
</li>
<li><p class="first">Facebook Tao</p>
</li>
<li><p class="first">Titan:db</p>
</li>
<li><p class="first">Jena</p>
</li>
<li><p class="first">Sesame</p>
</li>
<li><p class="first">Public Cloud: Azure Table</p>
<p>Microsoft offers its NoSQL Azure Table product to the market as a
low-cost, fast and scalable data storage
option. <a class="reference internal" href="#www-what-to-use" id="id189">[156]</a> Table stores data as collections
of key-value combinations, which it terms <em>properties</em>.  Table
refers to a collection of properties as an <em>entity</em>.  Each entity
can contain a mix of properties.  The mix of properties can vary
between each entity, although each entity may consist of no more
than 255 properties. <a class="reference internal" href="#www-blobqueuetable" id="id190">[157]</a></p>
<p>Although data in Azure Table will be structured via key-value
pairs, Table provides just one mechanism for the user to define
relationships between entities: the entity&#8217;s <em>primary key</em>.  The
primary key, which Microsoft sometimes calls a <em>clustered index</em>,
consists of a PartitionKey and a RowKey.  The PartitionKey
indicates the group, a.k.a partition, to which the user assigned
the entity.  The RowKey indicates the entity&#8217;s relative position
in the group.  Table sorts in ascending order by the PartitionKey
first, then by the RowKey using lexical comparisons.  As a
result, numeric sorting requires fixed-length, zero-padded
strings.  For instance, Table sorts <em>111</em> before <em>2</em>, but will
sort <em>111</em> after <em>002</em>. <a class="reference internal" href="#www-scalable-partitioning" id="id191">[158]</a></p>
<p>Azure Table is considered best-suited for infrequently accessed
data storage.</p>
</li>
<li><p class="first">Amazon Dynamo</p>
</li>
<li><p class="first">Google DataStore</p>
</li>
</ol>
</div>
<div class="section" id="file-management">
<h2>File management<a class="headerlink" href="#file-management" title="Permalink to this headline"></a></h2>
<ol class="arabic" start="254">
<li><p class="first">iRODS</p>
</li>
<li><p class="first">NetCDF</p>
</li>
<li><p class="first">CDF</p>
</li>
<li><p class="first">HDF</p>
</li>
<li><p class="first">OPeNDAP</p>
</li>
<li><p class="first">FITS</p>
<p>FITS stand for &#8216;Flexible Image Trasnport System&#8217;. It is a
standard data format used in astronomy. FITS data format is
endorsed by NASA and International Astronomical Union. According
to <a class="reference internal" href="#www-fits-nasa" id="id192">[159]</a>, FITS can be used for transport,
analysis and archival storage of scientific datasets and support
multi-dimensional arrays, tables and headers sections.  FITS is
actively used and developed - according to
<a class="reference internal" href="#www-news-fits-2016" id="id193">[160]</a> newer version of FITS standard
document was released in July 2016. FITS can be used for
digitization of contents like books and
magzines. Vatican Library <a class="reference internal" href="#www-fits-vatican-library" id="id194">[161]</a> used FITS
for long term preservation of their book, manuscripts and other
collection. Matlab, a language used for technical computing
supports fits <a class="reference internal" href="#www-fits-matlab" id="id195">[162]</a>. The 2011 paper
<a class="reference internal" href="#paper-fits-2011" id="id196">[163]</a> explains how to perform
processing of astronomical images on Hadoop using FITS.</p>
</li>
<li><p class="first">RCFile</p>
</li>
<li><p class="first">ORC</p>
</li>
<li><p class="first">Parquet</p>
<p>Apache parquet is the column Oriented data store for Apache
Hadoop ecosystem and available in any data processing framework,
data model or programming language <a class="reference internal" href="#www-parquet" id="id197">[164]</a>. It
stores data such that the values in each column are physically
stored in contiguous memory locations. As it has the columnar
storage, it provides efficient data compression and encoding
schemes which saves storage space as the queries that fetch
specific column values need not read the entire row data and thus
improving performance.It can be implemented using the Apache
Thrift framework which increases its flexibility to work with a
number of programming languages like C++, Java, Python, PHP, etc.</p>
</li>
</ol>
</div>
<div class="section" id="data-transport">
<h2>Data Transport<a class="headerlink" href="#data-transport" title="Permalink to this headline"></a></h2>
<ol class="arabic" start="263">
<li><p class="first">BitTorrent</p>
<p>Bittorrent is P2P communication protocol commonly used for
sending and receiving the large digital files like movies and
audioclips.In order to upload and download file, user have to
download bittorrent client which implement the bittorrent
protocol. Bittorrent uses the principle of swarning and
tracking. <a class="reference internal" href="#www-bittorrent" id="id198">[165]</a> It divides the files in large
number of chunck and as soon as file is received it can be server
to the other users for downloading.  So rather than downloading
one entire large file from one source, user can download small
chunk from the different sources of linked users in
swarn. Bittorrent trackers keeps list of files available for
transfer and helps the swarn user find each other.</p>
<p>Using the protocol, machine with less configuration can serve as
server for distributing the files. It result in increase in the
downloading speed and reduction in origin server configuration.</p>
<p>Few popular bittorrent client in Torrent, qBittorrent.</p>
</li>
<li><p class="first">HTTP</p>
</li>
<li><p class="first">FTP</p>
</li>
<li><p class="first">SSH</p>
<p>SSH is a cryptographic network protocol <a class="reference internal" href="#www-ssh-wiki" id="id199">[166]</a> to
provide a secure channel between two clients over an unsecured
network. It uses public-key cryptography for authenticating the
remote machine and the user. The public-private key pairs could
be generated automatically to encrypt the network connection.
ssh-keygen utility could be used to generate the keys manually.
The public key then could be placed on the all the computers to
which the access is required by the owner of the private key.
SSH runs on the client-server model where a server listens for
incoming ssh connection requests. It&#8217;s generally used for remote
login and command execution. It&#8217;s other important uses include
tunneling(required in cloud computing) and file transfer(SFTP).
OpenSSH is an open source implementation of network utilities
based on SSH <a class="reference internal" href="#www-openssh-wiki" id="id200">[167]</a>.</p>
</li>
<li><p class="first">Globus Online (GridFTP)</p>
<p>GridFTP is a enhancement on the File Tranfer Protocol (FTP) which
provides high-performance , secure and reliable data transfer for
high-bandwidth wide-area networks. As noted in
<a class="reference internal" href="#www-globusonline" id="id201">[168]</a> the most widely used implementation of
GridFTP is Globus Online. GridFTP achieves efficient use of
bandwidth by using multiple simultaneous TCP streams.  Files can
be downloaded in pieces simultaneously from multiple sources; or
even in separate parallel streams from the same source. GridFTP
allows transfers to be restarted automatically and handles
network unavailability with a fault tolerant implementation of
FTP.The underlying TCP connection in FTP has numerous settings
such as window size and buffer size. GridFTP allows automatic (or
manual) negotiation of these settings to provide optimal transfer
speeds and reliability .</p>
</li>
<li><p class="first">Flume</p>
<p>Flume is distributed, reliable and available service for
efficiently collecting, aggregating and moving large amounts of
log data [apche-flume. Flume was created to allow you to flow data from a source into your Hadoop environment. In Flume][ the entities you work with are called sources][ decorators][ and sinks. A source can be any data source][ and Flume has many predefined source adapters. A sink is the target of a specific operation. A decorator is an operation on the stream that can transform the stream in some manner][ which could be to compress or uncompress data][ modify data by adding or removing pieces of information][ and more :cite: `ibm-flume].</p>
</li>
<li><p class="first">Sqoop</p>
<p>Apache Sqoop is a tool to transfer large amounts of data between Apache Hadoop
and sql databases <a class="reference internal" href="#www-sqoop" id="id210">[169]</a>. The name is a Portmanteau of
SQL + Hadoop. It is a command line interface application which
supports incremental loads of complete tables, free form (custom)
SQL Queries and allows the use of saved and scheduled jobs to import
latest updates made since the last import. The imports can also be
used to populate tables in Hive or Hbase. Sqoop has the option of
export, which allows data to be transferred from Hadoop into a
relational database. Sqoop is supported in many different business
integration suits like Informatica Big Data Management, Pentaho
Data Integration, Microsoft BI Suite and Couchbase <a class="reference internal" href="#sqoop-wiki" id="id211">[170]</a>.</p>
</li>
<li><p class="first">Pivotal GPLOAD/GPFDIST</p>
</li>
</ol>
</div>
<div class="section" id="cluster-resource-management">
<h2>Cluster Resource Management<a class="headerlink" href="#cluster-resource-management" title="Permalink to this headline"></a></h2>
<ol class="arabic" start="271">
<li><p class="first">Mesos</p>
</li>
<li><p class="first">Yarn</p>
<p>Yarn (Yet Another Resource Negotiator) is Apache Hadoops cluster
management project <a class="reference internal" href="#www-cloudera" id="id212">[171]</a> . Its a resource
management technology which make a pace between, the way
applications use Hadoop system resources &amp; node manager
agents. Yarn, split up the functionalities of resource
management and job scheduling/monitoring. The NodeManager watch
the resource (cpu, memory, disk,network) usage the container and
report the same to ResourceManager. Resource manager will take a
decision on allocation of resources to the
applications. ApplicationMaster is a library specific to
application, which requests/negotiate resources from
ResourceManager and launch and monitoring the task with
NodeManager(s) <a class="reference internal" href="#www-architecture" id="id213">[172]</a>.  ResourceManager have
two majors: Scheduler and ApplicationManager. Scheduler have a
task to schedule the resources required by the
application. ApplicationManger holds the record of application
who require resource. It validates (whether to allocate the
resource or not) the applications resource requirement and
ensure that no other application already have register for the
same resource requirement. Also it keeps the track of release of
resource. <a class="reference internal" href="#www-hadoopapache" id="id214">[173]</a></p>
</li>
<li><p class="first">Helix</p>
</li>
<li><p class="first">Llama</p>
</li>
<li><p class="first">Google Omega</p>
</li>
<li><p class="first">Facebook Corona</p>
</li>
<li><p class="first">Celery</p>
</li>
<li><p class="first">HTCondor</p>
</li>
<li><p class="first">SGE</p>
</li>
<li><p class="first">OpenPBS</p>
</li>
<li><p class="first">Moab</p>
</li>
<li><p class="first">Slurm <a class="reference internal" href="#www-slurm" id="id215">[174]</a></p>
<p>Simple Linux Utility for Resource Management (SLURM) workload
manager is an open source, scalable cluster resource management
tool used for job scheduling in small to large Linux cluster
using multi-core architecture. As per,
<a class="reference internal" href="#www-slurmschedmdsite" id="id216">[175]</a> SLURM has three key
functions. First, it allocates resources to users for some
duration with exclusive and/or non-exclusive access. Second, it
enables users to start, execute and monitor jobs on the resources
allocated to them. Finally, it intermediates to resolve conflicts
on resources for pending work by maintaining them in a queue. The
slurm architecture has following components: a centralized
manager to monitor resources and work, may have a backup manager,
daemon on each server to provide fault-tolerant communications,
an optional daemon for clusters with multiple mangers and tools
to initiate, terminate and report about jobs in a graphical view
with network topology. It also provides around twenty additional
plugins that could be used for functionalities like accounting,
advanced reservation, gang scheduling, back fill scheduling and
multifactor job prioritization. Though originally developed for
Linux, SLURM also provides full support on platforms like AIX,
FreeBSD, NetBSD and Solaris <a class="reference internal" href="#www-slurmplatformssite" id="id217">[176]</a>.</p>
</li>
<li><p class="first">Torque</p>
</li>
<li><p class="first">Globus Tools</p>
</li>
<li><p class="first">Pilot Jobs</p>
</li>
</ol>
</div>
<div class="section" id="file-systems">
<h2>File systems<a class="headerlink" href="#file-systems" title="Permalink to this headline"></a></h2>
<ol class="arabic" start="286">
<li><p class="first">HDFS</p>
</li>
<li><p class="first">Swift</p>
</li>
<li><p class="first">Haystack</p>
</li>
<li><p class="first">f4</p>
</li>
<li><p class="first">Cinder</p>
<p>&#8220;Cinder is a block storage service for Openstack&#8221;
<a class="reference internal" href="#wiki-cinder" id="id218">[177]</a>. According to <a class="reference internal" href="#book-cinder" id="id219">[178]</a> Openstack
Compute uses ephemeral disks meaning that they exist only for the
life of the Openstack instance i.e. when the instance is
terminated the disks disappear. Block storage system is a type of
persistent storage that can be used to persist data beyond the
life of the instance. Cinder provides users with access to
persistent block-level storage devices. It is designed such that
users can create block storage devices on demand and attach them
to any running instances of OpenStack
Compute. <a class="reference internal" href="#wiki-cinder" id="id220">[177]</a> This is achieved through the use of
either a reference implementation(LVM) or plugin drivers for
other storage. Cinder virtualizes the management of block storage
devices and provides end users with a self-service API to request
and consume those resources without requiring any knowledge of
where their storage is actually deployed or on what type of
device.</p>
</li>
<li><p class="first">Ceph</p>
</li>
<li><p class="first">FUSE</p>
</li>
<li><p class="first">Gluster</p>
</li>
<li><p class="first">Lustre</p>
<p>The Lustre file system <a class="reference internal" href="#www-lustre" id="id221">[179]</a> is an open-source,
parallel file system that supports many requirements of
leadership class HPC simulation environments and Enterprise
environments worldwide. Because Lustre file systems have high
performance capabilities and open licensing, it is often used in
supercomputers.Lustre file systems are scalable and can be part
of multiple computer clusters with tens of thousands of client
nodes, tens of petabytes of storage on hundreds of servers, and
more than a terabyte per second of aggregate I/O
throughput. Lustre file systems a popular choice for businesses
with large data centers, including those in industries such as
meteorology, simulation, oil and gas, life science, rich media,
and finance. Lustre provides a POSIX compliant interface and many
of the largest and most powerful supercomputers on Earth today
are powered by the Lustre file system.</p>
</li>
<li><p class="first">GPFS</p>
<p>IBM General Parallel File System (GPFS) was rebranded to IBM
Spectrum Scale on February 17, 2015.  <a class="reference internal" href="#www-wikigpfs" id="id222">[180]</a>
See 380.</p>
</li>
</ol>
<ol class="arabic" start="380">
<li><p class="first">IBM Spectrum Scale</p>
<p>General Parallel File System (GPFS) was rebranded as IBM Spectrum
Scale on February 17, 2015. <a class="reference internal" href="#www-wikigpfs" id="id223">[180]</a></p>
<p>Spectrum Scale is a clustered file system, developed by IBM, providing
high performance.  It &#8220;provides concurrent high-speed file access to
applications executing on multiple nodes of clusters&#8221; and can be
deployed in either shared-nothing or shared disk modes. Spectrum Scale
is available on AIX, Linux, Windows Server, and IBM System Cluster
1350. <a class="reference internal" href="#www-wikigpfs" id="id224">[180]</a></p>
<p>Due to its focus on performance and scalability, Spectrum Scale has
been utilized in compute clusters, big data and analytics (including
support for Hadoop Distributed File System (HDFS), backups and
restores, and private clouds. <a class="reference internal" href="#www-spectrumscale" id="id225">[181]</a></p>
</li>
</ol>
<ol class="arabic" start="296">
<li><p class="first">GFFS</p>
<p>The Global Federated File System (GFFS) <a class="reference internal" href="#www-gffs" id="id226">[182]</a> is a
computing technology that allows linking of data from Windows,
Mac OS X, Linux, AFS, and Lustre file systems into a global
namespace, making them available to multiple systems. It is a
federated, secure, standardized, scalable, and transparent
mechanism to access and share resources across organizational
boundaries It is useful when, for data resources, boundaries do
not require application modification and do not disrupt existing
data access patterns. It uses FUSE to handle access control and
allows research collaborators on remote systems to access a
shared file system. Existing applications can access resources
anywhere in the GFFS without modification. It helps in rapid
development of code, which can then be exported via GFFS and
implemented in-place on a given computational resource or Science
Gateway.</p>
</li>
<li><p class="first">Public Cloud: Amazon S3</p>
<p>Amazon Simple Storage Service (Amazon S3) <a class="reference internal" href="#www-amazon-s3" id="id227">[183]</a> is
storage object which provides a simple web service interface to
store and retrieve any amount of data from anywhere on the
web. With Amazon S3, users can store as much data as they want
and can scale it up and down based on the requirements.For
developers Amazon S3 provides full REST API&#8217;s and SDK&#8217;s which can
be integrated with third-party technologies. Amazon S3 is also
deeply integrated with other AWS services to make it easier to
build solutions that use a range of AWS services which include
Amazon CloudFront, Amazon CloudWatch, Amazon Kinesis, Amazon RDS,
Amazon Glacier etc. Amazon S3 provides auotmatic encryption of
data once the data is uploaded in the cloud. Amazon S3 uses the
concept of Buckets and Objects for storing data wherein Buckets
are used to store objects. Amazon S3 services can be used using
the Amazon Console Management. <a class="reference internal" href="#www-amazon-s3-docs" id="id228">[184]</a> The steps
for using the Amazon S3 are as follows:
1) Sign up for Amazon S3
2) After sign up, create a Bucket in your account.
3) Create an object which might be an file or folder.
4) Perform operations on the object which is stored in the cloud.</p>
</li>
<li><p class="first">Azure Blob</p>
</li>
<li><p class="first">Google Cloud Storage</p>
<p>Google Cloud Storage is the cloud enabled storage offered by
Google. <a class="reference internal" href="#www-google-cloud-storage" id="id229">[185]</a> It is unified object
storage. To have high availability and performance among
different regions in the geo-redundant storage offering. If you
want high availability and redundancy with a single region one
can go for Regional storage. Nearline and Coldline are the
different archival storage techniques. Nearline storage
offering is for the archived data which the user access less than
once a month . Coldline storage is the storage which is used
for the data which is touched less than once a year.</p>
<p>All the data in Google Cloud storage belongs inside a project. A
project will contains different buckets. Each bucket has
different objects. We need to make sure that the name of the
bucket is unique across all Google cloud name space . And the
name of the objects should unique in a bucket.</p>
</li>
</ol>
</div>
<div class="section" id="interoperability">
<h2>Interoperability<a class="headerlink" href="#interoperability" title="Permalink to this headline"></a></h2>
<ol class="arabic" start="300">
<li><p class="first">Libvirt</p>
</li>
<li><p class="first">Libcloud</p>
</li>
<li><p class="first">JClouds</p>
<p><a class="reference internal" href="#cloud-portability-book" id="id230">[186]</a> Primary goals of cross-platform
cloud APIs is that application built using these APIs can be
seamlessly ported to different cloud providers. The APIs also
bring interoperability such that cloud platforms can communicate
and exchange information using these common or shared interfaces.
Jclouds or apache jclouds <a class="reference internal" href="#www-jclouds" id="id231">[187]</a> is a java based
library to provide seamless access to cloud platforms. Jclouds
library provides interfaces for most of cloud providers like
docker, openstack, amazon web services, microsoft azure, google
cloud engine etc. It will allow users build applications which
can be portable across different cloud environments.  Key
components of jcloud are:</p>
<ol class="arabic">
<li><p class="first">Views: abstracts functionality from a specific vendor and
allow user to write more generic code. For example odbc
abstracts the underlying relational data source. However, odbc
driver converts to native format. In this case user can switch
databases without rewriting the application. Jcloud provide
following views: blob store, compute service, loadBalancer
service</p>
</li>
<li><p class="first">API: APIs are requests to execute a particular
functionality. Jcloud provide a single set of APIs for all
cloud vendors which is also location aware. If a cloud vendor
doesnt support customers from a particular region the API
will not work from that region.</p>
</li>
<li><p class="first">Provider: a particular cloud vendor is a provider. Jcloud uses
provider information to initialize its context.</p>
</li>
<li><p class="first">Context: it can be termed as a handle to a particular
provider. Its like a ODBC connection object. Once connection
is initialized for a particular database, it can used to make
any api call.</p>
<p>Jclouds provides test library to mock context, APIs etc to
different providers so that user can write unit test for his
implementation rather than waiting to test with the cloud
provider. Jcloud library certifies support after testing the
interfaces with live cloud provider. These features make
jclouds robust and adoptable, hiding most of the complexity of
cloud providers.</p>
</li>
</ol>
</li>
<li><p class="first">TOSCA</p>
</li>
<li><p class="first">OCCI</p>
<p>The Open Cloud Computing Interface (OCCI) is a RESTful
Protocol and API that provides specifications  and remote
management for the development of interoperable tools
<a class="reference internal" href="#www-occi" id="id232">[188]</a>. It supports IaaS, PaaS and SaaS and
focuses on integration, portability, interoperability,
innovation and extensibility. It provides a set of documents
that describe an OCCI Core model, contain best practices
of interaction with the model, combined into OCCI Protocols,
explain methods of communication between components via
HTTP protocol introduced in the OCCI Renderings, and
define infrastructure for IaaS presented in the OCCI
Extensions.</p>
<p>The current version 1.2 OCCI consists of seven documents that
identify require and optional components. Of the Core Model.  In
particular, the following components are required to implement:
a)Core Model, b)HTTP protocol, c)Text rendering and d)JSON
rendering. Meanwhile, Infrastructure, Platform and SLA models are
optional.  The OCCI Core model defines instance types and</p>
<p>provides a layer of abstraction that allows the OCCI client
to interact with the model without knowing of its potential
structural changes. The model supports extensibility via
inheritance and using mixin types that represent ability to
add new components and capabilities at run-time.
<a class="reference internal" href="#nyren-edmonds-papaspyrou-2016" id="id233">[189]</a></p>
<p>The OCCI Protocol defines the common set of names provided
for the IaaS cloud services user that specify requested
system requirements. It is often denoted as resource
templates or flavours   <a class="reference internal" href="#drescher-parak-wallom-2015" id="id234">[190]</a>.</p>
<p>OCCI RESTful HTTP Protocol describes communications between
server and client on OCCI platform via HTTP protocol
<a class="reference internal" href="#nyren-edmonds-metsch-2016" id="id235">[191]</a>. It defines a minimum set of HTTP
headers and status codes to ensure compliance with the
OCCI Protocol. Separate requirements for Server and Client
for versioning need to be implemented using HTTP &#8216;Server&#8217;
header and &#8216;User-Agent&#8217; header respectively.</p>
<p>JSON rendering  <a class="reference internal" href="#nyren-feldhaus-parak-2016" id="id236">[192]</a> protocol provides
JSON specifications to allow &#8220;render OCCI instances
independently of the protocol being used.&#8221; In addition, it
provides details of the JSON object declaration, OCCI Action
Invocation, object members required for OCCI Link Instance
Rendering, &#8220;location maps to OCCI Core&#8217;s source and target
model attributes and kind maps to OCCI Core&#8217;s target&#8221; to
satisfy OCCI Link Instance Source/Target Rendering requirements.
Finally, it specifies various attributes and collection
rendering requirements.
The text rendering process is depricated and will be
removed from the next major version  <a class="reference internal" href="#edmonds-metsch-2016" id="id237">[193]</a>.</p>
</li>
<li><p class="first">CDMI</p>
</li>
<li><p class="first">Whirr</p>
</li>
<li><p class="first">Saga</p>
</li>
<li><p class="first">Genesis</p>
</li>
</ol>
</div>
<div class="section" id="devops">
<h2>DevOps<a class="headerlink" href="#devops" title="Permalink to this headline"></a></h2>
<ol class="arabic" start="309">
<li><p class="first">Docker (Machine, Swarm)</p>
</li>
<li><p class="first">Puppet</p>
</li>
<li><p class="first">Chef</p>
<p>Chef is a configuration management tool. It is implemented in
Ruby and Erlang. Chef can be used to configure and maintain
servers on-premise as well as cloud platforms like Amazon EC2,
Google Cloud Platform and Open Stack. The book
<a class="reference internal" href="#chef-book" id="id238">[194]</a> explains the use of concept called &#8216;recipes&#8217; in
Chef to manage server applications and utilities such as database
servers like MySQL, or HTTP servers like Apache HTPP and systems
like Apache Hadoop.</p>
<p>Chef is available in open source version and it also has
commercial products for the companies which need it
<a class="reference internal" href="#www-chef-commercial" id="id239">[195]</a></p>
</li>
<li><p class="first">Ansible</p>
<p>Ansible is an IT automation tool that automates cloud
provisioning, configuration management, and application
deployment. <a class="reference internal" href="#www-ansible" id="id240">[196]</a> Once Ansible gets installed on a
control node, which is an agentless architecture, it connects to
a managed node through the default OpenSSH connection
type. <a class="reference internal" href="#www-ansible2" id="id241">[197]</a></p>
<p>As with most configuration management softwares, Ansible
distinguishes two types of servers: controlling machines and
nodes. First, there is a single controlling machine which is
where orchestration begins. Nodes are managed by a controlling
machine over SSH. The controlling machine describes the location
of nodes through its inventory.</p>
<p>Ansible manages machines in an agent-less manner. Ansible is
decentralized, if needed, Ansible can easily connect with
Kerberos, LDAP, and other centralized authentication management
systems.</p>
</li>
<li><p class="first">SaltStack</p>
</li>
<li><p class="first">Boto</p>
</li>
<li><p class="first">Cobbler</p>
<p>Cobbler is a Linux provisioning system that facilitates and
automates the network based system installation of multiple computer
operating systems from a central point using services such as DHCP,
TFTP and DNS <a class="reference internal" href="#www-cobbler" id="id242">[198]</a>.It is a nifty piece of code that
assemble s all the usual
setup bits required for a large network installation like TFTP, DNS,
PXE installation trees. and automates the process[1].It can be
configured for PXE, reinstallations and virtualized guests using Xen,
KVM or VMware.  Cobbler interacts with the koan program for
re-installation and virtualization support.  Cobbler builds the
Kickstart mechanism and offers installation profiles that can be
applied to one or many machines.  Cobbler has features to dynamically
change the information contained in a kickstart template (definition),
either by passing variables called ksmeta or by using so-called
snippets.</p>
</li>
<li><p class="first">Xcat</p>
</li>
<li><p class="first">Razor</p>
</li>
<li><p class="first">CloudMesh</p>
</li>
<li><p class="first">Juju</p>
<p>Juju (formerly Ensemble) <a class="reference internal" href="#juju-paper" id="id243">[199]</a> is software from
Canonical that provides open source service orchestration. It is
used to easily and quickly deploy and manage services on cloud
and physical servers. Juju charms can be deployed on cloud
services such as Amazon Web Services (AWS), Microsoft Azure and
OpenStack. It can also be used on bare metal using MAAS.
Specifically <a class="reference internal" href="#www-juju" id="id244">[200]</a> lists around 300 charms available
for services available in the Juju store. Charms can be written
in any language. It also supports Bundles which are
pre-configured collection of Charms that helps in quick
deployment of whole infrastructure.</p>
</li>
<li><p class="first">Foreman</p>
</li>
<li><p class="first">OpenStack Heat</p>
</li>
<li><p class="first">Sahara</p>
<p>The Sahara product provides users with the capability to
provision data processing frameworks (such as Hadoop, Spark and
Storm) on OpenStack <a class="reference internal" href="#www-openstack" id="id245">[201]</a> by specifying several
parameters such as the version,cluster topology and hardware node
details.As specified in <a class="reference internal" href="#www-sahara" id="id246">[202]</a> the solution allows
for fast provisioning of data processing clusters on OpenStack
for development and quality assurance and utilisation of unused
computer power from a general purpose OpenStack Iaas Cloud.Sahara
is managed via a REST API with a User Interface available as part
of OpenStack Dashboard.</p>
</li>
<li><p class="first">Rocks</p>
</li>
<li><p class="first">Cisco Intelligent Automation for Cloud</p>
</li>
<li><p class="first">Ubuntu MaaS</p>
</li>
<li><p class="first">Facebook Tupperware</p>
</li>
<li><p class="first">AWS OpsWorks</p>
<p>AWS Opsworks is a configuration service provided by Amazon Web
Services that uses Chef, a Ruby and Erlang based configuration
management tool <a class="reference internal" href="#www-wikichef" id="id247">[203]</a>, to automate the
configuration, deployment, and management of servers and
applications. There are two versions of AWS Opsworks.
The first, a fee based offering called AWS OpsWorks for Chef
Automate, provides a Chef Server and suite of tools to enable
full stack automation. The second, AWS OpsWorks Stacks, is a
free offering in which applications are modeled as stacks
containing various layers. Amazon Elastic Cloud Compute (EC2)
instances or other resources can be deployed and configured
in each layer. <a class="reference internal" href="#www-awsopsworks" id="id248">[204]</a></p>
</li>
<li><p class="first">OpenStack Ironic</p>
</li>
<li><p class="first">Google Kubernetes</p>
</li>
<li><p class="first">Buildstep</p>
<p>Buildsteps is an open software developed under MIT license.
It is a base for Dockerfile and it activates Heroku-style
application. Heroku is a platform-as-service (PaaS) that
automates deployment of applications on the cloud. The
program is pushed to the PaaS using git push, and then
PaaS detects the programming language, builds, and runs
application on a cloud platform <a class="reference internal" href="#plassnig-2015" id="id249">[205]</a>.
Buildstep takes two parameters: a tar file that contains
the application and a new application container name to
create a new container for this application. Build script
is dependent on buildpacks that are pre-requisites for
buildstep to run. The builder script runs inside the new
container.  The resulting build app can be run with Docker
using docker build -t your_app_name command.
<a class="reference internal" href="#gonzalez-2015" id="id250">[206]</a>.</p>
</li>
<li><p class="first">Gitreceive</p>
</li>
<li><p class="first">OpenTOSCA</p>
</li>
<li><p class="first">Winery</p>
<p>Eclipse Winery <a class="reference internal" href="#www-winery" id="id251">[207]</a> is a &#8220;web-based environment to
graphically model [Topology and Orchestration Specification for
Cloud Applications] TOSCA topologies and plans managing these
topologies.&#8221; Winery <a class="reference internal" href="#winery-paper-2013" id="id252">[208]</a> is a &#8220;tool
offering an HTML5-based environment for graph-based modeling of
application topologies and defining reusable component and
relationship types.&#8221; This web-based <a class="reference internal" href="#winery-paper-2013" id="id253">[208]</a>
interface enables users to drag and drop icons to create
automated &#8220;provisioning, management, and termination of
applications in a portable and interoperable way.&#8221;
Essentially, this web-based interface <a class="reference internal" href="#winery-paper-2013" id="id254">[208]</a>
allows users to create an application topology, which
&#8220;describes software and hardware components involved and
relationships between them&#8221; as well a management plan, which
&#8220;captures knowledge [regarding how] to deploy and manage an
application.&#8221;</p>
</li>
<li><p class="first">CloudML</p>
</li>
<li><p class="first">Blueprints</p>
<p>In <a class="reference internal" href="#www-blueprints" id="id255">[209]</a>, it is explained that &#8220;IBM Blueprint
has been replaced by IBM Blueworks Live.&#8221; In
<a class="reference internal" href="#www-blueworks-live2" id="id256">[210]</a>, IBM Blueworks Live is described &#8220;as
a cloud-based business process modeller, belonging under the set
of IBM SmartCloud applications&#8221; that as
<a class="reference internal" href="#www-blueworks-live" id="id257">[211]</a> states &#8220;drive[s] out inefficiencies
and improve[s] business operations.&#8221; Similarly to Google Docs,
IBM Blueworks Live is &#8220;designed to help organizations discover
and document their business processes, business decisions and
policies in a collaborative manner.&#8221; While Google Docs and IBM
Blueworks Live are both simple to use in a collaborative manner,
<a class="reference internal" href="#www-blueworks-live2" id="id258">[210]</a> explains that IBM Blueworks Live
has the &#8220;capabilities to implement more complex models.&#8221;</p>
</li>
<li><p class="first">Terraform</p>
</li>
<li><p class="first">DevOpSlang</p>
</li>
<li><p class="first">Any2Api</p>
<p>This framework <a class="reference internal" href="#wettinger-any2api" id="id259">[212]</a> allows user to wrap an
executable program or scripts, for example scripts, chef
cookbooks, ansible playbooks, juju charms, other compiled
programs etc. to generate APIs from your existing code.  These
APIs are also containerized so that they can be hosted on a
docker container, vagrant box etc Any2Api helps to deal with
problems like scale of application, technical expertise, large
codebase and different API formats. The generated API hide the
tool specific details simplifying the integration and
orchestration different kinds of artifacts. The APIfication
framework contains various modules:</p>
<ol class="arabic simple">
<li>Invokers, which are capable of running a given type of
executable for example cookbook invoker can be used to run Chef
cookbooks</li>
<li>Scanners, which are capable of scanning modules of certain type for
example cookbook scanner scans Chef cookbooks.</li>
<li>API impl generators, which are doingthe actual work to
generate the API implementation.</li>
</ol>
<p>The final API implementation <a class="reference internal" href="#www-any2api" id="id260">[213]</a> is is packages
with executable in container.  The module is packaged as npm
module. Currently any2api-cli provides a command line interface
and web based interface is planned for future
development. Any2Api is very useful for by devops to orchestrate
open source ecosystem without dealing with low level details of
chef cookbook or ansible playbook or puppet. It can also be very
useful in writing microservices where services talk to each other
using well defined APIs.</p>
</li>
</ol>
</div>
<div class="section" id="iaas-management-from-hpc-to-hypervisors">
<h2>IaaS Management from HPC to hypervisors<a class="headerlink" href="#iaas-management-from-hpc-to-hypervisors" title="Permalink to this headline"></a></h2>
<ol class="arabic" start="339">
<li><p class="first">Xen</p>
<p>Xen is the only open-source bare-metal hypervisor based on
microkernel design <a class="reference internal" href="#www-xen-wikipedia" id="id261">[214]</a>. The hypervisor
runs at the highest privilege among all the processes on the
host. It&#8217;s responsibility is to manage CPU and memory and
handle interrupts <a class="reference internal" href="#www-xen-overview" id="id262">[215]</a>. Virtual
machines are deployed in the guest domain called DomU which
has no access privilege to hardware. A special virtual machine
is deployed in the control domain called Domain 0. It contains
hardware drivers and the toolstack to control the VMs and is
the first VM to be deployed. Xen supports both Paravirtualization
and hardware assisted virtualization. The hypervisor itself has
a very small footprint. It&#8217;s being actively maintained by Linux
Foundation under the trademark &#8220;XEN Project&#8221;. Some of the
features included in the latest releases include &#8220;Reboot-free
Live Patching&#8221; (to enable application of security patches without
rebooting the system) and KCONFIG support (compilation support to
create a lighter version for requirements such as embedded
systems) <a class="reference internal" href="#www-xen-fl" id="id263">[216]</a>.</p>
</li>
<li><p class="first">KVM</p>
</li>
<li><p class="first">QEMU</p>
<p>QEMU (Quick Emulator) is a generic open source hosted hypervisor
<a class="reference internal" href="#www-hypervisor" id="id264">[217]</a> that performs hardware virtualization
(virtualization of computers as complete hardware platform,
certain logical abstraction of their componentry or only the
certain functionality required to run various operating systems)
<a class="reference internal" href="#www-qemu" id="id265">[218]</a> and also emulates CPUs through dynamic binary
translations and provides a set of device models, enabling it to
run a variety of unmodified guest operating systems.</p>
<p>When used as an emulator, QEMU can run Operating Systems and programs
made for one machine (ARM board) on a different machine (e.g. a
personal computer) and achieve good performance by using dynamic
translations.  When used as a virtualizer, QEMU achieves near native
performance by executing the guest code directly on the host CPU. QEMU
supports virtualization when executing under the Xen hypervisor or
using KVM kernel module in Linux <a class="reference internal" href="#www-qemuwiki" id="id266">[219]</a>.</p>
<p>Compared to other virtualization programs like VMWare and VirtualBox,
QEMU does not provide a GUI interface to manage virtual machines nor
does it provide a way to create persistent virtual machine with saved
settings. All parameters to run virtual machine have to be specified
on a command line at every launch. Its worth noting that there are
several GUI front-ends for QEMU like virt-manager and gnome-box.</p>
</li>
<li><p class="first">Hyper-V</p>
</li>
<li><p class="first">VirtualBox</p>
</li>
<li><p class="first">OpenVZ</p>
</li>
<li><p class="first">LXC</p>
</li>
<li><p class="first">Linux-Vserver</p>
</li>
<li><p class="first">OpenStack</p>
</li>
<li><p class="first">OpenNebula</p>
</li>
<li><p class="first">Eucalyptus</p>
</li>
<li><p class="first">Nimbus</p>
<p>Nimbus Infrastructure <a class="reference internal" href="#www-nimbus-wiki" id="id267">[220]</a> is an open source
IaaS implementation. It allows deployment of self-configured
virtual clusters and it supports configuration of scheduling,
networking leases, and usage metering.</p>
<p>Nimbus Platform <a class="reference internal" href="#www-nimbus" id="id268">[221]</a> provides an integrated set of
tools which enable users to launch large virtual clusters as well
as launch and monitor the cloud apps. It also includes service
that provides auto-scaling and high availability of resources
deployed over multiple IaaS cloud.  The Nimubs Platform tools are
cloudinit.d, Phantom and Context Broker.  In this paper
<a class="reference internal" href="#nimbus-paper" id="id269">[222]</a>, the use of Nimbus Phantom
to deploy auto-scaling solution across multiple NSF FutureGrid
clouds is explained. In this implementation Phantom was responsible
for deploying instances across multiple clouds and monitoring those
instance.  Nimbus platform supports Nimbus, Open Stack, Amazon
and several other clouds.</p>
</li>
<li><p class="first">CloudStack</p>
<p>Apache CloudStack is open source software designed to deploy and
manage large networks of virtual machines, as a highly available,
highly scalable Infrastructure as a Service (IaaS) cloud
computing platform. It uses existing hypervisors such as KVM,
VMware vSphere, and XenServer/XCP for virtualization. In addition
to its own API, CloudStack also supports the Amazon Web Services
(AWS) API and the Open Cloud Computing Interface from the Open
Grid Forum. [www-clodstack]</p>
<p>ColudStack features like built-in high-availability for hosts
and VMs, AJAX web GUI for management, AWS API compatibility,
Hypervisor agnostic, snapshot management, usage metering, network
management (VLAN&#8217;s, security groups), virtual routers, firewalls,
load balancers and multi-role support. <a class="reference internal" href="#www-cloudstack2" id="id271">[223]</a></p>
</li>
<li><p class="first">CoreOS</p>
<p><a class="reference internal" href="#www-core" id="id272">[224]</a> states that CoreOS is a linux operating system
used for clustered deployments. CoreOS allows applications to
run on containers. CoreOS can be run on clouds, virtual or
physical servers. CoreOS allows the ability for automatic software
updates inorder to make sure containers in cluster are secure and
reliable. It also makes managing large cluster environements
easier. CoreOS provides open source tools like CoreOS Linux,
etcd,rkt and flannel. CoreOS also has commercial products
Kubernetes and CoreOS stack. Core OS. In CoreOS linux service
discovery is achieved by etcd, applications are run on Docker and
process management is achieved by fleet.</p>
</li>
<li><p class="first">rkt</p>
</li>
<li><p class="first">VMware ESXi</p>
</li>
<li><p class="first">vSphere and vCloud</p>
</li>
<li><p class="first">Amazon</p>
</li>
<li><p class="first">Azure</p>
</li>
<li><p class="first">Google and other public Clouds</p>
</li>
<li><p class="first">Networking: Google Cloud DNS</p>
</li>
<li><p class="first">Amazon Route 53</p>
</li>
</ol>
</div>
<div class="section" id="cross-cutting-functions">
<h2>Cross-Cutting Functions<a class="headerlink" href="#cross-cutting-functions" title="Permalink to this headline"></a></h2>
<div class="section" id="monitoring">
<h3>Monitoring<a class="headerlink" href="#monitoring" title="Permalink to this headline"></a></h3>
<ol class="arabic" start="361">
<li><p class="first">Ambari</p>
</li>
<li><p class="first">Ganglia</p>
</li>
<li><p class="first">Nagios <a class="reference internal" href="#www-nagios" id="id273">[225]</a></p>
<p>Nagios is a platform, which provides a set of software for
network infrastructure monitoring. It also offers administrative
tools to diagnose when failure events happen, and to notify
operators when hardware issues are detected. Specifically,
illustrates that Nagios is consist of modules including
<a class="reference internal" href="#nagios-book" id="id274">[226]</a>: a core and its dedicated tool for core
configuration, extensible plugins and its frontend. Nagios core
is designed with scalability in mind.  Nagios contains a
specification language allowing for building an extensible
monitoring systems.  Through the Nagios API components can
integrate with the Nagios core services. Plugins can be developed
via static languages like C or script languages. This mechanism
empowers Nagios to monitor a large set of various scenarios yet
being very flexible. <a class="reference internal" href="#nagios-paper-2012" id="id275">[227]</a> Besides its open
source components, Nagios also has commercial products to serve
needing clients.</p>
</li>
<li><p class="first">Inca</p>
<p>Inca is a grid monitoring <a class="reference internal" href="#inca-book" id="id276">[228]</a> software suite. It
provides grid monitoring features. These monitoring features
provide operators failure trends, debugging support, email
notifications, environmental issues etc. <a class="reference internal" href="#www-inca" id="id277">[229]</a>. It
enables users to automate the tests which can be executed on a
periodic basis. Tests can be added and configured as and when
needed. It helps users with different portfolios like system
administrators, grid operators, end users etc Inca provides
user-level grid monitoring. For each user it stores results as
well as allows users to deploy new tests as well as share the
results with other users. The incat web ui allows users to view
the status of test, manage test and results. The architectural
blocks of inca include report repository, agent, data consumers
and depot. Reporter is an executable program which is used to
collect the data from grid source. Reporters can be written in
perl and python. Inca repository is a collection of pre build
reporters.  These can be accessed using a web url. Inca
repository has 150+ reporters available. Reporters are versioned
and allow automatic updates. Inca agent does the configuration
management. Agent can be managed using the incat web ui. Inca
depot provides storage and archival of reports. Depot uses
relational database for this purpose. The database is accessed
using hibernate backend.  Inca web UI or incat provides real time
as well as historical view of inca data.  All communication
between inca components is secured using SSL certificates. It
requires user credentials for any access to the
system. Credentials are created at the time of the setup and
installation. Inca&#8217;s performance has been phenomenal in
production deployments. Some of the deployments are running for
more than a decade and has been very stable. Overall Inca
provides a solid monitoring system which not only monitors but
also detects problems very early on.</p>
</li>
</ol>
</div>
<div class="section" id="security-privacy">
<h3>Security &amp; Privacy<a class="headerlink" href="#security-privacy" title="Permalink to this headline"></a></h3>
<ol class="arabic" start="365">
<li><p class="first">InCommon</p>
</li>
<li><p class="first">Eduroam <a class="reference internal" href="#www-eduroam" id="id278">[230]</a></p>
<p>Eduroam is an initiative started in the year 2003 when the number
of personal computers with in the academia are growing
rapidly. The goal is to solve the problem of secure access to
WI-FI due to increasing number of students and reasearch teams
becoming mobile which was increasing the administrative problems
for provide access to WI-FI. Eduroam provides any user from an
eduroam participating site to get network access at any
instituion connected through eduroam. According to the
orgnizatioin it uses a combination of radius-based infrastructuor
with 802.1X standard techonology to provide roaming acess across
reasearch and educational networks. The role of the RADIUS
hierarchy is to forward user crednetials to the users home
instituion where they can be verified. This proved to be a
successful solution when compared to other traditonal ways like
using MAC-adress, SSID, WEP, 802.1x(EAP-TLS, EAP-TTLS), VPN
Clients, Mobile-IP etc which have their own short comings when
used for this purpose <a class="reference internal" href="#eduroam-paper-2005" id="id279">[231]</a>. Today by
enabling eduroam users get access to internet across 70 countries
and tens of thousands of access points worldwide.</p>
</li>
<li><p class="first">OpenStack Keystone</p>
</li>
<li><p class="first">LDAP</p>
<p>LDAP stands for Lightweight Directory Access Protocol. It is a software
protocol for enabling anyone to locate organizations, individuals, and
other resources such as files and devices in a network, whether on the
Internet or on corporate internet.
<a class="reference internal" href="#www-ldap" id="id280">[232]</a></p>
<p>LDAP is a &#8220;lightweight&#8221; (smaller amount of code) version of
Directory Access Protocol (DAP), which is part of X.500, a
standard for directory services in a network.  In a network, a
directory tells you where in the network something is located. On
TCP/IP networks (including the Internet), the domain name system
(DNS) is the directory system used to relate the domain name to a
specific network address (a unique location on the
network). However, you may not know the domain name. LDAP allows
you to search for an individual without knowing where they&#8217;re
located (although additional information will help with the
search).An LDAP directory can be distributed among many
servers. Each server can have a replicated version of the total
directory that is synchronized periodically.  An LDAP server is
called a Directory System Agent (DSA). An LDAP server that
receives a request from a user takes responsibility for the
request, passing it to other DSAs as necessary, but ensuring a
single coordinated response for the user.</p>
</li>
<li><p class="first">Sentry</p>
</li>
<li><p class="first">Sqrrl</p>
</li>
<li><p class="first">OpenID</p>
</li>
<li><p class="first">SAML OAuth</p>
</li>
</ol>
</div>
<div class="section" id="distributed-coordination">
<h3>Distributed Coordination<a class="headerlink" href="#distributed-coordination" title="Permalink to this headline"></a></h3>
<ol class="arabic" start="373">
<li><p class="first">Google Chubby</p>
</li>
<li><p class="first">Zookeeper</p>
<p>Zookeeper provides coordination services to distributed applications.
It includes synchronization, configuration management and naming
services among others. The interfaces are available in Java and C
<a class="reference internal" href="#www-zoo-overiew" id="id281">[233]</a>. The services themselves can be distributed
across multiple Zookeeper servers to avoid single point of failure.
If the leader fails to answer, the clients can fall-back to other
nodes. The state of the cluster is maintained in an in-memory image
along with a persistent storage file called znode by each server. The
cluster namespace is maintained in a hierarchical order. The changes to the
data are totally ordered <a class="reference internal" href="#www-zoo-wiki" id="id282">[234]</a> by stamping each update
with a number. Clients can also set a watch on a znode to be notified
of any change <a class="reference internal" href="#www-zoo-ibm" id="id283">[235]</a>. The performance of the ZooKeeper
is optimum for &#8220;read-dominant&#8221; workloads. It&#8217;s maintained by Apache
and is open-source.</p>
</li>
<li><p class="first">Giraffe</p>
<p>Giraffe is a scalable distributed coordination
service. Distributed coordination is a media access technique
used in distributed systems to perform functions like providing
group membership, gaining lock over resources, publishing,
subscribing, granting ownership and synchronization together
among multiple servers without issues. Giraffe was proposed as
alternative to coordinating services like Zookeeper and Chubby
which were efficient only in read-intensive scenario and small
ensembles. To overcome this three important aspects were included
in the design of Giraffe <a class="reference internal" href="#giraffepaper" id="id284">[236]</a>. First feature is
Giraffe uses interior-node joint trees to organize coordination
servers for better scalability. Second, Giraffe uses Paxos
protocol for better consistency and to provide more
fault-tolerance. Finally, Giraffe also facilitates hierarchical
data organization and in-memory storage for high throughput and
low latency.</p>
</li>
<li><p class="first">JGroups</p>
</li>
</ol>
</div>
<div class="section" id="message-and-data-protocols">
<h3>Message and Data Protocols<a class="headerlink" href="#message-and-data-protocols" title="Permalink to this headline"></a></h3>
<ol class="arabic" start="377">
<li><p class="first">Avro</p>
</li>
<li><p class="first">Thrift</p>
</li>
<li><p class="first">Protobuf</p>
<p>Protocol Buffer <a class="reference internal" href="#www-protobuf" id="id285">[237]</a> is a way to serialize
structured data into binary form (stream of bytes) in order to
transfer it over wires or for storage. It is used for inter
apllication communication or for remote procedure call (RPC). It
involves a interface description that describes the structure of
some data and a program that can generate source code or parse it
back to the binary form. It emphasizes on simplicity and
performance over xml. Though xml is more readable but requires
more resources in parsing and storing.  This is developed by
Google and available under open source licensing. The parser
program is available in many languages including java and python.</p>
</li>
</ol>
</div>
</div>
<div class="section" id="new-technologies-to-be-integrated">
<h2>New Technologies to be integrated<a class="headerlink" href="#new-technologies-to-be-integrated" title="Permalink to this headline"></a></h2>
<ol class="arabic simple" start="382">
<li>TBD</li>
</ol>
</div>
<div class="section" id="excersise">
<span id="techs-exercise"></span><h2>Excersise<a class="headerlink" href="#excersise" title="Permalink to this headline"></a></h2>
<dl class="docutils">
<dt>TechList.1: In class you will be given an HID and you will be assigned</dt>
<dd><p class="first">a number of technologies that you need to research and create a
summary as well as one or more relevant references to be added to the
Web page. All technologies for TechList.1 are marked with a (1)
behind the technology.  An example text is given for Nagios in this
page.  Please create a pull request with your responses. You are
responsible for making sure the request shows up and each commit is
using gitchangelog in the commit message:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">new</span><span class="p">:</span><span class="n">usr</span><span class="p">:</span> <span class="n">added</span> <span class="n">paragraph</span> <span class="n">about</span> <span class="o">&lt;</span><span class="n">PUTTECHHERE</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>You can create one or more pull requests for the technology and the
references. We have created in the referens file a placeholder using
your HID to simplify the management of the references while avoiding
conflicts.  For the technologies you are responsible to invesitgate
them and write an academic summary of the technology. Make sure to
add your reference to refs.bib.  Many technologies may have
additional references than the Web page. Please add the most
important once while limiting it to three if you can. Avoid
plagearism and use proper quotations or better rewrite the text.</p>
<p>You must look at <a class="reference internal" href="technologies-hw.html"><span class="doc">Completing Techlist Assignments</span></a> to sucessfully complete the
homework</p>
<p>A video about this hoemwork is posted at
<a class="reference external" href="https://www.youtube.com/watch?v=roi7vezNmfo">https://www.youtube.com/watch?v=roi7vezNmfo</a> showing how to
do references in emacs and jabref, it shows you how to configure
git, it shows you how to do the fork request while asking you to add
&#8220;new:usr ....&#8221; to the commit messages). As this is a homework
realated video we put a lot of information in it that is not only
useful for beginners. We recommend you watch it.</p>
<p>This homework can be done in steps. First you can collect all the
content in an editor. Second you can create a fork. Third you can
add the new content to the fork. Fourth you can commit. Fith you
can push. Six if the TAs have commend improve. The commit message
must have new:usr: at the beginning.</p>
<p>While the Nagios entry is a good example (make sure grammer is ok
the Google app engine is an example for a bad entry.</p>
<p class="last">Do Techlist 1.a 1.b 1.c first. We  will assign Techlist 1.d and
TechList 2 in February.</p>
</dd>
<dt>TechList.1.a:</dt>
<dd>Complete the pull request with the technologies assigned to you.
Details for the assignment are posted in Piazza. Search for TechList.</dd>
<dt>TechList.1.b: Identify how to cite. We are using &#8220;scientific&#8221; citation</dt>
<dd>formats such as IEEEtran, and ACM. We are <strong>not</strong> using citation
formats such as Chicago, MLA, or ALP. The later are all for non
scientific publications and thus of no use to us. Also when writing
about a technology do not use the names of the person, simply say
something like. In [1] the definition of a turing machine is given
as follows, ...  and do not use elaborate sentences such as: In his
groundbraking work conducted in England, Allan Turing, introduced
the turing machine in the years 1936-37 [2]. Its definition is base
on ... The difference is clear, while the first focusses on results
and technological concepts, the second introduces a colorful
description that is more suitable for a magazine or a computer
history paper.</dd>
<dt>TechList 1.c:</dt>
<dd>Learn about Plagearism and how to avoid it.
Many Web pages will conduct self advertisement while adding
suspicious and subjective adjectives or phrases such as cheaper,
superior, best, most important, with no equal, and others that you
may not want to copy into your descriptions. Please focus on facts
not on what the author of the Web page claims.</dd>
<dt>TechList 1.d:</dt>
<dd>Identify technologies from the Apache project or other
Big Data related Web pages and projects that are not yet listed here
and add the name and descriptions as well as references and that you
find important.</dd>
<dt>TechList.2:</dt>
<dd>In this hopweork we provide you with additional technologies
that you need to compleate They are marked with (2) in the HID
assignment.</dd>
<dt>TechList.3:</dt>
<dd>Identify technologies that are not listed here and add
them. Provide a description and a refrence just as you did before.
Make sure duplicated entries will be merged. Before you start doing a
technology to avoid adding technologies that have already been done by
others.</dd>
</dl>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline"></a></h2>
<p id="bibtex-bibliography-i524/technologies-0"><table class="docutils citation" frame="void" id="www-taverna" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>Taverna. Web Page. URL: <a class="reference external" href="https://taverna.incubator.apache.org/introduction/">https://taverna.incubator.apache.org/introduction/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="taverna-paper" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[2]</a></td><td><em>Taverna Workflows: Syntax and Semantics</em>, IEEE, December 2007. URL: <a class="reference external" href="http://ieeexplore.ieee.org/document/4426917/">http://ieeexplore.ieee.org/document/4426917/</a>, <a class="reference external" href="http://dx.doi.org/10.1109/E-SCIENCE.2007.71">doi:10.1109/E-SCIENCE.2007.71</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-trident-tutorial" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[3]</td><td><em>(<a class="fn-backref" href="#id3">1</a>, <a class="fn-backref" href="#id4">2</a>, <a class="fn-backref" href="#id6">3</a>)</em> Trident tutorial. Web Page. Accessed: 2017-1-24. URL: <a class="reference external" href="http://storm.apache.org/releases/0.10.1/Trident-tutorial.html">http://storm.apache.org/releases/0.10.1/Trident-tutorial.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-trident-overview" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id5">[4]</a></td><td>Trident api overview. Web Page. Accessed: 2017-1-24. URL: <a class="reference external" href="http://storm.apache.org/releases/1.0.0/Trident-API-Overview.html">http://storm.apache.org/releases/1.0.0/Trident-API-Overview.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-biokepler" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id7">[5]</a></td><td>What is biokepler. WebPage. URL: <a class="reference external" href="http://www.biokepler.org/faq#what-is-biokepler">http://www.biokepler.org/faq#what-is-biokepler</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-biokepler-demos" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id8">[6]</a></td><td>Demo workflow. WebPage. URL: <a class="reference external" href="http://www.biokepler.org/userguide#demos">http://www.biokepler.org/userguide#demos</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="bioactors" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id9">[7]</a></td><td>Weizhong Li, editor. <em>Introduction to bioActors</em>, number&nbsp;1st in 1st Workshop on bioKepler Tools and Its Applications, UCSD;SDSC, September 2012. URL: <a class="reference external" href="http://www.biokepler.org/sites/swat.sdsc.edu.biokepler/files/workshops/2012-09-05/slides/2012-09-05-02-Li.pdf">http://www.biokepler.org/sites/swat.sdsc.edu.biokepler/files/workshops/2012-09-05/slides/2012-09-05-02-Li.pdf</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-cascading" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id10">[8]</a></td><td>Cascading. Web Page, 2017. URL: <a class="reference external" href="http://www.cascading.org/projects/cascading/">http://www.cascading.org/projects/cascading/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="e-science-central-paper-2010" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[9]</td><td><em>(<a class="fn-backref" href="#id11">1</a>, <a class="fn-backref" href="#id12">2</a>, <a class="fn-backref" href="#id14">3</a>, <a class="fn-backref" href="#id15">4</a>)</em> Hugo Hiden, Paul Watson, Simon Woodman, and David Leahy. E-science central: cloud-based e-science and its application to chemical property modelling. In <em>University of Newcastle upon Tyne, Computing Science, Technical Report Series, No. CS-TR-1227</em>. University of Newcastle upon Tyne, November 2010.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-e-science-central" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id13">[10]</a></td><td>Escience central overview. Web Page. Accessed: 2017-1-24. URL: <a class="reference external" href="https://bitbucket.org/digitalinstitute/esciencecentral/">https://bitbucket.org/digitalinstitute/esciencecentral/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-dataflow" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id16">[11]</a></td><td>Cloud dataflow. WebPage. URL: <a class="reference external" href="https://cloud.google.com/dataflow/">https://cloud.google.com/dataflow/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-googlelivestream" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id17">[12]</a></td><td>Jacob Jackson. Google service analyzes live streaming data. WebPage, June 2014. URL: <a class="reference external" href="http://www.infoworld.com/article/2607938/data-mining/google-service-analyzes-live-streaming-data.html">http://www.infoworld.com/article/2607938/data-mining/google-service-analyzes-live-streaming-data.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-mahout" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id18">[13]</a></td><td>Apache mahout. Web Page. URL: <a class="reference external" href="http://mahout.apache.org/">http://mahout.apache.org/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-datafu" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id19">[14]</a></td><td>Datafu. Web Page. Accessed:1/16/2017. URL: <a class="reference external" href="https://datafu.incubator.apache.org/">https://datafu.incubator.apache.org/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-r" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id20">[15]</a></td><td>R: what is r? Web Page. Accessed: 2017-1-26. URL: <a class="reference external" href="https://www.r-project.org/about.html">https://www.r-project.org/about.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="book-r" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id21">[16]</a></td><td>Vignesh Prajapati. <em>Big data analytics with R and Hadoop</em>. Packt Publishing, 2013. ISBN 9781782163282.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-pbdr" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id22">[17]</a></td><td>G.&nbsp;Ostrouchov, W.-C. Chen, D.&nbsp;Schmidt, and P.&nbsp;Patel. Web Page, 2012. URL: <a class="reference external" href="http://r-pbd.org/">http://r-pbd.org/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-azuremlsite" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id23">[18]</a></td><td>Azure machine learning. Web Page. Accessed: 2017-1-28. URL: <a class="reference external" href="https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-what-is-machine-learning#what-is-machine-learning-in-the-microsoft-azure-cloud">https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-what-is-machine-learning#what-is-machine-learning-in-the-microsoft-azure-cloud</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-prediction" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id24">[19]</a></td><td>Google cloud prediction api documentation. WebPage. Accessed 2017-1-26. URL: <a class="reference external" href="https://cloud.google.com/prediction/docs/">https://cloud.google.com/prediction/docs/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-translation" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id25">[20]</a></td><td>Google cloud translation api documentation. WebPage. URL: <a class="reference external" href="https://cloud.google.com/translate/docs/">https://cloud.google.com/translate/docs/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-caffe" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id26">[21]</a></td><td>Caffe-deep learning. Accessed: 02-06-2017. URL: <a class="reference external" href="http://caffe.berkeleyvision.org/">http://caffe.berkeleyvision.org/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-torch" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id27">[22]</a></td><td>Torch-machine learning. Accessed: 02-06-2017. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/Torch_(machine_learning)">https://en.wikipedia.org/wiki/Torch_(machine_learning)</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-dl4j" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id28">[23]</a></td><td>DL4j. Webpage. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/Deeplearning4j">https://en.wikipedia.org/wiki/Deeplearning4j</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-ibmwatson-wiki" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id29">[24]</a></td><td>Ibm watson. Web Page. Accessed: 2017-1-25. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/Watson_(computer)">https://en.wikipedia.org/wiki/Watson_(computer)</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-ibmwatson" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[25]</td><td><em>(<a class="fn-backref" href="#id30">1</a>, <a class="fn-backref" href="#id31">2</a>)</em> Ibm watson product page. Web Page. Accessed: 2017-1-25. URL: <a class="reference external" href="https://www.ibm.com/watson">https://www.ibm.com/watson</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-graphlab" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id32">[26]</a></td><td>Graphlab. Webpage. Accessed: 2017-01-28. URL: <a class="reference external" href="http://www.select.cs.cmu.edu/code/graphlab/">http://www.select.cs.cmu.edu/code/graphlab/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-graphx" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id33">[27]</a></td><td>GraphX. Web Page. Accessed: 2017-01-30. URL: <a class="reference external" href="http://spark.apache.org/graphx/">http://spark.apache.org/graphx/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-graphx1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id34">[28]</a></td><td>Reynold&nbsp;S. Xin, Joseph&nbsp;E. Gonzalez, Michael&nbsp;J. Franklin, and Ion Stoica. Graphx: a resilient distributed graph system on spark. In <em>First International Workshop on Graph Data Management Experiences and Systems</em>, GRADES &#8216;13, 2:12:6. New York, NY, USA, 2013. ACM. URL: <a class="reference external" href="http://doi.acm.org/10.1145/2484425.2484427">http://doi.acm.org/10.1145/2484425.2484427</a>, <a class="reference external" href="http://dx.doi.org/10.1145/2484425.2484427">doi:10.1145/2484425.2484427</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-news" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id35">[29]</a></td><td>Dylan Raithel. Apache tinkerpop graduates to top-level project. Web Page, 2016. URL: <a class="reference external" href="https://www.infoq.com/news/2016/06/tinkerpop-top-level-apache/">https://www.infoq.com/news/2016/06/tinkerpop-top-level-apache/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-apachetinkerpophome" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id36">[30]</a></td><td>Apache Tinker Pop Home. Apache tinkerpop home. Web Page, 2016. URL: <a class="reference external" href="https://tinkerpop.apache.org/">https://tinkerpop.apache.org/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="dream" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[31]</td><td><em>(<a class="fn-backref" href="#id37">1</a>, <a class="fn-backref" href="#id38">2</a>)</em> Overview. Online. The contact information listed on the webpage was for Yogesh Simmhan. URL: <a class="reference external" href="http://dream-lab.cds.iisc.ac.in/about/overview/">http://dream-lab.cds.iisc.ac.in/about/overview/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="rao" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[32]</td><td><em>(<a class="fn-backref" href="#id39">1</a>, <a class="fn-backref" href="#id40">2</a>)</em> Siddharth Rao. Dream:lab  democratising computing through the cloud. Online, March 2016. URL: <a class="reference external" href="http://iisc.researchmedia.center/article/dreamlab-">http://iisc.researchmedia.center/article/dreamlab-</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="denero" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[33]</td><td><em>(<a class="fn-backref" href="#id41">1</a>, <a class="fn-backref" href="#id42">2</a>)</em> John Denero. <em>CS61A: Online Textbook</em>. Berkeley, http://www-inst.eecs.berkeley.edu/~cs61a/sp12/book/, 2011. &#8220;This book is derived from the classic textbook Structure and Interpretation of Computer Programs by Abelson, Sussman, and Sussman. John Denero originally modified if for Python for the Fall 2011 semester.&#8221; http://www-inst.eecs.berkeley.edu/~cs61a/sp12/book/. URL: <a class="reference external" href="http://www-inst.eecs.berkeley.edu/~cs61a/sp12/book/communication.html">http://www-inst.eecs.berkeley.edu/~cs61a/sp12/book/communication.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-fusiontablesupport" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id43">[34]</a></td><td>Google. Fusiontablesupporthelp. Web Page, 2017. URL: <a class="reference external" href="https://support.google.com/fusiontables/answer/171181?hl=en">https://support.google.com/fusiontables/answer/171181?hl=en</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="wiki-fusiontable" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id44">[35]</a></td><td>Wikipedia. Fusion table support. Web Page, Last updated in 1 November 2016. URL: <a class="reference external" href="https://support.google.com/fusiontables/answer/171181?hl=en">https://support.google.com/fusiontables/answer/171181?hl=en</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="googlefusiontable2012" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id45">[36]</a></td><td>Google. Google fusion tables: data management, integration and collaboration in the cloud. 2012. URL: <a class="reference external" href="http://homes.cs.washington.edu/~alon/files/socc10.pdf">http://homes.cs.washington.edu/~alon/files/socc10.pdf</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-nwb-edu" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id46">[37]</a></td><td>Nwb. Web Page, 2017. URL: <a class="reference external" href="http://nwb.cns.iu.edu/about.html">http://nwb.cns.iu.edu/about.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-elasticsearch" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id47">[38]</a></td><td>Elastic search. Web Page. Accessed: 2017-1-25. URL: <a class="reference external" href="https://www.elastic.co/products/elasticsearch">https://www.elastic.co/products/elasticsearch</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-elasticsearch-intro" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id48">[39]</a></td><td>Elastic search getting started. Web Page. Accessed: 2017-1-25. URL: <a class="reference external" href="https://www.elastic.co/guide/en/elasticsearch/reference/current/getting-started.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/getting-started.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="elasticsearch-book" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id49">[40]</a></td><td>Clinton Gormley and Zachary Tong. <em>Elasticsearch - The Definitive Guide : A Distributed REAL-TIME SEARCH AND ANALYTICS ENGINE</em>. O&#8217;Reilly Media,Inc, 1005 Gravenstein Highway North, Sebastopol, CA 95472, 1st edition, 2015. ISBN 9781449358549.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-elasticsearch-hadoop" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id50">[41]</a></td><td>Elastic search on hadoop. Web Page. Accessed: 2017-1-25. URL: <a class="reference external" href="https://www.elastic.co/products/hadoop">https://www.elastic.co/products/hadoop</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-wikipedia-elasticsearch" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id51">[42]</a></td><td>Elastic Search. Web Page. Accessed: 2017-1-25. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/Elasticsearch">https://en.wikipedia.org/wiki/Elasticsearch</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-logstash" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id52">[43]</a></td><td>Logstash. Webpage. URL: <a class="reference external" href="https://www.elastic.co/guide/en/logstash/current/introduction.html">https://www.elastic.co/guide/en/logstash/current/introduction.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-dcjs" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id53">[44]</a></td><td>Dc.js - dimensional charting javascript library. Web Page. accessed: 2017-01-21. URL: <a class="reference external" href="https://dc-js.github.io/dc.js/">https://dc-js.github.io/dc.js/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-gae" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id54">[45]</a></td><td>Google app engine. Web Page. URL: <a class="reference external" href="https://cloud.google.com/appengine/">https://cloud.google.com/appengine/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-appscale" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id55">[46]</a></td><td>AppScale. What-is-appscale. Web Page, 2016. URL: <a class="reference external" href="https://www.appscale.com/community/what-is-appscale/">https://www.appscale.com/community/what-is-appscale/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-aero" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id57">[47]</a></td><td>Aerobatic - overview. Web Page. accessed: 2017-01-25. URL: <a class="reference external" href="https://www.aerobatic.com/docs/overview/">https://www.aerobatic.com/docs/overview/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-wikipedia-cloud" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id58">[48]</a></td><td>wikipedia.org. Web Page. accessed 2017-01-21. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/Cloud_computing">https://en.wikipedia.org/wiki/Cloud_computing</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-azure-msft" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[49]</td><td><em>(<a class="fn-backref" href="#id59">1</a>, <a class="fn-backref" href="#id60">2</a>, <a class="fn-backref" href="#id66">3</a>)</em> Microsoft Corp. Web Page. accessed 2017-01-21. URL: <a class="reference external" href="https://azure.microsoft.com/en-us/">https://azure.microsoft.com/en-us/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-sec-edgar-msft" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id61">[50]</a></td><td>Microsoft Corp. Web Page, July 2016. accessed 2017-01-21. URL: <a class="reference external" href="https://www.sec.gov/Archives/edgar/data/789019/000119312516662209/d187868d10k.htm">https://www.sec.gov/Archives/edgar/data/789019/000119312516662209/d187868d10k.htm</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-aws-amzn" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id62">[51]</a></td><td>Amazon.com, Inc. Web Page. accessed 2017-01-25. URL: <a class="reference external" href="https://aws.amazon.com">https://aws.amazon.com</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-softlayer-ibm" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id63">[52]</a></td><td>IBM Corp. Web Page. accessed 2017-01-25. URL: <a class="reference external" href="www.softlayer.com">www.softlayer.com</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-bluemix-ibm" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id64">[53]</a></td><td>IBM Corp. Web Page. accessed 2017-01-25. URL: <a class="reference external" href="https://www.ibm.com/cloud-computing/bluemix/">https://www.ibm.com/cloud-computing/bluemix/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-cloud-google" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id65">[54]</a></td><td>Web Page. accessed 2017-01-25. URL: <a class="reference external" href="https://cloud.google.com">https://cloud.google.com</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-ninefoldsite" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id67">[55]</a></td><td>Ninefold website. Web Page. Accessed: 2017-1-28. URL: <a class="reference external" href="http://ninefold.com/news/">http://ninefold.com/news/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="wee" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[56]</td><td><em>(<a class="fn-backref" href="#id68">1</a>, <a class="fn-backref" href="#id72">2</a>)</em> Pau&nbsp;Kiat Wee. <em>Instant AppFog</em>., chapter 1. Packt Publishing, July 2013. URL: <a class="reference external" href="https://www.packtpub.com/mapt/book/Web-Development/9781782167624/1/ch01lvl1sec03/So,+what+is+AppFog">https://www.packtpub.com/mapt/book/Web-Development/9781782167624/1/ch01lvl1sec03/So,+what+is+AppFog</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="kepes" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[57]</td><td><em>(<a class="fn-backref" href="#id69">1</a>, <a class="fn-backref" href="#id70">2</a>)</em> Ben Kepes. Understanding the cloud computing stack: saas, paas, iaas. white paper, Racspace, 2015. URL: <a class="reference external" href="https://support.rackspace.com/white-paper/understanding-the-cloud-computing-stack-saas-paas-iaas/">https://support.rackspace.com/white-paper/understanding-the-cloud-computing-stack-saas-paas-iaas/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="appfog" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id71">[58]</a></td><td>appfog. Overview. Online. URL: <a class="reference external" href="https://www.ctl.io/appfog/#Overview">https://www.ctl.io/appfog/#Overview</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="tweney" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id73">[59]</a></td><td>Dylan Tweney. Appfog gives developers an easier way to deploy cloud apps (interview). Online, May 2012. URL: <a class="reference external" href="http://venturebeat.com/2012/05/15/appfog-gives-developers-an-easier-way-to-deploy-cloud-apps-interview/">http://venturebeat.com/2012/05/15/appfog-gives-developers-an-easier-way-to-deploy-cloud-apps-interview/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-wiki" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id74">[60]</a></td><td>Wikipedia. Cloudcontrol. Wiki Page, February 2016. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/CloudControl">https://en.wikipedia.org/wiki/CloudControl</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-dotcloud" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id75">[61]</a></td><td>Jordan Novet. Dotcloud. Web Page, January 2016. Accessed: 2017-1-31. URL: <a class="reference external" href="http://venturebeat.com/2016/01/22/dotcloud-the-cloud-service-that-gave-birth-to-docker-is-shutting-down-on-february-29/">http://venturebeat.com/2016/01/22/dotcloud-the-cloud-service-that-gave-birth-to-docker-is-shutting-down-on-february-29/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-apache-tajo" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id76">[62]</a></td><td>Apache tajo. Web Page. Accessed: 2017-1-27. URL: <a class="reference external" href="https://tajo.apache.org">https://tajo.apache.org</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-tutorialspoint-tajo" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[63]</td><td><em>(<a class="fn-backref" href="#id77">1</a>, <a class="fn-backref" href="#id78">2</a>)</em> Apache tajo quick guide. Web Page. Accessed: 2017-1-25. URL: <a class="reference external" href="https://www.tutorialspoint.com/apache_tajo/apache_tajo_quick_guide.htm">https://www.tutorialspoint.com/apache_tajo/apache_tajo_quick_guide.htm</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-phoenix-cloudera" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[64]</td><td><em>(<a class="fn-backref" href="#id79">1</a>, <a class="fn-backref" href="#id83">2</a>)</em> Justin Kestelyn. Phoenix in 15 Minutes or Less. Web Page, March 2013. accessed 2017-01-25. URL: <a class="reference external" href="http://blog.cloudera.com/blog/2013/03/phoenix-in-15-minutes-or-less/">http://blog.cloudera.com/blog/2013/03/phoenix-in-15-minutes-or-less/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-phoenix-wikipedia" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id80">[65]</a></td><td>Anon. Apache Phoenix. Web Page. accessed 2017-01-25. URL: <a class="reference external" href="https://en.m.wikipedia.org/wiki/Apache_Phoenix">https://en.m.wikipedia.org/wiki/Apache_Phoenix</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-apachephoenix-org" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id81">[66]</a></td><td>Anon. Web Page. accessed 2017-01-25. URL: <a class="reference external" href="http://phoenix.apache.org/">http://phoenix.apache.org/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-phoenix-salesforcedev" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id82">[67]</a></td><td>Adam Seligman. Apache Phoenix - A Small Step for Big Data. Web Page, May 2014. accessed 2017-01-25. URL: <a class="reference external" href="https://developer.salesforce.com/blogs/developer-relations/2014/05/apache-phoenix-small-step-big-data.html">https://developer.salesforce.com/blogs/developer-relations/2014/05/apache-phoenix-small-step-big-data.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-phoenix-infoq" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id84">[68]</a></td><td>Abel Avram. Phoenix: Running SQL Queries on Apache HBase [Updated]. Web Page, January 2013. accessed 2017-01-25. URL: <a class="reference external" href="https://www.infoq.com/news/2013/01/Phoenix-HBase-SQL">https://www.infoq.com/news/2013/01/Phoenix-HBase-SQL</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-phoenix-bighadoop" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id85">[69]</a></td><td>Anon. Apache Phoenix - An SQL Driver for HBase. Web Page, May 2014. accessed 2017-01-23. URL: <a class="reference external" href="https://bighadoop.wordpress.com/2014/05/17/apache-phoenix-an-sql-driver-for-hbase/">https://bighadoop.wordpress.com/2014/05/17/apache-phoenix-an-sql-driver-for-hbase/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-apachemrql" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[70]</td><td><em>(<a class="fn-backref" href="#id86">1</a>, <a class="fn-backref" href="#id87">2</a>)</em> Apache. Apache mrql. Web Page, April 2016. accessed 2017-01-29.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-mrqlhadoop" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id88">[71]</a></td><td>Edward&nbsp;J. Yoon. Mrql - a sql on hadoop miracle. Web Page, January 2017. accessed 2017-01-29. URL: <a class="reference external" href="http://www.hadoopsphere.com/2013/04/mrql-sql-on-hadoop-miracle.html">http://www.hadoopsphere.com/2013/04/mrql-sql-on-hadoop-miracle.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-apacheincubator" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id89">[72]</a></td><td>Apache. Apache incubator. Web Page, January 2017. accessed 2017-01-29.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-sap-hana" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id90">[73]</a></td><td>SAP. What is sap hana. Web Page. Accessed: 2017-1-17. URL: <a class="reference external" href="http://www.sap.com/product/technology-platform/hana.html">http://www.sap.com/product/technology-platform/hana.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="olofson-2014" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id91">[74]</a></td><td>Carl&nbsp;W Olofson. The analytic-transactional data platform: enabling the real-time enterprise (idc). Technical Report, International Data Corporation (IDC), Dec 2014. Accessed: 2017-1-17. URL: <a class="reference external" href="http://www.sap.com/documents/2016/08/3c4e546e-817c-0010-82c7-eda71af511fa.html">http://www.sap.com/documents/2016/08/3c4e546e-817c-0010-82c7-eda71af511fa.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-presto" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id92">[75]</a></td><td>Presto. Web Page. Accessed: 2017-1-24. URL: <a class="reference external" href="https://prestodb.io/">https://prestodb.io/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="presto-paper-2014" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id93">[76]</a></td><td>Yueguo Chen, Xiongpai Qin, Haoqiong Bian, Jun Chen, Zhaoan Dong, Xiaoyong Du, Yanjie Gao, Dehai Liu, Jiaheng Lu, and Huijie Zhang. <em>A Study of SQL-on-Hadoop Systems</em>., pages 154166. Springer International Publishing, 2014.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-kyotocabinet" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id94">[77]</a></td><td>Kyoto cabinet. Web Page. Accessed:1/16/2017. URL: <a class="reference external" href="http://fallabs.com/kyotocabinet/">http://fallabs.com/kyotocabinet/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="google-sawzall" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[78]</td><td><em>(<a class="fn-backref" href="#id95">1</a>, <a class="fn-backref" href="#id97">2</a>)</em> Rob Pike, Sean Dorward, Robert Griesemer, and Sean Quinlan. Interpreting the data: parallel analysis with sawzall. <em>Sci. Program.</em>, 13(4):277298, October 2005. URL: <a class="reference external" href="https://research.google.com/archive/sawzall-sciprog.pdf">https://research.google.com/archive/sawzall-sciprog.pdf</a>, <a class="reference external" href="http://dx.doi.org/10.1155/2005/962135">doi:10.1155/2005/962135</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-bytemining-sawzall" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id96">[79]</a></td><td>Anon. Exciting Tools for Big Data: S4, Sawzall and mrjob! Web Page, November 2010. accessed 2017-01-30. URL: <a class="reference external" href="http://www.bytemining.com/2010/11/exciting-tools-for-big-data-s4-sawzall-and-mrjob/">http://www.bytemining.com/2010/11/exciting-tools-for-big-data-s4-sawzall-and-mrjob/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-google-code-wiki-sawzall" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id98">[80]</a></td><td>Google Code Archive. szl - Overview.wiki. Web Page. accessed 2017-01-30. URL: <a class="reference external" href="https://code.google.com/archive/p/szl/wikis/Overview.wiki">https://code.google.com/archive/p/szl/wikis/Overview.wiki</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-kinesis" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id99">[81]</a></td><td>Kinesis, components. Web Page. Accessed: 2017-01-17. URL: <a class="reference external" href="http://docs.aws.amazon.com/streams/latest/dev/key-concepts.html/">http://docs.aws.amazon.com/streams/latest/dev/key-concepts.html/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="big-data-analytics-book" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id100">[82]</a></td><td>Sumit&nbsp;Gupta Shilpi&nbsp;Saxena. <em>Real-Time Big Data Analytics</em>. Packt Publishing, 35 Livery Street, Birmingham B3 2PB, UK, 1st edition, 2016. ISBN 9781784391409.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-spark" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id101">[83]</a></td><td>Abdul&nbsp;Ghaffar Shoro and Tariq&nbsp;Rahim Soomro. Big data analysis: apache spark perspective. <em>Global Journal of Computer Science and Technology</em>, 2015. Accessed: 2017-1-21. URL: <a class="reference external" href="http://www.computerresearch.org/index.php/computer/article/view/1137/1124">http://www.computerresearch.org/index.php/computer/article/view/1137/1124</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-mapreducempi" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id102">[84]</a></td><td>Mr-mpi. Web Page, 2017. URL: <a class="reference external" href="http://mapreduce.sandia.gov/doc">http://mapreduce.sandia.gov/doc</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-reef" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id103">[85]</a></td><td>Reef. Webpage. Accessed: 2017-01-28. URL: <a class="reference external" href="https://wiki.apache.org/incubator/ReefProposal">https://wiki.apache.org/incubator/ReefProposal</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-galoissite" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id104">[86]</a></td><td>Galois website. Web Page. Accessed: 2017-1-28. URL: <a class="reference external" href="www-galoisSite: http://iss.ices.utexas.edu/?p=projects/galois">www-galoisSite: http://iss.ices.utexas.edu/?p=projects/galois</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="taoparallelismpaper" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id105">[87]</a></td><td>Keshav Pingali, Donald Nguyen, Milind Kulkarni, Martin Burtscher, M.&nbsp;Amber Hassaan, Rashid Kaleem, Tsung-Hsien Lee, Andrew Lenharth, Roman Manevich, Mario Mendez-Lojo, Dimitrios Prountzos, and Xin Sui. The tao of parallelism in algorithms. In <em>The Tao of Parallelism in Algorithms</em>, 114. June 2011. URL: <a class="reference external" href="http://iss.ices.utexas.edu/Publications/Papers/pingali11.pdf">http://iss.ices.utexas.edu/Publications/Papers/pingali11.pdf</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-hpx-5" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id106">[88]</a></td><td>High performance parallex (hpx-5). Web Page. Accessed: 2017-1-17. URL: <a class="reference external" href="https://hpx.crest.iu.edu/">https://hpx.crest.iu.edu/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-hpx-5-user-guide" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id107">[89]</a></td><td><em>HPX-5: user guide</em>. HPX-5. Accessed: 2017-1-17. URL: <a class="reference external" href="https://hpx.crest.iu.edu/users_guide">https://hpx.crest.iu.edu/users_guide</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-harp" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id108">[90]</a></td><td>Harp. Webpage. Accessed: 2017-01-28. URL: <a class="reference external" href="http://harpjs.com">http://harpjs.com</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-netty" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id109">[91]</a></td><td>Netty site. Web Page. URL: <a class="reference external" href="http://netty.io/">http://netty.io/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="netty-book" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id110">[92]</a></td><td>Norman Maurer and Marvin Wolfthal. <em>Netty in Action</em>. Manning Publications, 2016.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-zeromq" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[93]</td><td><em>(<a class="fn-backref" href="#id111">1</a>, <a class="fn-backref" href="#id113">2</a>)</em> Distributed messaging. Web Page. Accessed: 2017-1-24. URL: <a class="reference external" href="http://zeromq.org">http://zeromq.org</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-zeromq2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id112">[94]</a></td><td>0mq - the guide. Web Page. Accessed: 2017-1-24. URL: <a class="reference external" href="http://zguide.zeromq.org/page:all">http://zguide.zeromq.org/page:all</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-rabbitmq" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id114">[95]</a></td><td>RabbitMQ, components. Web Page. Accessed: 2017-01-19. URL: <a class="reference external" href="https://www.rabbitmq.com/">https://www.rabbitmq.com/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="ampq-article" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id115">[96]</a></td><td>John O&#8217;Hara. Toward a commodity enterprise middleware. <em>Queue</em>, 5(4):4855, 2007.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-kafka" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id116">[97]</a></td><td>Apache&nbsp;Software Foundation. Kafka-a distributed streaming platform. Web Page. URL: <a class="reference external" href="https://kafka.apache.org/">https://kafka.apache.org/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-amqp" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id117">[98]</a></td><td>Amqp is the internet protocol for business messaging. Web Page. accessed: 2017-01-31. URL: <a class="reference external" href="http://www.amqp.org/about/what">http://www.amqp.org/about/what</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-mqtt" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id118">[99]</a></td><td>Mqtt. Web Page. Accessed: 2017-1-27. URL: <a class="reference external" href="http://mqtt.org/">http://mqtt.org/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-floodnet" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id119">[100]</a></td><td>Mqtt floodnet. Web Page. Accessed: 2017-1-27. URL: <a class="reference external" href="http://mqtt.org/projects/floodnet">http://mqtt.org/projects/floodnet</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-gora" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id120">[101]</a></td><td>Gora, components. Web Page. Accessed: 2017-01-18. URL: <a class="reference external" href="http://gora.apache.org/">http://gora.apache.org/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-memcached" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id121">[102]</a></td><td>Memcached. Web Page. Accessed: 2017-01-30. URL: <a class="reference external" href="http://www.memcached.org/">http://www.memcached.org/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-keyvalue" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id122">[103]</a></td><td>Wikipedia. Key-value database. WebPage. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/Key-value_database">https://en.wikipedia.org/wiki/Key-value_database</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-relationaldb" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id123">[104]</a></td><td>Wikipedia. Relational database. WebPage. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/Relational_database">https://en.wikipedia.org/wiki/Relational_database</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-lmdb" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id124">[105]</a></td><td>Matthew Hardin. Understanding lmdb database file sizes and memory utilization. WebPage, May 2016. URL: <a class="reference external" href="https://symas.com/understanding-lmdb-database-file-sizes-and-memory-utilization/">https://symas.com/understanding-lmdb-database-file-sizes-and-memory-utilization/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-wikihazel" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[106]</td><td><em>(<a class="fn-backref" href="#id125">1</a>, <a class="fn-backref" href="#id127">2</a>, <a class="fn-backref" href="#id128">3</a>)</em> Wikipedia. Hazelcast. Web Page, January 2017. accessed 2017-01-29. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/Hazelcast">https://en.wikipedia.org/wiki/Hazelcast</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-githubhazel" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id126">[107]</a></td><td>Hazelcast. Open source in-memory data grid. Web Page, January 2017. accessed 2017-01-29. URL: <a class="reference external" href="https://github.com/hazelcast/hazelcast">https://github.com/hazelcast/hazelcast</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-ehcache-features" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id129">[108]</a></td><td>Ehcache - features. Web Page. Accessed: 2017-01-21. URL: <a class="reference external" href="http://www.ehcache.org/about/features.html">http://www.ehcache.org/about/features.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-ehcache-documentation" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id130">[109]</a></td><td>Ehcache - documentation. Web Page. Accessed: 2017-01-21. URL: <a class="reference external" href="http://www.ehcache.org/documentation/3.2/getting-started.html">http://www.ehcache.org/documentation/3.2/getting-started.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-hstore" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id131">[110]</a></td><td>H-store. Web Page. Accessed:1/16/2017. URL: <a class="reference external" href="http://hstore.cs.brown.edu/">http://hstore.cs.brown.edu/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="kallman2008" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id132">[111]</a></td><td>Robert Kallman, Hideaki Kimura, Jonathan Natkins, Andrew Pavlo, Alexander Rasin, Stanley Zdonik, Evan P.&nbsp;C. Jones, Samuel Madden, Michael Stonebraker, Yang Zhang, John Hugg, and Daniel&nbsp;J. Abadi. H-Store: a high-performance, distributed main memory transaction processing system. <em>Proc. VLDB Endow.</em>, 1(2):14961499, 2008. URL: <a class="reference external" href="http://hstore.cs.brown.edu/papers/hstore-demo.pdf">http://hstore.cs.brown.edu/papers/hstore-demo.pdf</a>, <a class="reference external" href="http://dx.doi.org/http://doi.acm.org/10.1145/1454159.1454211">doi:http://doi.acm.org/10.1145/1454159.1454211</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-hstorewiki" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id133">[112]</a></td><td>H-storewiki. Web Page. Accessed:1/16/2017. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/H-Store">https://en.wikipedia.org/wiki/H-Store</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-eclipselink" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id134">[113]</a></td><td>Eclipselink. Accessed: 02-06-2017. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/EclipseLink">https://en.wikipedia.org/wiki/EclipseLink</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-tika" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id135">[114]</a></td><td>Apache tika. Web Page. URL: <a class="reference external" href="https://tika.apache.org/">https://tika.apache.org/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-sqlserver-wiki" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id136">[115]</a></td><td>Sql server wiki. Web Page. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/Microsoft_SQL_Server">https://en.wikipedia.org/wiki/Microsoft_SQL_Server</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-azuresql" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id137">[116]</a></td><td>Sql server azure. Web Page. URL: <a class="reference external" href="https://azure.microsoft.com/en-us/services/sql-database/?b=16.50">https://azure.microsoft.com/en-us/services/sql-database/?b=16.50</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="book-sqlserver" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id138">[117]</a></td><td>Ross Mistry and Stacia Misner. <em>Introducing Microsoft SQL Server 2014 Technical Overview</em>. Microsoft Press, 2014. ISBN 978-0-7356-8475-1.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="devmysql" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[118]</td><td><em>(<a class="fn-backref" href="#id139">1</a>, <a class="fn-backref" href="#id140">2</a>, <a class="fn-backref" href="#id141">3</a>, <a class="fn-backref" href="#id142">4</a>)</em> mysql. Mysql 5.7 reference manual, what is mysql. Online. URL: <a class="reference external" href="https://dev.mysql.com/doc/refman/5.7/en/what-is-mysql.html">https://dev.mysql.com/doc/refman/5.7/en/what-is-mysql.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="howmysql" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id143">[119]</a></td><td>HowStuffWorks.com. What are relational databases? Online, March 2001. URL: <a class="reference external" href="http://computer.howstuffworks.com/question599.htm">http://computer.howstuffworks.com/question599.htm</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-cubrid" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id144">[120]</a></td><td>Cubrid. Web Page, 2017. URL: <a class="reference external" href="http://www.cubrid.org/">http://www.cubrid.org/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-galera-cluster" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id145">[121]</a></td><td>Galera cluster. Web Page, 2017. URL: <a class="reference external" href="http://galeracluster.com/">http://galeracluster.com/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-lucene" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id146">[122]</a></td><td>Apache lucene. Web Page, January 2017. URL: <a class="reference external" href="http://lucene.apache.org/">http://lucene.apache.org/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-solandra" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id147">[123]</a></td><td>Solandra. Webpage. URL: <a class="reference external" href="https://github.com/tjake/Solandra/wiki/Solandra-Wiki">https://github.com/tjake/Solandra/wiki/Solandra-Wiki</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-solandra2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id148">[124]</a></td><td>Solandra. Webpage. URL: <a class="reference external" href="https://github.com/tjake/Solandra">https://github.com/tjake/Solandra</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-voldemort" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id149">[125]</a></td><td>LinkedIn. Project voldemort. Web Page. Accessed: 2017-1-17. URL: <a class="reference external" href="http://www.project-voldemort.com/voldemort/">http://www.project-voldemort.com/voldemort/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="rabl-sadoghi-jacobsen-2012" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id150">[126]</a></td><td>Tilmann Rabl, Sergio Gmez-Villamor, Mohammad Sadoghi, Victor Munts-Mulero, Hans-Arno Jacobsen, and Serge Mankovskii. Solving big data challenges for enterprise application performance management. <em>Proc. VLDB Endow.</em>, 5(12):17241735, August 2012. URL: <a class="reference external" href="https://arxiv.org/pdf/1208.4167.pdf">https://arxiv.org/pdf/1208.4167.pdf</a>, <a class="reference external" href="http://dx.doi.org/10.14778/2367502.2367512">doi:10.14778/2367502.2367512</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-riak-kv" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id151">[127]</a></td><td>Riak-kv - nosql key value database. Web Page. Accessed: 2017-01-20. URL: <a class="reference external" href="http://basho.com/products/riak-kv/">http://basho.com/products/riak-kv/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-riak-ts" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id152">[128]</a></td><td>Riak-ts - nosql time series database. Web Page. Accessed: 2017-01-20. URL: <a class="reference external" href="http://basho.com/products/riak-ts/">http://basho.com/products/riak-ts/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-riak-s2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id153">[129]</a></td><td>Riak-s2 - cloud object storage software. Web Page. Accessed: 2017-01-20. URL: <a class="reference external" href="http://basho.com/products/riak-s2/">http://basho.com/products/riak-s2/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="datasys" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id154">[130]</a></td><td>Illinois&nbsp;Institute of&nbsp;Technology Department&nbsp;of Computer&nbsp;Science. Zht: a zero-hop distributed hashtable. Online. URL: <a class="reference external" href="http://datasys.cs.iit.edu/projects/ZHT/">http://datasys.cs.iit.edu/projects/ZHT/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="wiley" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[131]</td><td><em>(<a class="fn-backref" href="#id155">1</a>, <a class="fn-backref" href="#id156">2</a>, <a class="fn-backref" href="#id157">3</a>)</em> Brandon Wiley. Distributed hash ttable, part 1. <em>Linux Journal</em>, October 2003. From issue number 114. URL: <a class="reference external" href="http://www.linuxjournal.com/article/6797?page=0,0">http://www.linuxjournal.com/article/6797?page=0,0</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="li" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[132]</td><td><em>(<a class="fn-backref" href="#id158">1</a>, <a class="fn-backref" href="#id159">2</a>, <a class="fn-backref" href="#id160">3</a>)</em> T.&nbsp;Li, X.&nbsp;Zhou, K.&nbsp;Brandstatter, D.&nbsp;Zhao, K.&nbsp;Wang, A.&nbsp;Rajendran, Z.&nbsp;Zhang, and I.&nbsp;Raicu. Zht: a light-weight reliable persistent dynamic scalable zero-hop distributed hash table. In <em>2013 IEEE 27th International Symposium on Parallel and Distributed Processing</em>, 775787. May 2013. URL: <a class="reference external" href="http://datasys.cs.iit.edu/publications/2013_IPDPS13_ZHT.pdf">http://datasys.cs.iit.edu/publications/2013_IPDPS13_ZHT.pdf</a>, <a class="reference external" href="http://dx.doi.org/10.1109/IPDPS.2013.110">doi:10.1109/IPDPS.2013.110</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-tokyo-cabinet" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[133]</td><td><em>(<a class="fn-backref" href="#id161">1</a>, <a class="fn-backref" href="#id163">2</a>)</em> Tokyo cabinet. Web Page. Accessed: 2017-1-27. URL: <a class="reference external" href="http://fallabs.com/tokyocabinet/">http://fallabs.com/tokyocabinet/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-kyoto-cabinet" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id162">[134]</a></td><td>Kyoto cabinet. Web Page. Accessed: 2017-1-27. URL: <a class="reference external" href="http://fallabs.com/kyotocabinet/">http://fallabs.com/kyotocabinet/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-tyrant-blog" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id164">[135]</a></td><td>Tyrant blog. Web Page. URL: <a class="reference external" href="https://www.percona.com/blog/2009/10/19/mysql_memcached_tyrant_part3/">https://www.percona.com/blog/2009/10/19/mysql_memcached_tyrant_part3/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-tyrant-fal-labs" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id165">[136]</a></td><td>Tyrant fallabs. Web Page. URL: <a class="reference external" href="http://fallabs.com/tokyotyrant/">http://fallabs.com/tokyotyrant/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-kyoto-tycoon" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id166">[137]</a></td><td>Kyoto tycoon. Web Page. URL: <a class="reference external" href="http://fallabs.com/kyototycoon/">http://fallabs.com/kyototycoon/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-infoworld-cbs" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id167">[138]</a></td><td>Rick Grehan. NoSQL Showdown: MongoDB vs. Couchbase. Web Page, March 2013. accessed 2017-01-29. URL: <a class="reference external" href="http://www.infoworld.com/article/2613970/nosql/nosql-showdown--mongodb-vs--couchbase.html">http://www.infoworld.com/article/2613970/nosql/nosql-showdown&#8211;mongodb-vs&#8211;couchbase.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-safaribooks-cbs" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id168">[139]</a></td><td>Martin Brown. The Technology Behind Couchbase. Web Page, March 2012. accessed 2017-01-29. URL: <a class="reference external" href="https://www.safaribooksonline.com/blog/2012/03/01/the-technology-behind-couchbase/">https://www.safaribooksonline.com/blog/2012/03/01/the-technology-behind-couchbase/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-erlangcentral-cbs" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id169">[140]</a></td><td>Couchbase Performance and Scalability: Iterating with DTrace Observability. Web Page, March 2012. accessed 2017-01-29. URL: <a class="reference external" href="http://erlangcentral.org/videos/couchbase-performance-and-scalability-iterating-with-dtrace-observability/#.WI5uYephnRY">http://erlangcentral.org/videos/couchbase-performance-and-scalability-iterating-with-dtrace-observability/#.WI5uYephnRY</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-wikipedia-erlang-cbs" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id170">[141]</a></td><td>Erlang (programming language. Web Page. accessed: 2017-01-29. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/Erlang_(programming_language)">https://en.wikipedia.org/wiki/Erlang_(programming_language)</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-couchbase-blog-cbs" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id171">[142]</a></td><td>Sean Lynch. Why Membase Uses Erlang. Web Page, October 2010. accessed 2017-01-29. URL: <a class="reference external" href="https://blog.couchbase.com/why-membase-uses-erlang">https://blog.couchbase.com/why-membase-uses-erlang</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-hightower-cbs" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id172">[143]</a></td><td>Riyad Kalla. Well put! When should you use MongoDB vs Couchbase versus Redis... Web Page, October 2011. accessed 2017-01-29. URL: <a class="reference external" href="http://rick-hightower.blogspot.com/2014/04/well-put-when-should-you-use-mongodb-vs.html">http://rick-hightower.blogspot.com/2014/04/well-put-when-should-you-use-mongodb-vs.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-quora-cbs" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id173">[144]</a></td><td>Russell Smith. What are the advantages and disadvantages of using MongoDB vs CouchDB vs Cassandra vs Redis? Web Page, November 2015. accessed 2017-01-29. URL: <a class="reference external" href="https://www.quora.com/What-are-the-advantages-and-disadvantages-of-using-MongoDB-vs-CouchDB-vs-Cassandra-vs-Redis">https://www.quora.com/What-are-the-advantages-and-disadvantages-of-using-MongoDB-vs-CouchDB-vs-Cassandra-vs-Redis</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-gemfire" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id174">[145]</a></td><td>About pivotal gemfire. Web Page. Accessed: 2017-01-28. URL: <a class="reference external" href="http://gemfire.docs.pivotal.io/gemfire/getting_started/gemfire_overview.html">http://gemfire.docs.pivotal.io/gemfire/getting_started/gemfire_overview.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-cloudbigtable" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id175">[146]</a></td><td>Google. Cloud bigtable. Web Page, January 2017. accessed 2017-01-29. URL: <a class="reference external" href="https://cloud.google.com/bigtable/">https://cloud.google.com/bigtable/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-wikibigtable" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[147]</td><td><em>(<a class="fn-backref" href="#id176">1</a>, <a class="fn-backref" href="#id177">2</a>)</em> Wikipedia. Bigtable. Web Page, January 2017. accessed 2017-01-29. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/Bigtable">https://en.wikipedia.org/wiki/Bigtable</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-wikispanner" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id178">[148]</a></td><td>Wikipedia. Spanner (database). Web Page, October 2016. accessed 2017-01-29. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/Spanner_(database)">https://en.wikipedia.org/wiki/Spanner_(database)</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="corbett-spanner" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id179">[149]</a></td><td>James&nbsp;C Corbett, Jeffrey Dean, Michael Epstein, Andrew Fikes, Christopher Frost, Jeffrey&nbsp;John Furman, Sanjay Ghemawat, Andrey Gubarev, Christopher Heiser, Peter Hochschild, and others. Spanner: googles globally distributed database. <em>ACM Transactions on Computer Systems (TOCS)</em>, 31(3):8, 2013. URL: <a class="reference external" href="http://dl.acm.org/ft_gateway.cfm?id=2491245&amp;type=pdf">http://dl.acm.org/ft_gateway.cfm?id=2491245&amp;type=pdf</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-magastore-spanner" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id180">[150]</a></td><td>Magastore, Spanner, components. Web Page. Accessed: 2017-01-28. URL: <a class="reference external" href="http://blog.mikiobraun.de/2013/03/more-google-papers-megastore-spanner-voted-commits.html">http://blog.mikiobraun.de/2013/03/more-google-papers-megastore-spanner-voted-commits.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-cassandra" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id181">[151]</a></td><td>Apache cassandra. Web Page, 2016. URL: <a class="reference external" href="http://cassandra.apache.org/">http://cassandra.apache.org/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="punnoose" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[152]</td><td><em>(<a class="fn-backref" href="#id182">1</a>, <a class="fn-backref" href="#id183">2</a>, <a class="fn-backref" href="#id185">3</a>, <a class="fn-backref" href="#id186">4</a>)</em> Roshan Punnoose, Adina Crainiceanu, and David Rapp. Rya: a scalable rdf triple store for the clouds. In <em>Proceedings of the 1st International Workshop on Cloud Intelligence</em>, Cloud-I &#8216;12, 4:14:8. New York, NY, USA, 2012. ACM. URL: <a class="reference external" href="http://doi.acm.org/10.1145/2347673.2347677">http://doi.acm.org/10.1145/2347673.2347677</a>, <a class="reference external" href="http://dx.doi.org/10.1145/2347673.2347677">doi:10.1145/2347673.2347677</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="w3" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id184">[153]</a></td><td>RDF&nbsp;Working Group. Resource description framework (rdf). Online, February 2014. URL: <a class="reference external" href="https://www.w3.org/RDF/">https://www.w3.org/RDF/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="apacherya" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id187">[154]</a></td><td>Apache Rya. Apache rya. Online. URL: <a class="reference external" href="https://rya.apache.org/">https://rya.apache.org/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-graphdb" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id188">[155]</a></td><td>GraphDb. Web Page. Accessed: 2017-01-30. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/Graph_database/">https://en.wikipedia.org/wiki/Graph_database/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-what-to-use" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id189">[156]</a></td><td>blog.wouldbetheologian.com. Azure: What to Use, What to Avoid. Web Page, October 2014. accessed 2017-01-28. URL: <a class="reference external" href="http://blog.wouldbetheologian.com/2014/10/azure-what-to-use-what-to-avoid.html">http://blog.wouldbetheologian.com/2014/10/azure-what-to-use-what-to-avoid.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-blobqueuetable" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id190">[157]</a></td><td>www.thewindowsclub.com. Understanding Blob, Queue and Table Storage for Windows Azure. Web Page. accessed 2017-01-28; no published data available. URL: <a class="reference external" href="http://www.thewindowsclub.com/understanding-blobqueuetable-storage-windows-azure">http://www.thewindowsclub.com/understanding-blobqueuetable-storage-windows-azure</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-scalable-partitioning" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id191">[158]</a></td><td>www.microsoft.com. Designing a Scalable Partitioning Strategy for Azure Table Storage. Web Page, January 2017. accessed 2017-01-28. URL: <a class="reference external" href="https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/designing-a-scalable-partitioning-strategy-for-azure-table-storage">https://docs.microsoft.com/en-us/rest/api/storageservices/fileservices/designing-a-scalable-partitioning-strategy-for-azure-table-storage</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-fits-nasa" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id192">[159]</a></td><td>Fits nasa. web. URL: <a class="reference external" href="https://fits.gsfc.nasa.gov/">https://fits.gsfc.nasa.gov/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-news-fits-2016" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id193">[160]</a></td><td>Fits news. Web Page. URL: <a class="reference external" href="https://fits.gsfc.nasa.gov/fits_standard.html">https://fits.gsfc.nasa.gov/fits_standard.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-fits-vatican-library" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id194">[161]</a></td><td>Fits vatican library. Web Page. URL: <a class="reference external" href="https://www.vatlib.it/home.php?pag=digitalizzazione&amp;ling=eng">https://www.vatlib.it/home.php?pag=digitalizzazione&amp;ling=eng</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-fits-matlab" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id195">[162]</a></td><td>Fits matlab. Web Page. URL: <a class="reference external" href="https://www.mathworks.com/help/matlab/import_export/importing-flexible-image-transport-system-fits-files.html?requestedDomain=www.mathworks.com">https://www.mathworks.com/help/matlab/import_export/importing-flexible-image-transport-system-fits-files.html?requestedDomain=www.mathworks.com</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="paper-fits-2011" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id196">[163]</a></td><td><em>Astronomical Image Processing with Hadoop</em>, volume 442, Astronomical Data Analysis Software and Systems XX. ASP Conference Proceedings, July 2011. URL: <a class="reference external" href="http://adsabs.harvard.edu/abs/2011ASPC..442...93W">http://adsabs.harvard.edu/abs/2011ASPC..442...93W</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-parquet" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id197">[164]</a></td><td>Parquet. Accessed: 02-06-2017. URL: <a class="reference external" href="https://parquet.apache.org/documentation/latest">https://parquet.apache.org/documentation/latest</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-bittorrent" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id198">[165]</a></td><td>Bittorrent. Web Page, 2017. URL: <a class="reference external" href="https://www.lifewire.com/how-torrent-downloading-works-2483513">https://www.lifewire.com/how-torrent-downloading-works-2483513</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-ssh-wiki" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id199">[166]</a></td><td>Ssh - wikipedia. Web Page. Accessed: 2017-01-26. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/Secure_Shell">https://en.wikipedia.org/wiki/Secure_Shell</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-openssh-wiki" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id200">[167]</a></td><td>Openssh - wikipedia. Web Page. Accessed: 2017-01-26. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/OpenSSH">https://en.wikipedia.org/wiki/OpenSSH</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-globusonline" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id201">[168]</a></td><td>Globus online (gridftp). Web Page. Accessed:1/16/2017. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/GridFTP">https://en.wikipedia.org/wiki/GridFTP</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-sqoop" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id210">[169]</a></td><td>The Apache&nbsp;Software Foundation. Web. URL: <a class="reference external" href="http://sqoop.apache.org/">http://sqoop.apache.org/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="sqoop-wiki" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id211">[170]</a></td><td>Wikipedia. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/Sqoop">https://en.wikipedia.org/wiki/Sqoop</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-cloudera" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id212">[171]</a></td><td>cloudera. Untangling apache hadoop yarn part 1 cluster and yarn basics. Web Page, 2015. URL: <a class="reference external" href="https://blog.cloudera.com/blog/2015/09/untangling-apache-hadoop-yarn-part-1/">https://blog.cloudera.com/blog/2015/09/untangling-apache-hadoop-yarn-part-1/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-architecture" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id213">[172]</a></td><td>Difference between application manager and application master in yarn? StackOverflow, 2015. URL: <a class="reference external" href="http://stackoverflow.com/questions/30967247/difference-between-application-manager-and-application-master-in-yarn">http://stackoverflow.com/questions/30967247/difference-between-application-manager-and-application-master-in-yarn</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-hadoopapache" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id214">[173]</a></td><td>Hadoop Apache. Apache software foundation. Web Page, 2016. URL: <a class="reference external" href="https://hadoop.apache.org/docs/r2.7.2/hadoop-yarn/hadoop-yarn-site/YARN.html">https://hadoop.apache.org/docs/r2.7.2/hadoop-yarn/hadoop-yarn-site/YARN.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-slurm" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id215">[174]</a></td><td>Slurm. Web Page. URL: <a class="reference external" href="https://slurm.schedmd.com/">https://slurm.schedmd.com/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-slurmschedmdsite" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id216">[175]</a></td><td>Slurm website. Web Page. Accessed: 2017-1-28. URL: <a class="reference external" href="https://slurm.schedmd.com/overview.html">https://slurm.schedmd.com/overview.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-slurmplatformssite" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id217">[176]</a></td><td>Slurm supported platforms. Web Page. Accessed: 2017-1-28. URL: <a class="reference external" href="https://slurm.schedmd.com/platforms.html">https://slurm.schedmd.com/platforms.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="wiki-cinder" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[177]</td><td><em>(<a class="fn-backref" href="#id218">1</a>, <a class="fn-backref" href="#id220">2</a>)</em> Cinder - openstack. Web Page. Accessed: 2017-1-21. URL: <a class="reference external" href="https://wiki.openstack.org/wiki/Cinder">https://wiki.openstack.org/wiki/Cinder</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="book-cinder" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id219">[178]</a></td><td>Dan Radez. <em>OpenStack Essentials</em>. Packt Publishing Ltd., 2015. ISBN 978-1-78398-708-5. URL: <a class="reference external" href="http://ebook.konfigurasi.net/Openstack/OpenStack">http://ebook.konfigurasi.net/Openstack/OpenStack</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-lustre" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id221">[179]</a></td><td>Lustre. Webpage. Accessed: 2017-01-28. URL: <a class="reference external" href="http://lustre.org/">http://lustre.org/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-wikigpfs" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[180]</td><td><em>(<a class="fn-backref" href="#id222">1</a>, <a class="fn-backref" href="#id223">2</a>, <a class="fn-backref" href="#id224">3</a>)</em> Wikipedia. Ibm general parallel file system. Web Page, January 2017. accessed 2017-01-29. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/IBM_General_Parallel_File_System">https://en.wikipedia.org/wiki/IBM_General_Parallel_File_System</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-spectrumscale" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id225">[181]</a></td><td>IBM. Ibm spectrum scale. Web Page, January 2017. accessed 2017-01-29. URL: <a class="reference external" href="http://www-03.ibm.com/systems/storage/spectrum/scale/">http://www-03.ibm.com/systems/storage/spectrum/scale/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-gffs" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id226">[182]</a></td><td>Gffs. Webpage. Accessed: 2017-01-28. URL: <a class="reference external" href="http://genesis2.virginia.edu/wiki/Main/GFFS">http://genesis2.virginia.edu/wiki/Main/GFFS</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-amazon-s3" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id227">[183]</a></td><td>Amazon s3. Web Page. Accessed: 2017-1-27. URL: <a class="reference external" href="https://aws.amazon.com/s3/">https://aws.amazon.com/s3/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-amazon-s3-docs" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id228">[184]</a></td><td>Using Amazon S3. Web Page. Accessed: 2017-1-27. URL: <a class="reference external" href="http://docs.aws.amazon.com/AmazonS3/latest/gsg/CopyingAnObject.html">http://docs.aws.amazon.com/AmazonS3/latest/gsg/CopyingAnObject.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-google-cloud-storage" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id229">[185]</a></td><td>Google cloud storage. Accessed: 02-06-2017. URL: <a class="reference external" href="https://cloud.google.com/storage/docs">https://cloud.google.com/storage/docs</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="cloud-portability-book" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id230">[186]</a></td><td>Antonio&nbsp;Esposito Beniamino Di&nbsp;Martino, Giuseppina&nbsp;Cretella. <em>Cloud Portability and Interoperability</em>. Springer International Publishing, New York City, USA, illustrated edition, 2015. ISBN 331913700X, 9783319137001.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-jclouds" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id231">[187]</a></td><td>JClouds, components. Web Page. Accessed: 2017-01-20. URL: <a class="reference external" href="https://jclouds.apache.org/">https://jclouds.apache.org/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-occi" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id232">[188]</a></td><td>Open&nbsp;Grid Forum. Open cloud computing interface. Web Page. Accessed: 2017-1-17. URL: <a class="reference external" href="http://occi-wg.org/">http://occi-wg.org/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="nyren-edmonds-papaspyrou-2016" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id233">[189]</a></td><td>Ralf Nyren, Andy Edmonds, Alesander Papaspyrou, Thijs Metsch, and Boris Parak. Open cloud computing interface core. OGF Published Document GWD-R-P.221, Global Grid Forum, Open Grid Forum, P.O. Box 1738, Muncie IN 47308, USA, September 2016. Accessed: 2017-1-17. URL: <a class="reference external" href="https://www.ogf.org/documents/GFD.221.pdf">https://www.ogf.org/documents/GFD.221.pdf</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="drescher-parak-wallom-2015" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id234">[190]</a></td><td>Michel Drescher, Boris Parak, and David Wallom. Occi compute resource templates profile. OGF Published Document GWD-R-P.222, Global Grid Forum, Open Grid Forum, P.O. Box 1738, Muncie IN 47308, USA, April 2015. Accessed: 2017-1-17. URL: <a class="reference external" href="https://www.ogf.org/documents/GFD.222.pdf">https://www.ogf.org/documents/GFD.222.pdf</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="nyren-edmonds-metsch-2016" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id235">[191]</a></td><td>Ralf Nyren, Andy Edmonds, Thijs Metsch, and Boris Parak. Open cloud computing interface - http protocol. OGF Published Document GWD-R-P.223, Global Grid Forum, Open Grid Forum, P.O. Box 1738, Muncie IN 47308, USA, September 2016. Accessed: 2017-1-17. URL: <a class="reference external" href="https://www.ogf.org/documents/GFD.223.pdf">https://www.ogf.org/documents/GFD.223.pdf</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="nyren-feldhaus-parak-2016" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id236">[192]</a></td><td>Ralf Nyren, Florian Feldhaus, Boris Parak, and Zdenek Sustr. Open cloud computing interface -json rendering. OGF Published Document GWD-R-P.226, Global Grid Forum, Open Grid Forum, P.O. Box 1738, Muncie IN 47308, USA, September 2016. Accessed: 2017-1-17. URL: <a class="reference external" href="https://www.ogf.org/documents/GFD.226.pdf">https://www.ogf.org/documents/GFD.226.pdf</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="edmonds-metsch-2016" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id237">[193]</a></td><td>Andy Edmonds and Thijs Metsch. Open cloud computing interface - text rendering. OGF Published Document GWD-R-P.229, Global Grid Forum, Open Grid Forum, P.O. Box 1738, Muncie IN 47308, USA, September 2016. Accessed: 2017-1-17. URL: <a class="reference external" href="https://www.ogf.org/documents/GFD.229.pdf">https://www.ogf.org/documents/GFD.229.pdf</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="chef-book" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id238">[194]</a></td><td>Matthias Marschall. <em>Chef Infrastructure Automation Cookbook</em>. Packt Publishing, 2013. ISBN 9351105164 and 9789351105169.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-chef-commercial" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id239">[195]</a></td><td>Chef commercial support. Web Page. URL: <a class="reference external" href="https://www.chef.io/support/">https://www.chef.io/support/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-ansible" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id240">[196]</a></td><td>Ansible. Webpage. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/Ansible_(software)">https://en.wikipedia.org/wiki/Ansible_(software)</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-ansible2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id241">[197]</a></td><td>Ansible. Webpage. URL: <a class="reference external" href="https://docs.ansible.com/ansible/index.html">https://docs.ansible.com/ansible/index.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-cobbler" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id242">[198]</a></td><td>Cobbler. Web Page. Accessed: 2017-02-05. URL: <a class="reference external" href="http://www.theregister.co.uk/2008/06/19/red_hat_summit_2008_cobbler/">http://www.theregister.co.uk/2008/06/19/red_hat_summit_2008_cobbler/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="juju-paper" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id243">[199]</a></td><td>Kent Baxley, JD&nbsp;la&nbsp;Rosa, and Mark Wenning. Deploying workloads with juju and maas in ubuntu 14.04 lts. In <em>Deploying workloads with Juju and MAAS in Ubuntu 14.04 LTS</em>. Dell Inc, Technical White Paper, may 2014.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-juju" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id244">[200]</a></td><td>Canonical. Juju site. Web Page. URL: <a class="reference external" href="https://www.ubuntu.com/cloud/juju">https://www.ubuntu.com/cloud/juju</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-openstack" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id245">[201]</a></td><td>Openstack. Web Page. Accessed:1/16/2017. URL: <a class="reference external" href="https://www.openstack.org/">https://www.openstack.org/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-sahara" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id246">[202]</a></td><td>Sahara. Web Page. Accessed:1/16/2017. URL: <a class="reference external" href="http://docs.openstack.org/developer/sahara/">http://docs.openstack.org/developer/sahara/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-wikichef" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id247">[203]</a></td><td>Wikipedia. Chef (software). Web Page, January 2017. accessed 2017-01-26. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/Chef_(software)">https://en.wikipedia.org/wiki/Chef_(software)</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-awsopsworks" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id248">[204]</a></td><td>Amazon. Aws opsworks. Web Page, January 2017. accessed 2017-01-25. URL: <a class="reference external" href="https://aws.amazon.com/opsworks/">https://aws.amazon.com/opsworks/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="plassnig-2015" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id249">[205]</a></td><td>Moritz Plassnig. Heroku-style application deployments with docker - dzone cloud. Web Page, Nov 2015. Accessed: 2017-1-17. URL: <a class="reference external" href="https://dzone.com/articles/heroku-style-application-deployments-with-docker">https://dzone.com/articles/heroku-style-application-deployments-with-docker</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="gonzalez-2015" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id250">[206]</a></td><td>Jose Gonzalez and Jeff Lindsay. Buildstep. Web Page, Jul 2015. Accessed: 2017-1-24. URL: <a class="reference external" href="https://github.com/progrium/buildstep">https://github.com/progrium/buildstep</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-winery" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id251">[207]</a></td><td>Eclipse winery. Web Page. Accessed: 2017-1-24. URL: <a class="reference external" href="https://projects.eclipse.org/projects/soa.winery">https://projects.eclipse.org/projects/soa.winery</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="winery-paper-2013" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[208]</td><td><em>(<a class="fn-backref" href="#id252">1</a>, <a class="fn-backref" href="#id253">2</a>, <a class="fn-backref" href="#id254">3</a>)</em> Oliver Kopp, Tobias Binz, Uwe Breitenbcher, and Frank Leymann. Winery  a modeling tool for tosca-based cloud applications. In <em>11\textsuperscript th International Conference on Service-Oriented Computing</em>, 700704. Springer, December 2013.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-blueprints" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id255">[209]</a></td><td>Exercise: analyze business processes with ibm bpm blueprint. Web Page. Accessed: 2017-1-24. URL: <a class="reference external" href="http://www.ibm.com/developerworks/downloads/soasandbox/blueprint.html">http://www.ibm.com/developerworks/downloads/soasandbox/blueprint.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-blueworks-live2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[210]</td><td><em>(<a class="fn-backref" href="#id256">1</a>, <a class="fn-backref" href="#id258">2</a>)</em> Blueworkslive. Web Page. Accessed: 2017-1-24. URL: <a class="reference external" href="https://www.blueworkslive.com/home">https://www.blueworkslive.com/home</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-blueworks-live" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id257">[211]</a></td><td>Ibm blueworks live. Web Page. Accessed: 2017-1-24. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/IBM_Blueworks_Live">https://en.wikipedia.org/wiki/IBM_Blueworks_Live</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="wettinger-any2api" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id259">[212]</a></td><td>Johannes Wettinger, Uwe Breitenbcher, and Frank Leymann. Any2api - automated apification. In <em>Proceedings of the 5th International Conference on Cloud Computing and Services Science</em>, 475486. SciTePress, 2015. URL: <a class="reference external" href="https://pdfs.semanticscholar.org/1cd4/4b87be8cf68ea5c4c642d38678a7b40a86de.pdf">https://pdfs.semanticscholar.org/1cd4/4b87be8cf68ea5c4c642d38678a7b40a86de.pdf</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-any2api" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id260">[213]</a></td><td>Any2Api, components. Web Page. Accessed: 2017-02-02. URL: <a class="reference external" href="http://www.any2api.org/">http://www.any2api.org/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-xen-wikipedia" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id261">[214]</a></td><td>Xen - wikipedia. Web Page. Accessed: 2017-02-04. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/Xen">https://en.wikipedia.org/wiki/Xen</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-xen-overview" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id262">[215]</a></td><td>Xen project overview. Web Page. Accessed: 2017-02-04. URL: <a class="reference external" href="https://wiki.xenproject.org/wiki/Xen_Project_Software_Overview">https://wiki.xenproject.org/wiki/Xen_Project_Software_Overview</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-xen-fl" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id263">[216]</a></td><td>Xen feature list. Web Page. Accessed: 2017-02-04. URL: <a class="reference external" href="https://wiki.xenproject.org/wiki/Xen_Project_4.7_Feature_List">https://wiki.xenproject.org/wiki/Xen_Project_4.7_Feature_List</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-hypervisor" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id264">[217]</a></td><td>Hypervisor. WebPage. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/Hypervisor">https://en.wikipedia.org/wiki/Hypervisor</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-qemu" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id265">[218]</a></td><td>Qemu. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/QEMU">https://en.wikipedia.org/wiki/QEMU</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-qemuwiki" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id266">[219]</a></td><td>Qemu. WebPage. URL: <a class="reference external" href="http://wiki.qemu-project.org/index.php/Main_Page">http://wiki.qemu-project.org/index.php/Main_Page</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-nimbus-wiki" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id267">[220]</a></td><td>Nimbus wiki. Web Page. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/Nimbus_(cloud_computing)">https://en.wikipedia.org/wiki/Nimbus_(cloud_computing)</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-nimbus" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id268">[221]</a></td><td>Nimbus. Web Page. URL: <a class="reference external" href="http://www.nimbusproject.org/doc/nimbus/platform/">http://www.nimbusproject.org/doc/nimbus/platform/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="nimbus-paper" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id269">[222]</a></td><td><em>Rebalancing in a multi-cloud environment in Science Cloud &#8216;13</em>, ACM, 2013. URL: <a class="reference external" href="http://dl.acm.org/citation.cfm?id=2465854">http://dl.acm.org/citation.cfm?id=2465854</a>, <a class="reference external" href="http://dx.doi.org/10.1145/2465848.2465854">doi:10.1145/2465848.2465854</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-cloudstack2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id271">[223]</a></td><td>Cloud Stack. Webpage. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/Apache_CloudStack">https://en.wikipedia.org/wiki/Apache_CloudStack</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-core" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id272">[224]</a></td><td>Why coreos. Web Page. accessed: 2017-01-23. URL: <a class="reference external" href="https://coreos.com/why/">https://coreos.com/why/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-nagios" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id273">[225]</a></td><td>Nagios components. Web Page. Accessed: 2017-1-11. URL: <a class="reference external" href="https://www.nagios.org/projects/">https://www.nagios.org/projects/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="nagios-book" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id274">[226]</a></td><td>David Josephsen. <em>Nagios: Building Enterprise-Grade Monitoring Infrastructures for Systems and Networks</em>. Prentice Hall Press, Upper Saddle River, NJ, USA, 2nd edition, 2013. ISBN 013313573X, 9780133135732.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="nagios-paper-2012" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id275">[227]</a></td><td>C.&nbsp;Issariyapat, P.&nbsp;Pongpaibool, S.&nbsp;Mongkolluksame, and K.&nbsp;Meesublak. Using nagios as a groundwork for developing a better network monitoring system. In <em>2012 Proceedings of PICMET &#8216;12: Technology Management for Emerging Technologies</em>, 27712777. July 2012.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="inca-book" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id276">[228]</a></td><td>Jinjun&nbsp;Chen Lizhe&nbsp;Wang, Wei&nbsp;Jie. <em>Grid Computing: Infrastructure, Service, and Applications</em>. Taylor &amp; Francis, 6000 Broken Sound Parkway NW, Suite 300 Boca Raton, FL 33487, 2009. ISBN 1420067664.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-inca" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id277">[229]</a></td><td>Inca, components. Web Page. Accessed: 2017-01-16. URL: <a class="reference external" href="http://inca.sdsc.edu/">http://inca.sdsc.edu/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-eduroam" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id278">[230]</a></td><td>Eduroam. Web Page. URL: <a class="reference external" href="https://www.eduroam.org/about/">https://www.eduroam.org/about/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="eduroam-paper-2005" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id279">[231]</a></td><td>Licia Florio and Klaas Wierenga. Eduroam, providing mobility for roaming users. <em>TERENA</em>, 2005. URL: <a class="reference external" href="https://www.terena.org/activities/tf-mobility/docs/ppt/eunis-eduroamfinal-LF.pdf">https://www.terena.org/activities/tf-mobility/docs/ppt/eunis-eduroamfinal-LF.pdf</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-ldap" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id280">[232]</a></td><td>LDAP. Web Page. Accessed: 2017-02-02. URL: <a class="reference external" href="http://searchmobilecomputing.techtarget.com/definition/LDAP">http://searchmobilecomputing.techtarget.com/definition/LDAP</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-zoo-overiew" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id281">[233]</a></td><td>Zookeeper - overview. Web Page. Accessed: 2017-01-23. URL: <a class="reference external" href="https://zookeeper.apache.org/doc/trunk/zookeeperOver.html">https://zookeeper.apache.org/doc/trunk/zookeeperOver.html</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-zoo-wiki" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id282">[234]</a></td><td>Zookeeper - wikipedia. Web Page. Accessed: 2017-01-23. URL: <a class="reference external" href="https://en.wikipedia.org/wiki/Apache_ZooKeeper">https://en.wikipedia.org/wiki/Apache_ZooKeeper</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-zoo-ibm" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id283">[235]</a></td><td>Ibm - what is zookeeper. Web Page. Accessed: 2017-01-23. URL: <a class="reference external" href="http://www-01.ibm.com/software/data/infosphere/hadoop/zookeeper/">http://www-01.ibm.com/software/data/infosphere/hadoop/zookeeper/</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="giraffepaper" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id284">[236]</a></td><td>Xuanhua Shi, Haohong Lin, Hai Jin, Bing&nbsp;Bing Zhou, Zuoning Yin, Sheng Di, and Song Wu. Giraffe: a scalable distributed coordination service for large-scale systems. In <em>GIRAFFE: A Scalable Distributed Coordination Service for Large-scale Systems</em>, 110. 2014. URL: <a class="reference external" href="http://www.mcs.anl.gov/papers/P5157-0714.pdf">http://www.mcs.anl.gov/papers/P5157-0714.pdf</a>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="www-protobuf" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id285">[237]</a></td><td>Protocol buffer. Web Page, September 2016. URL: <a class="reference external" href="https://developers.google.com/protocol-buffers/">https://developers.google.com/protocol-buffers/</a>.</td></tr>
</tbody>
</table>
</p>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2016, Gregor von Laszewski.<br/>
    </p>
  </div>
</footer>
  </body>
</html>